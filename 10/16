{"id":"2110.08173","submitter":"Zaiqiao Meng","authors":"Zaiqiao Meng, Fangyu Liu, Ehsan Shareghi, Yixuan Su, Charlotte\n  Collins, Nigel Collier","title":"Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge\n  of Pre-trained Language Models","comments":"ACL 2022; code and data are released at\n  https://github.com/cambridgeltl/medlama","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge probing is crucial for understanding the knowledge transfer\nmechanism behind the pre-trained language models (PLMs). Despite the growing\nprogress of probing knowledge for PLMs in the general domain, specialised areas\nsuch as biomedical domain are vastly under-explored. To catalyse the research\nin this direction, we release a well-curated biomedical knowledge probing\nbenchmark, MedLAMA, which is constructed based on the Unified Medical Language\nSystem (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs\nand probing approaches on our benchmark, reaching at most 3% of acc@10. While\nhighlighting various sources of domain-specific challenges that amount to this\nunderwhelming performance, we illustrate that the underlying PLMs have a higher\npotential for probing tasks. To achieve this, we propose Contrastive-Probe, a\nnovel self-supervised contrastive probing approach, that adjusts the underlying\nPLMs without using any probing data. While Contrastive-Probe pushes the acc@10\nto 28%, the performance gap still remains notable. Our human expert evaluation\nsuggests that the probing performance of our Contrastive-Probe is still\nunder-estimated as UMLS still does not include the full spectrum of factual\nknowledge. We hope MedLAMA and Contrastive-Probe facilitate further\ndevelopments of more suited probing techniques for this domain.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:00:11 GMT"},{"version":"v2","created":"Tue, 22 Mar 2022 17:31:10 GMT"},{"version":"v3","created":"Sun, 22 May 2022 15:23:19 GMT"}],"update_date":"2022-05-24"}
{"id":"2110.08174","submitter":"Swagata Acharya","authors":"Swagata Acharya, Dimitar Pashov, Alexander N. Rudenko, Malte R\\\"osner,\n  Mark van Schilfgaarde, and Mikhail I. Katsnelson","title":"Excitons in Bulk and Layered Chromium Tri-Halides: From Frenkel to the\n  Wannier-Mott Limit","comments":"17 pages, 12 figures","journal-ref":"npj 2D Materials and Applications 6, 33 (2022)","doi":"10.1038/s41699-022-00307-7","report-no":"6, Article number: 33 (2022)","categories":"cond-mat.mtrl-sci cond-mat.str-el physics.comp-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Excitons with large binding energies $\\sim$2-3 eV in CrX$_{3}$ are\nhistorically characterized as being localized (Frenkel) excitons that emerge\nfrom the atomic $d{-}d$ transitions between the Cr-3$d$-$t_{2g}$ and $e_{g}$\norbitals. The argument has gathered strength in recent years as the excitons in\nrecently made monolayers are found at almost the same energies as the bulk. The\nLaporte rule, which restricts such parity forbidden atomic transitions, can\nrelax if, at least, one element is present: spin-orbit coupling, odd-parity\nphonons or Jahn-Teller distortion. While what can be classified as a purely\nFrenkel exciton is a matter of definition, we show using an advanced first\nprinciples parameter-free approach that these excitons in CrX$_{3}$, in both\nits bulk and monolayer variants, have band-origin and do not require the\nrelaxation of Laporte rule as a fundamental principle. We show that, the\ncharacter of these excitons is mostly determined by the Cr-$d$ orbital\nmanifold, nevertheless, they appear only as a consequence of X-p states\nhybridizing with the Cr-$d$. The hybridization enhances as the halogen atom\nbecomes heavier, bringing the X-$p$ states closer to the Cr-$d$ states in the\nsequence Cl{\\textrightarrow}Br{\\textrightarrow}I, with an attendant increase in\nexciton intensity and decrease in binding energy. By applying a range of\ndifferent kinds of perturbations, we show that, moderate changes to the\ntwo-particle Hamiltonian that essentially modifies the Cr-$d$-X-$p$\nhybridization, can alter both the intensities and positions of the exciton\npeaks. A detailed analysis of several deep lying excitons, with and without\nstrain, reveals that the exciton is most Frenkel like in CrCl$_{3}$ and\nacquires mixed Frenkel-Wannier character in CrI$_{3}$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:02:21 GMT"}],"update_date":"2022-05-24"}
{"id":"2110.08175","submitter":"Lidiya Murakhovs'ka","authors":"Lidiya Murakhovs'ka, Chien-Sheng Wu, Philippe Laban, Tong Niu, Wenhao\n  Liu, Caiming Xiong","title":"MixQG: Neural Question Generation with Mixed Answer Types","comments":"camera-ready version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Asking good questions is an essential ability for both human and machine\nintelligence. However, existing neural question generation approaches mainly\nfocus on the short factoid type of answers. In this paper, we propose a neural\nquestion generator, MixQG, to bridge this gap. We combine 9 question answering\ndatasets with diverse answer types, including yes/no, multiple-choice,\nextractive, and abstractive answers, to train a single generative model. We\nshow with empirical results that our model outperforms existing work in both\nseen and unseen domains and can generate questions with different cognitive\nlevels when conditioned on different answer types. Our code is released and\nwell-integrated with the Huggingface library to facilitate various downstream\napplications.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:03:40 GMT"},{"version":"v2","created":"Tue, 31 May 2022 15:53:46 GMT"}],"update_date":"2022-06-01"}
{"id":"2110.08176","submitter":"Dj Strouse","authors":"DJ Strouse, Kevin R. McKee, Matt Botvinick, Edward Hughes, Richard\n  Everett","title":"Collaborating with Humans without Human Data","comments":"Accepted at NeurIPS 2021 (spotlight)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.HC cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collaborating with humans requires rapidly adapting to their individual\nstrengths, weaknesses, and preferences. Unfortunately, most standard\nmulti-agent reinforcement learning techniques, such as self-play (SP) or\npopulation play (PP), produce agents that overfit to their training partners\nand do not generalize well to humans. Alternatively, researchers can collect\nhuman data, train a human model using behavioral cloning, and then use that\nmodel to train \"human-aware\" agents (\"behavioral cloning play\", or BCP). While\nsuch an approach can improve the generalization of agents to new human\nco-players, it involves the onerous and expensive step of collecting large\namounts of human data first. Here, we study the problem of how to train agents\nthat collaborate well with human partners without using human data. We argue\nthat the crux of the problem is to produce a diverse set of training partners.\nDrawing inspiration from successful multi-agent approaches in competitive\ndomains, we find that a surprisingly simple approach is highly effective. We\ntrain our agent partner as the best response to a population of self-play\nagents and their past checkpoints taken throughout training, a method we call\nFictitious Co-Play (FCP). Our experiments focus on a two-player collaborative\ncooking simulator that has recently been proposed as a challenge problem for\ncoordination with humans. We find that FCP agents score significantly higher\nthan SP, PP, and BCP when paired with novel agent and human partners.\nFurthermore, humans also report a strong subjective preference to partnering\nwith FCP agents over all baselines.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:03:57 GMT"},{"version":"v2","created":"Fri, 7 Jan 2022 17:36:59 GMT"}],"update_date":"2022-01-10"}
{"id":"2110.08177","submitter":"James Honaker","authors":"Benjamin M. Case and James Honaker and Mahnush Movahedi","title":"The Privacy-preserving Padding Problem: Non-negative Mechanisms for\n  Conservative Answers with Differential Privacy","comments":"20 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Differentially private noise mechanisms commonly use symmetric noise\ndistributions. This is attractive both for achieving the differential privacy\ndefinition, and for unbiased expectations in the noised answers. However, there\nare contexts in which a noisy answer only has utility if it is conservative,\nthat is, has known-signed error, which we call a padded answer. Seemingly, it\nis paradoxical to satisfy the DP definition with one-sided error, but we show\nhow it is possible to bury the paradox into approximate DP's delta parameter.\nWe develop a few mechanisms for one-sided padding mechanisms that always give\nconservative answers, but still achieve approximate differential privacy. We\nshow how these mechanisms can be applied in a few select areas including making\nthe cardinalities of set intersections and unions revealed in Private Set\nIntersection protocols differential private and enabling multiparty computation\nprotocols to compute on sparse data which has its exact sizes made differential\nprivate rather than performing a fully oblivious more expensive computation.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:05:35 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08178","submitter":"Marius Buliga","authors":"Marius Buliga","title":"COLIN implies LIN for emergent algebras","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.DG math.MG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Emergent algebras, first time introduced in arXiv:0907.1520 , are families of\nquasigroup operations indexed by a commutative group, which satisfy some\nalgebraic relations and also topological (convergence and continuity)\nrelations. Besides sub-riemannian geometry arXiv:math/0608536, they appear as a\nsemantics of a family of graph-rewrite systems related to interaction\ncombinators arXiv:2007.10288, or lambda calculus arXiv:1305.5786 . In\narXiv:1807.02058 there is a lambda calculus version of emergent algebras.\n  In this article we prove that for emergent algebras the condition (COLIN), or\nright-distributivity for emergent algebras, implies (LIN), or\nleft-distributivity for emergent algebras. It means that any emergent algebra\nwhich is right-distributive has to come from a commutative group endowed with a\nfamily of dilations.\n  This is surprising, because there are many examples of emergent algebras\nwhich satisfy (LIN), but not (COLIN), namely those who are associated to\nnon-commutative conical groups, in particular to non-commutative Carnot groups.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:06:30 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08179","submitter":"Alexandros Spyridon Arvanitakis","authors":"Alex S. Arvanitakis, Chris D. A. Blair, Daniel C. Thompson","title":"A QP perspective on topology change in Poisson-Lie T-duality","comments":"40 pages. v2: references added","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th math-ph math.DG math.MP math.SG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe topological T-duality and Poisson-Lie T-duality in terms of QP\n(differential graded symplectic) manifolds and their canonical transformations.\nDuality is mediated by a QP-manifold on doubled non-abelian \"correspondence\"\nspace, from which we can perform mutually dual symplectic reductions, where\ncertain canonical transformations play a vital role. In the presence of\nspectator coordinates, we show how the introduction of \"bibundle\" structure on\ncorrespondence space realises changes in the global fibration structure under\nPoisson-Lie duality. Our approach can be directly translated to the worldsheet\nto derive dual string current algebras. Finally, the canonical transformations\nappearing in our reduction procedure naturally suggest a Fourier-Mukai integral\ntransformation for Poisson-Lie T-duality.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:11:56 GMT"},{"version":"v2","created":"Tue, 26 Oct 2021 13:24:31 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08180","submitter":"Samuel Farrens","authors":"S. Farrens, A. Lacan, A. Guinot and A. Z. Vitorelli","title":"Deep Transfer Learning for Blended Source Identification in Galaxy\n  Survey Data","comments":"9 pages, 6 figures, accepted for publication in A&A","journal-ref":"A&A 657, A98 (2022)","doi":"10.1051/0004-6361/202141166","report-no":null,"categories":"astro-ph.IM astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present BlendHunter, a proof-of-concept for a deep transfer learning based\napproach for the automated and robust identification of blended sources in\ngalaxy survey data. We take the VGG-16 network with pre-trained convolutional\nlayers and train the fully connected layers on parametric models of COSMOS\nimages. We test the efficacy of the transfer learning by taking the weights\nlearned on the parametric models and using them to identify blends in more\nrealistic CFIS-like images. We compare the performance of this method to SEP (a\nPython implementation of SExtractor) as function of noise level and the\nseparation between sources. We find that BlendHunter outperforms SEP by $\\sim\n15\\%$ in terms of classification accuracy for close blends ($<10$ pixel\nseparation between sources) regardless of the noise level used for training.\nAdditionally, the method provides consistent results to SEP for distant blends\n($\\geq10$ pixel separation between sources) provided the network is trained on\ndata with a relatively close noise standard deviation to the target images. The\ncode and data have been made publicly available to ensure the reproducibility\nof the results.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:12:45 GMT"}],"update_date":"2022-01-19"}
{"id":"2110.08181","submitter":"Rebecca Durst","authors":"Erik Burman, Rebecca Durst, Miguel Fern\\'andez, Johnny Guzm\\'an","title":"Loosely coupled, non-iterative time-splitting scheme based on\n  Robin-Robin coupling: unified analysis for parabolic/parabolic and\n  parabolic/hyperbolic problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a loosely coupled, non-iterative time-splitting scheme based on\nRobin-Robin coupling conditions. We apply a novel unified analysis for this\nscheme applied to both a Parabolic/Parabolic coupled system and a\nParabolic/Hyperbolic coupled system. We show for both systems that the scheme\nis stable, and the error converges as $\\mathcal{O}\\big(\\Delta t \\sqrt{T\n+\\log{\\frac{1}{\\Delta t}}}\\big)$, where $\\Delta t$ is the time step\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:18:59 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08182","submitter":"Cory Paik","authors":"Cory Paik, St\\'ephane Aroca-Ouellette, Alessandro Roncone and\n  Katharina Kann","title":"The World of an Octopus: How Reporting Bias Influences a Language\n  Model's Perception of Color","comments":"Accepted to EMNLP 2021, 9 Pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent work has raised concerns about the inherent limitations of text-only\npretraining. In this paper, we first demonstrate that reporting bias, the\ntendency of people to not state the obvious, is one of the causes of this\nlimitation, and then investigate to what extent multimodal training can\nmitigate this issue. To accomplish this, we 1) generate the Color Dataset\n(CoDa), a dataset of human-perceived color distributions for 521 common\nobjects; 2) use CoDa to analyze and compare the color distribution found in\ntext, the distribution captured by language models, and a human's perception of\ncolor; and 3) investigate the performance differences between text-only and\nmultimodal models on CoDa. Our results show that the distribution of colors\nthat a language model recovers correlates more strongly with the inaccurate\ndistribution found in text than with the ground-truth, supporting the claim\nthat reporting bias negatively impacts and inherently limits text-only\ntraining. We then demonstrate that multimodal models can leverage their visual\ntraining to mitigate these effects, providing a promising avenue for future\nresearch.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:28:17 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08183","submitter":"Jeremy Dalseno","authors":"J. Dalseno","title":"Rescaling the isospin triangle argument for constraining $\\phi_2$\n  ($\\alpha$): consolidating Belle II and a potential path forward for LHCb","comments":"10 pages, 7 figures, replaced with journal version. This article\n  should be considered in conjunction with arXiv:2108.06182","journal-ref":"Eur. Phys. J. Plus 137 (2022) 806","doi":"10.1140/epjp/s13360-022-03008-8","report-no":null,"categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A rescaling of the SU(2) isospin triangles constraining $\\phi_2$ ($\\alpha$)\nthat relies on measurements of the experimentally cleaner relative branching\nfractions, as opposed to those absolute, is proposed. Paving the way towards\nmore systematically sustainable analysis, this method promises to eliminate a\ndominant systematic at Belle II amongst others, namely the uncertainty on the\nnumber of $B \\bar B$ pairs in data. Furthermore, a $\\phi_2$ constraint in the\n$B \\to \\rho \\rho$ system at LHCb that is more independent of Belle II input is\nshown to become viable even without a measurement of $C\\!P$ violation in $B^0\n\\to \\rho^+\\rho^-$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:30:03 GMT"},{"version":"v2","created":"Tue, 12 Jul 2022 16:48:20 GMT"}],"update_date":"2022-07-13"}
{"id":"2110.08184","submitter":"Nikolaos Kidonakis","authors":"Nikolaos Kidonakis","title":"Top-quark production at approximate N$^3$LO","comments":"6 pages, 4 figures; contribution to the proceedings of the EPS-HEP\n  2021 conference","journal-ref":"PoS (EPS-HEP2021) 465","doi":null,"report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  I discuss recent theoretical results with soft-gluon corrections for various\ntop-quark production processes through approximate N$^3$LO, including soft\nanomalous dimensions through three loops. I present numerical results for total\ncross sections and differential distributions for top-pair and $tW$ production\nas well as for three-particle final states with a top quark and a Higgs boson.\nI show that soft-gluon corrections are dominant for a large range of collider\nenergies.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:37:35 GMT"}],"update_date":"2023-02-21"}
{"id":"2110.08185","submitter":"Eda Bayram","authors":"Eda Bayram","title":"Propagation on Multi-relational Graphs for Node Regression","comments":"Accepted to IJCLR 2021 Workshop: Statistical Relational AI (StarAI)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent years have witnessed a rise in real-world data captured with rich\nstructural information that can be conveniently depicted by multi-relational\ngraphs. While inference of continuous node features across a simple graph is\nrather under-studied by the current relational learning research, we go one\nstep further and focus on node regression problem on multi-relational graphs.\nWe take inspiration from the well-known label propagation algorithm aiming at\ncompleting categorical features across a simple graph and propose a novel\npropagation framework for completing missing continuous features at the nodes\nof a multi-relational and directed graph. Our multi-relational propagation\nalgorithm is composed of iterative neighborhood aggregations which originate\nfrom a relational local generative model. Our findings show the benefit of\nexploiting the multi-relational structure of the data in several node\nregression scenarios in different settings.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:37:39 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08186","submitter":"Rafael Bailo PhD DIC ARCS","authors":"Rafael Bailo, Jos\\'e A. Carrillo, Jingwei Hu","title":"Bound-Preserving Finite-Volume Schemes for Systems of Continuity\n  Equations with Saturation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose finite-volume schemes for general continuity equations which\npreserve positivity and global bounds that arise from saturation effects in the\nmobility function. In the case of gradient flows, the schemes dissipate the\nfree energy at the fully discrete level. Moreover, these schemes are\ngeneralised to coupled systems of non-linear continuity equations, such as\nmultispecies models in mathematical physics or biology, preserving the bounds\nand the dissipation of the energy whenever applicable. These results are\nillustrated through extensive numerical simulations which explore known\nbehaviours in biology and showcase new phenomena not yet described by the\nliterature.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:38:05 GMT"},{"version":"v2","created":"Mon, 4 Apr 2022 14:29:13 GMT"},{"version":"v3","created":"Sat, 14 Jan 2023 11:12:51 GMT"}],"update_date":"2023-01-18"}
{"id":"2110.08187","submitter":"Loic Landrieu","authors":"F\\'elix Quinton and Loic Landrieu","title":"Crop Rotation Modeling for Deep Learning-Based Parcel Classification\n  from Satellite Time Series","comments":"Published in Remote Sensing","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  While annual crop rotations play a crucial role for agricultural\noptimization, they have been largely ignored for automated crop type mapping.\nIn this paper, we take advantage of the increasing quantity of annotated\nsatellite data to propose the first deep learning approach modeling\nsimultaneously the inter- and intra-annual agricultural dynamics of parcel\nclassification. Along with simple training adjustments, our model provides an\nimprovement of over 6.3 mIoU points over the current state-of-the-art of crop\nclassification. Furthermore, we release the first large-scale multi-year\nagricultural dataset with over 300,000 annotated parcels.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:38:41 GMT"},{"version":"v2","created":"Tue, 16 Nov 2021 12:36:42 GMT"}],"update_date":"2021-11-17"}
{"id":"2110.08188","submitter":"Li Jiang","authors":"Li Jiang, Shaoshuai Shi, Zhuotao Tian, Xin Lai, Shu Liu, Chi-Wing Fu,\n  Jiaya Jia","title":"Guided Point Contrastive Learning for Semi-supervised Point Cloud\n  Semantic Segmentation","comments":"ICCV 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rapid progress in 3D semantic segmentation is inseparable from the advances\nof deep network models, which highly rely on large-scale annotated data for\ntraining. To address the high cost and challenges of 3D point-level labeling,\nwe present a method for semi-supervised point cloud semantic segmentation to\nadopt unlabeled point clouds in training to boost the model performance.\nInspired by the recent contrastive loss in self-supervised tasks, we propose\nthe guided point contrastive loss to enhance the feature representation and\nmodel generalization ability in semi-supervised setting. Semantic predictions\non unlabeled point clouds serve as pseudo-label guidance in our loss to avoid\nnegative pairs in the same category. Also, we design the confidence guidance to\nensure high-quality feature learning. Besides, a category-balanced sampling\nstrategy is proposed to collect positive and negative samples to mitigate the\nclass imbalance problem. Extensive experiments on three datasets (ScanNet V2,\nS3DIS, and SemanticKITTI) show the effectiveness of our semi-supervised method\nto improve the prediction quality with unlabeled data.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:38:54 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08189","submitter":"Matthew Davies","authors":"Matthew W. Davies, Pedro Carrilho, David J. Mulryne","title":"Non-Gaussianity in inflationary scenarios for primordial black holes","comments":"22 pages, 4 figures; footnotes and extra references added","journal-ref":"JCAP06(2022)019","doi":"10.1088/1475-7516/2022/06/019","report-no":null,"categories":"astro-ph.CO gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Working in an idealised framework in which a series of phases of evolution\ndefined by the second slow-roll parameter $\\eta$ are matched together, we\ncalculate the reduced bispectrum, $f_{\\rm NL}$, for models of inflation with a\nlarge peak in their primordial power spectra. We find $f_{\\rm NL}$ is typically\napproximately constant over scales at which the peak is located, and provide an\nanalytic approximation for this value. This allows us to identify the\nconditions under which $f_{\\rm NL}$ is large enough to have a significant\nimpact on the resulting production of primordial black holes (PBHs) and scalar\ninduced gravitational waves (SIGWs). Together with analytic formulae for the\ngradient of the rise and fall in the power spectrum, this provides a toolkit\nfor designing or quickly analysing inflationary models that produce PBHs and\nSIGWs.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:40:58 GMT"},{"version":"v2","created":"Tue, 1 Feb 2022 13:09:38 GMT"}],"update_date":"2022-08-08"}
{"id":"2110.08190","submitter":"Shaoyi Huang","authors":"Shaoyi Huang, Dongkuan Xu, Ian E.H. Yen, Yijue Wang, Sung-en Chang,\n  Bingbing Li, Shiyang Chen, Mimi Xie, Sanguthevar Rajasekaran, Hang Liu,\n  Caiwen Ding","title":"Sparse Progressive Distillation: Resolving Overfitting under\n  Pretrain-and-Finetune Paradigm","comments":"11 pages; 16 figures; Published in Proceedings of the 60th Annual\n  Meeting of the Association for Computational Linguistics and the 11th\n  International Joint Conference on Natural Language Processing","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conventional wisdom in pruning Transformer-based language models is that\npruning reduces the model expressiveness and thus is more likely to underfit\nrather than overfit. However, under the trending pretrain-and-finetune\nparadigm, we postulate a counter-traditional hypothesis, that is: pruning\nincreases the risk of overfitting when performed at the fine-tuning phase. In\nthis paper, we aim to address the overfitting problem and improve pruning\nperformance via progressive knowledge distillation with error-bound properties.\nWe show for the first time that reducing the risk of overfitting can help the\neffectiveness of pruning under the pretrain-and-finetune paradigm. Ablation\nstudies and experiments on the GLUE benchmark show that our method outperforms\nthe leading competitors across different tasks.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:42:56 GMT"},{"version":"v2","created":"Mon, 18 Oct 2021 19:56:35 GMT"},{"version":"v3","created":"Mon, 4 Apr 2022 18:09:14 GMT"},{"version":"v4","created":"Mon, 16 Jan 2023 22:25:58 GMT"}],"update_date":"2023-01-18"}
{"id":"2110.08191","submitter":"Jind\\v{r}ich Libovick\\'y","authors":"Jind\\v{r}ich Libovick\\'y, Helmut Schmid, Alexander Fraser","title":"Why don't people use character-level machine translation?","comments":"16 pages, 4 figures; Findings of ACL 2022, camera-ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a literature and empirical survey that critically assesses the\nstate of the art in character-level modeling for machine translation (MT).\nDespite evidence in the literature that character-level systems are comparable\nwith subword systems, they are virtually never used in competitive setups in\nWMT competitions. We empirically show that even with recent modeling\ninnovations in character-level natural language processing, character-level MT\nsystems still struggle to match their subword-based counterparts.\nCharacter-level MT systems show neither better domain robustness, nor better\nmorphological generalization, despite being often so motivated. However, we are\nable to show robustness towards source side noise and that translation quality\ndoes not degrade with increasing beam size at decoding time.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:43:31 GMT"},{"version":"v2","created":"Wed, 27 Apr 2022 09:45:40 GMT"}],"update_date":"2022-04-28"}
{"id":"2110.08192","submitter":"Patrick Ruhkamp","authors":"Patrick Ruhkamp, Daoyi Gao, Hanzhi Chen, Nassir Navab, Benjamin Busam","title":"Attention meets Geometry: Geometry Guided Spatial-Temporal Attention for\n  Consistent Self-Supervised Monocular Depth Estimation","comments":"Accepted at 3DV 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inferring geometrically consistent dense 3D scenes across a tuple of\ntemporally consecutive images remains challenging for self-supervised monocular\ndepth prediction pipelines. This paper explores how the increasingly popular\ntransformer architecture, together with novel regularized loss formulations,\ncan improve depth consistency while preserving accuracy. We propose a spatial\nattention module that correlates coarse depth predictions to aggregate local\ngeometric information. A novel temporal attention mechanism further processes\nthe local geometric information in a global context across consecutive images.\nAdditionally, we introduce geometric constraints between frames regularized by\nphotometric cycle consistency. By combining our proposed regularization and the\nnovel spatial-temporal-attention module we fully leverage both the geometric\nand appearance-based consistency across monocular frames. This yields\ngeometrically meaningful attention and improves temporal depth stability and\naccuracy compared to previous methods.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:43:31 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08193","submitter":"Alicia Parrish","authors":"Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar,\n  Jason Phang, Jana Thompson, Phu Mon Htut, Samuel R. Bowman","title":"BBQ: A Hand-Built Bias Benchmark for Question Answering","comments":"Accepted to ACL 2022 Findings. 20 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It is well documented that NLP models learn social biases, but little work\nhas been done on how these biases manifest in model outputs for applied tasks\nlike question answering (QA). We introduce the Bias Benchmark for QA (BBQ), a\ndataset of question sets constructed by the authors that highlight attested\nsocial biases against people belonging to protected classes along nine social\ndimensions relevant for U.S. English-speaking contexts. Our task evaluates\nmodel responses at two levels: (i) given an under-informative context, we test\nhow strongly responses reflect social biases, and (ii) given an adequately\ninformative context, we test whether the model's biases override a correct\nanswer choice. We find that models often rely on stereotypes when the context\nis under-informative, meaning the model's outputs consistently reproduce\nharmful biases in this setting. Though models are more accurate when the\ncontext provides an informative answer, they still rely on stereotypes and\naverage up to 3.4 percentage points higher accuracy when the correct answer\naligns with a social bias than when it conflicts, with this difference widening\nto over 5 points on examples targeting gender for most models tested.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:43:46 GMT"},{"version":"v2","created":"Wed, 16 Mar 2022 01:35:45 GMT"}],"update_date":"2022-03-17"}
{"id":"2110.08194","submitter":"Daniel Chernowitz","authors":"Daniel Chernowitz, Oleksandr Gamayun","title":"On the Dynamics of Free-Fermionic Tau-Functions at Finite Temperature","comments":"83 pages, 21 figures. Revised based on reviews on SciPost Physics\n  Core","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cond-mat.quant-gas cond-mat.str-el math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we explore an instance of the $\\tau$-function of vertex type\noperators, specified in terms of a constant phase shift in a free-fermionic\nbasis. From the physical point of view this $\\tau$-function has multiple\ninterpretations: as a correlator of Jordan-Wigner strings, a Loschmidt Echo in\nthe Aharonov-Bohm effect, or the generating function of the local densities in\nthe Tonks-Girardeau gas. We present the $\\tau$-function as a form-factors\nseries and tackle it from four vantage points: (i) we perform an exact\nsummation and express it in terms of a Fredholm determinant in the\nthermodynamic limit, (ii) we use bosonization techniques to perform partial\nsummations of soft modes around the Fermi surface to acquire the scaling at\nzero temperature, (iii) we derive large space and time asymptotic behavior for\nthe thermal Fredholm determinant by relating it to effective form-factors with\nan asymptotically similar kernel, and (iv) we identify and sum the important\nbasis elements directly through a tailor-made numerical algorithm for\nfinite-entropy states in a free-fermionic Hilbert space. All methods confirm\neach other. We find that, in addition to the exponential decay in the\nfinite-temperature case the dynamic correlation functions exhibit an extra\npower law in time, universal over any distribution and time scale.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:47:10 GMT"},{"version":"v2","created":"Wed, 1 Dec 2021 17:00:16 GMT"},{"version":"v3","created":"Tue, 18 Jan 2022 21:11:23 GMT"}],"update_date":"2022-01-20"}
{"id":"2110.08195","submitter":"Julien Ricaud","authors":"Phan Th\\`anh Nam, Julien Ricaud, Arnaud Triay","title":"The condensation of a trapped dilute Bose gas with three-body\n  interactions","comments":"57 pages","journal-ref":"Prob. Math. Phys. 4 (2023) 91-149","doi":"10.2140/pmp.2023.4.91","report-no":null,"categories":"math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a trapped dilute gas of $N$ bosons in $\\mathbb{R}^3$ interacting\nvia a three-body interaction potential of the form $N\\, V(N^{1/2}(x-y,x-z))$.\nIn the limit $N\\to \\infty$, we prove that every approximate ground state of the\nsystem is a convex superposition of minimizers of a 3D energy-critical\nnonlinear Schr\\\"odinger functional where the nonlinear coupling constant is\nproportional to the scattering energy of the interaction potential. In\nparticular, the $N$-body ground state exhibits complete Bose--Einstein\ncondensation if the nonlinear Schr\\\"odinger minimizer is unique up to a complex\nphase.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:51:33 GMT"},{"version":"v2","created":"Thu, 28 Oct 2021 13:07:16 GMT"},{"version":"v3","created":"Mon, 12 Sep 2022 14:35:03 GMT"}],"update_date":"2023-04-05"}
{"id":"2110.08196","submitter":"Yo\\`av Montacute","authors":"Yo\\`av Montacute and Nihil Shah","title":"The Pebble-Relation Comonad in Finite Model Theory","comments":"Appears in Logic in Computer Science (LICS) 2022 Proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The pebbling comonad, introduced by Abramsky, Dawar and Wang, provides a\ncategorical interpretation for the k-pebble games from finite model theory. The\ncoKleisli category of the pebbling comonad specifies equivalences under\ndifferent fragments and extensions of infinitary k-variable logic. Moreover,\nthe coalgebras over this pebbling comonad characterise treewidth and correspond\nto tree decompositions. In this paper we introduce the pebble-relation comonad,\nwhich characterises pathwidth and whose coalgebras correspond to path\ndecompositions. We further show that the existence of a coKleisli morphism in\nthis comonad is equivalent to truth preservation in the restricted conjunction\nfragment of k-variable infinitary logic. We do this using Dalmau's\npebble-relation game and an equivalent all-in-one pebble game. We then provide\na similar treatment to the corresponding coKleisli isomorphisms via a bijective\nversion of the all-in-one pebble game with a hidden pebble placement. Finally,\nwe show as a consequence a new Lov\\'asz-type theorem relating pathwidth to the\nrestricted conjunction fragment of k-variable infinitary logic with counting\nquantifiers.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:52:34 GMT"},{"version":"v2","created":"Tue, 31 Jan 2023 12:03:40 GMT"}],"update_date":"2023-02-01"}
{"id":"2110.08197","submitter":"Andr\\'as Cristian L\\H{o}rincz","authors":"Andr\\'as C. L\\H{o}rincz and Claudiu Raicu","title":"Borel-Moore homology of determinantal varieties","comments":"28 pages, v2: added results on mixed Hodge structures. New sections:\n  2.2, 4.3, 7","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.AC math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We compute the rational Borel-Moore homology groups for affine determinantal\nvarieties in the spaces of general, symmetric, and skew-symmetric matrices,\nsolving a problem suggested by the work of Pragacz and Ratajski. The main\ningredient is the relation with Hartshorne's algebraic de Rham homology theory,\nand the calculation of the singular cohomology of matrix orbits, using the\nmethods of Cartan and Borel. We also establish the degeneration of the\n\\v{C}ech-de Rham spectral sequence for determinantal varieties, and compute\nexplicitly the dimensions of de Rham cohomology groups of local cohomology with\ndeterminantal support, which are analogues of Lyubeznik numbers first\nintroduced by Switala. Additionally, in the case of general matrices we further\ndetermine the Hodge numbers of the singular cohomology of matrix orbits and of\nthe Borel-Moore homology of their closures, based on Saito's theory of mixed\nHodge modules.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:53:44 GMT"},{"version":"v2","created":"Sat, 6 Nov 2021 16:56:24 GMT"}],"update_date":"2021-11-09"}
{"id":"2110.08198","submitter":"Nikita Astrakhantsev","authors":"Nikita Astrakhantsev, Francesco Ferrari, Nils Niggemann, Tobias\n  M\\\"uller, Aishwarya Chauhan, Augustine Kshetrimayum, Pratyay Ghosh, Nicolas\n  Regnault, Ronny Thomale, Johannes Reuther, Titus Neupert, Yasir Iqbal","title":"Pinwheel valence-bond-crystal ground state of the spin-$\\frac{1}{2}$\n  Heisenberg antiferromagnet on the $shuriken$ lattice","comments":"Main paper (7 pages, 5 figures, 1 table) + Supplemental Material","journal-ref":"Phys. Rev. B 104, L220408 (2021)","doi":"10.1103/PhysRevB.104.L220408","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the nature of the ground-state of the spin-$\\frac{1}{2}$\nHeisenberg antiferromagnet on the $shuriken$ lattice by complementary\nstate-of-the-art numerical techniques, such as variational Monte Carlo (VMC)\nwith versatile Gutzwiller-projected Jastrow wave functions, unconstrained\nmulti-variable variational Monte Carlo (mVMC), and pseudo-fermion/Majorana\nfunctional renormalization group (PF/PM-FRG) methods. We establish the presence\nof a quantum paramagnetic ground state and investigate its nature, by\nclassifying symmetric and chiral quantum spin liquids, and inspecting their\ninstabilities towards competing valence-bond-crystal (VBC) orders. Our VMC\nanalysis reveals that a VBC with a pinwheel structure emerges as the\nlowest-energy variational ground state, and it is obtained as an instability of\nthe U(1) Dirac spin liquid. Analogous conclusions are drawn from mVMC\ncalculations employing accurate BCS pairing states supplemented by symmetry\nprojectors, which confirm the presence of pinwheel VBC order by a thorough\nanalysis of dimer-dimer correlation functions. Our work highlights the\nnontrivial role of quantum fluctuations via the Gutzwiller projector in\nresolving the subtle interplay between competing orders.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:54:55 GMT"},{"version":"v2","created":"Wed, 20 Oct 2021 19:42:54 GMT"},{"version":"v3","created":"Wed, 17 Nov 2021 08:22:57 GMT"}],"update_date":"2021-12-24"}
{"id":"2110.08199","submitter":"Jose Edson Sampaio","authors":"Alexandre Fernandes and Jos\\'e Edson Sampaio","title":"On characterization of smoothness of complex analytic sets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.CV math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The paper is devoted to metric properties of singularities. We investigate\nthe relations among topology, metric properties and smoothness. In particular,\nwe present some higher dimensional analogous of Mumford's theorem on smoothness\nof normal surfaces. For example, we prove that a complex analytic set, with an\nisolated singularity at $0$, is smooth at $0$ if and only if it is locally\nmetrically conical at $0$ and its link at $0$ is a homotopy sphere.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:57:57 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08200","submitter":"Marc Serra-Peralta","authors":"Marc Serra-Peralta, Joan Serr\\`a, \\'Alvaro Corral","title":"Lognormals, Power Laws and Double Power Laws in the Distribution of\n  Frequencies of Harmonic Codewords from Classical Music","comments":"33 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Zipf's law is a paradigm describing the importance of different elements in\ncommunication systems, especially in linguistics. Despite the complexity of the\nhierarchical structure of language, music has in some sense an even more\ncomplex structure, due to its multidimensional character (melody, harmony,\nrhythm, timbre...). Thus, the relevance of Zipf's law in music is still an open\nquestion. Using discrete codewords representing harmonic content obtained from\na large-scale analysis of classical composers, we show that a nearly universal\nZipf-like law holds at a qualitative level. However, in an in-depth\nquantitative analysis, where we introduce the double power-law distribution as\na new player in the classical debate between the superiority of Zipf's (power)\nlaw and that of the lognormal distribution, we conclude not only that\nuniversality does not hold, but that there is not a unique probability\ndistribution that best describes the usage of the different codewords by each\ncomposer.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:58:40 GMT"},{"version":"v2","created":"Wed, 5 Jan 2022 19:06:09 GMT"}],"update_date":"2022-01-07"}
{"id":"2110.08201","submitter":"Zakhar Kabluchko","authors":"Zakhar Kabluchko","title":"Face numbers of high-dimensional Poisson zero cells","comments":"14 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $\\mathcal Z_d$ be the zero cell of a $d$-dimensional, isotropic and\nstationary Poisson hyperplane tessellation. We study the asymptotic behavior of\nthe expected number of $k$-dimensional faces of $\\mathcal Z_d$, as\n$d\\to\\infty$. For example, we show that the expected number of hyperfaces of\n$\\mathcal Z_d$ is asymptotically equivalent to $\\sqrt{2\\pi/3}\\, d^{3/2}$, as\n$d\\to\\infty$. We also prove that the expected solid angle of a random cone\nspanned by $d$ random vectors that are independent and uniformly distributed on\nthe unit upper half-sphere in $\\mathbb R^{d}$ is asymptotic to $\\sqrt 3\n\\pi^{-d}$, as $d\\to\\infty$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:59:45 GMT"},{"version":"v2","created":"Fri, 18 Mar 2022 09:43:29 GMT"}],"update_date":"2022-03-21"}
{"id":"2110.08202","submitter":"Jana Kemnitz","authors":"Stephanie Holly, Thomas Hiessl, Safoura Rezapour Lakani, Daniel\n  Schall, Clemens Heitzinger, Jana Kemnitz","title":"Evaluation of Hyperparameter-Optimization Approaches in an Industrial\n  Federated Learning System","comments":"This paper is accepted at the IDSC https://idsc.at/ and will be\n  published by Springer. The Version uploaded is before the peer review\n  process. The link to the final version will be updated as soon as the paper\n  is published. Figure one was corrected on 2021/10/20","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Federated Learning (FL) decouples model training from the need for direct\naccess to the data and allows organizations to collaborate with industry\npartners to reach a satisfying level of performance without sharing vulnerable\nbusiness information. The performance of a machine learning algorithm is highly\nsensitive to the choice of its hyperparameters. In an FL setting,\nhyperparameter optimization poses new challenges. In this work, we investigated\nthe impact of different hyperparameter optimization approaches in an FL system.\nIn an effort to reduce communication costs, a critical bottleneck in FL, we\ninvestigated a local hyperparameter optimization approach that -- in contrast\nto a global hyperparameter optimization approach -- allows every client to have\nits own hyperparameter configuration. We implemented these approaches based on\ngrid search and Bayesian optimization and evaluated the algorithms on the MNIST\ndata set using an i.i.d. partition and on an Internet of Things (IoT) sensor\nbased industrial data set using a non-i.i.d. partition.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:01:40 GMT"},{"version":"v2","created":"Wed, 20 Oct 2021 11:54:12 GMT"}],"update_date":"2021-10-22"}
{"id":"2110.08203","submitter":"Daniela Mihai","authors":"Daniela Mihai, Jonathon Hare","title":"Shared Visual Representations of Drawing for Communication: How do\n  different biases affect human interpretability and intent?","comments":null,"journal-ref":"3rd Workshop on Shared Visual Representations in Human and Machine\n  Intelligence (SVRHM 2021) of the Neural Information Processing Systems\n  (NeurIPS) conference","doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present an investigation into how representational losses can affect the\ndrawings produced by artificial agents playing a communication game. Building\nupon recent advances, we show that a combination of powerful pretrained encoder\nnetworks, with appropriate inductive biases, can lead to agents that draw\nrecognisable sketches, whilst still communicating well. Further, we start to\ndevelop an approach to help automatically analyse the semantic content being\nconveyed by a sketch and demonstrate that current approaches to inducing\nperceptual biases lead to a notion of objectness being a key feature despite\nthe agent training being self-supervised.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:02:34 GMT"},{"version":"v2","created":"Thu, 20 Jan 2022 13:08:02 GMT"}],"update_date":"2022-01-21"}
{"id":"2110.08204","submitter":"Ping Guo","authors":"Yunzhi Xu, Junior Ndayikengurukiye, Ange-Therese Akono, Ping Guo","title":"Fabrication of Fiber-Reinforced Polymer Ceramic Composites by Wet\n  Electrospinning","comments":"Manufacturing Letters (2021)","journal-ref":null,"doi":"10.1016/j.mfglet.2021.07.017","report-no":null,"categories":"cond-mat.soft physics.app-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a novel approach of wet electrospinning to yield fiber-reinforced\npolymer ceramic composites, where a reactive ceramic precursor gel is used as a\ncollector. We illustrate our approach by generating polyethylene oxide (PEO)\nfibers in a potassium silicate gel; the gel is later activated using metakaolin\nto yield a ceramic-0.5 wt% PEO fiber composite. An increase of 29% and 22% is\nrecorded for the fabricated polymer ceramic composites in terms of indentation\nmodulus and indentation hardness respectively. Our initial findings demonstrate\nthe process viability and might lead to a potentially scalable manufacturing\napproach for fiber-reinforced polymer ceramic composites.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:08:04 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08205","submitter":"Gaetano Romano","authors":"Gaetano Romano, Idris Eckley, Paul Fearnhead, Guillem Rigaill","title":"Fast Online Changepoint Detection via Functional Pruning CUSUM\n  statistics","comments":null,"journal-ref":"Journal of Machine Learning Research, 2023","doi":null,"report-no":"24(81)","categories":"stat.ME stat.CO stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many modern applications of online changepoint detection require the ability\nto process high-frequency observations, sometimes with limited available\ncomputational resources. Online algorithms for detecting a change in mean often\ninvolve using a moving window, or specifying the expected size of change. Such\nchoices affect which changes the algorithms have most power to detect. We\nintroduce an algorithm, Functional Online CuSUM (FOCuS), which is equivalent to\nrunning these earlier methods simultaneously for all sizes of window, or all\npossible values for the size of change. Our theoretical results give tight\nbounds on the expected computational cost per iteration of FOCuS, with this\nbeing logarithmic in the number of observations. We show how FOCuS can be\napplied to a number of different change in mean scenarios, and demonstrate its\npractical utility through its state-of-the art performance at detecting\nanomalous behaviour in computer server data.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:08:06 GMT"},{"version":"v2","created":"Wed, 12 Jan 2022 16:44:55 GMT"},{"version":"v3","created":"Wed, 27 Jul 2022 18:40:20 GMT"}],"update_date":"2023-04-12"}
{"id":"2110.08206","submitter":"Apoorva Khare","authors":"Alexander Belton, Dominique Guillot, Apoorva Khare, and Mihai Putinar","title":"Preservers of totally positive kernels and Polya frequency functions","comments":"25 pages, no figures. This is an announcement of some of the results\n  in a sequence of three closely related recent papers arXiv:2006.16213,\n  arXiv:2008.05121, and arXiv:2101.02129. Final version, published in\n  Mathematics Research Reports","journal-ref":"Mathematics Research Reports 3 (2022), 35-56","doi":"10.5802/mrr.12","report-no":null,"categories":"math.FA math.CA math.PR math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fractional powers and polynomial maps preserving structured totally positive\nmatrices, one-sided Polya frequency functions, or totally positive kernels are\ntreated from a unifying perspective. Besides the stark rigidity of the\npolynomial transforms, we unveil an ubiquitous separation between discrete and\ncontinuous spectra of such inner fractional powers. Classical works of\nSchoenberg, Karlin, Hirschman, and Widder are completed by our classification.\nConcepts of probability theory, multivariate statistics, and group\nrepresentation theory naturally enter into the picture.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:08:07 GMT"},{"version":"v2","created":"Tue, 7 Jun 2022 16:47:51 GMT"},{"version":"v3","created":"Wed, 17 Aug 2022 18:48:05 GMT"}],"update_date":"2022-08-19"}
{"id":"2110.08207","submitter":"Albert Webson","authors":"Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang\n  Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao,\n  Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma\n  Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak,\n  Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo\n  Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas\n  Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault\n  Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao,\n  Thomas Wolf, Alexander M. Rush","title":"Multitask Prompted Training Enables Zero-Shot Task Generalization","comments":"ICLR 2022 Spotlight (with extended discussion)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models have recently been shown to attain reasonable zero-shot\ngeneralization on a diverse set of tasks (Brown et al., 2020). It has been\nhypothesized that this is a consequence of implicit multitask learning in\nlanguage models' pretraining (Radford et al., 2019). Can zero-shot\ngeneralization instead be directly induced by explicit multitask learning? To\ntest this question at scale, we develop a system for easily mapping any natural\nlanguage tasks into a human-readable prompted form. We convert a large set of\nsupervised datasets, each with multiple prompts with diverse wording. These\nprompted datasets allow for benchmarking the ability of a model to perform\ncompletely held-out tasks. We fine-tune a pretrained encoder-decoder model\n(Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a\nwide variety of tasks. The model attains strong zero-shot performance on\nseveral standard datasets, often outperforming models up to 16x its size.\nFurther, our approach attains strong performance on a subset of tasks from the\nBIG-bench benchmark, outperforming models up to 6x its size. All trained models\nare available at https://github.com/bigscience-workshop/t-zero and all prompts\nare available at https://github.com/bigscience-workshop/promptsource.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:08:57 GMT"},{"version":"v2","created":"Mon, 13 Dec 2021 03:31:00 GMT"},{"version":"v3","created":"Thu, 17 Mar 2022 17:53:01 GMT"}],"update_date":"2022-03-18"}
{"id":"2110.08208","submitter":"Xiaoping Zhu","authors":"Yanwen Luo, Tianqi Wu, Xiaoping Zhu","title":"The Convergence of Discrete Uniformizations for Genus Zero Surfaces","comments":"19 pages, 4 figures. Comments are welcomed!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The notion of discrete conformality proposed by Luo and\nBobenko-Pinkall-Springborn on triangle meshes has rich mathematical theories\nand wide applications. Gu et al. proved that the discrete uniformizations\napproximate the continuous uniformization for closed surfaces of genus $\\geq\n1$, given that the approximating triangle meshes are reasonably good. In this\npaper, we generalize this result to the remaining case of genus-zero surfaces,\nby reducing it to planar cases via stereographic projections.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:14:47 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08209","submitter":"Lisa Buchauer","authors":"Lisa Buchauer and Shalev Itzkovitz","title":"cellanneal: A User-Friendly Deconvolution Software for Omics Data","comments":"3 pages; for the cellanneal python package and general documentation\n  see https://github.com/LiBuchauer/cellanneal ; for the cellanneal graphical\n  user interface see http://shalevlab.weizmann.ac.il/resources/","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM q-bio.GN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce cellanneal, a python-based software for deconvolving bulk RNA\nsequencing data. cellanneal relies on the optimization of Spearman's rank\ncorrelation coefficient between experimental and computational mixture gene\nexpression vectors using simulated annealing. cellanneal can be used as a\npython package or via a command line interface, but importantly also provides a\nsimple graphical user interface which is distributed as a single executable\nfile for user convenience. The python package is available at\nhttps://github.com/LiBuchauer/cellanneal , the graphical software can be\ndownloaded at http://shalevlab.weizmann.ac.il/resources .\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:14:58 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08210","submitter":"Jianlong Lu","authors":"Jianlong Lu","title":"Comment on \"Flavor invariants and renormalization-group equations in the\n  leptonic sector with massive Majorana neutrinos\"","comments":"12 pages; one typo in page 2 has been corrected, thanks to Orlando L.\n  G. Peres and Peter B. Denton; this version draws heavily from\n  arXiv:2111.02729[hep-ph] for better information integration; published in\n  JHEP, submitted on 18 October 2021, accepted on 4 February 2022","journal-ref":"JHEP 02 (2022) 135","doi":"10.1007/JHEP02(2022)135","report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently in [JHEP 09 (2021) 053], Wang et al. discussed the polynomial ring\nformed by flavor invariants in the leptonic sector with massive Majorana\nneutrinos. They have explicitly constructed the finite generating sets of the\npolynomial rings for both two-generation scenario and three-generation\nscenario. However, Wang et al.'s claim of the finiteness of the generating sets\nof the polynomial rings and their calculation by the approach of Hilbert series\nwith generalized Molien-Weyl formula are both based on their assertion that the\nunitary group ${\\rm U}(n,\\mathbb{C})$ is reductive, which is unfortunately\nincorrect. The property of being reductive is only applicable to linear\nalgebraic groups. And it is well-known that the unitary group ${\\rm\nU}(n,\\mathbb{C})$ is not even a linear algebraic group. In this paper, we point\nout the above issue and provide a solution to fill in the accompanying logical\ngaps in [JHEP 09 (2021) 053]. Some important results from the theory of linear\nalgebraic group, the invariant theory of square matrices and group theory are\nneeded in the analysis. We also clarify some somewhat misleading or vague\nstatements in [JHEP 09 (2021) 053] about the scope of flavor invariants. Note\nthat, although built from incorrect assertion, Wang et al.'s calculation\nresults in [JHEP 09 (2021) 053] are nonetheless correct, which is ultimately\nbecause the ring of invariants of ${\\rm U}(n,\\mathbb{C})$ is isomorphic to that\nof ${\\rm GL}(n,\\mathbb{C})$ which is itself reductive.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:17:03 GMT"},{"version":"v2","created":"Mon, 18 Oct 2021 06:56:25 GMT"},{"version":"v3","created":"Mon, 7 Feb 2022 15:46:50 GMT"},{"version":"v4","created":"Mon, 21 Feb 2022 09:08:29 GMT"}],"update_date":"2022-02-22"}
{"id":"2110.08211","submitter":"Simone Riggi","authors":"S. Riggi, C. Bordiu, F. Vitello, G. Tudisco, E. Sciacca, D. Magro, R.\n  Sortino, C. Pino, M. Molinaro, M. Benedettini, S.Leurini, F. Bufano, M.\n  Raciti, U. Becciani","title":"Astronomical source finding services for the CIRASA visual analytic\n  platform","comments":"16 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM stat.CO stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Innovative developments in data processing, archiving, analysis, and\nvisualization are nowadays unavoidable to deal with the data deluge expected in\nnext-generation facilities for radio astronomy, such as the Square Kilometre\nArray (SKA) and its precursors. In this context, the integration of source\nextraction and analysis algorithms into data visualization tools could\nsignificantly improve and speed up the cataloguing process of large area\nsurveys, boosting astronomer productivity and shortening publication time. To\nthis aim, we are developing a visual analytic platform (CIRASA) for advanced\nsource finding and classification, integrating state-of-the-art tools, such as\nthe CAESAR source finder, the ViaLactea Visual Analytic (VLVA) and Knowledge\nBase (VLKB). In this work, we present the project objectives and the platform\narchitecture, focusing on the implemented source finding services.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:17:32 GMT"},{"version":"v2","created":"Mon, 18 Oct 2021 11:39:18 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08212","submitter":"Sarath Shekkizhar","authors":"Sarath Shekkizhar, Antonio Ortega","title":"NNK-Means: Data summarization using dictionary learning with\n  non-negative kernel regression","comments":"Preprint. To be published at the 30th European Signal Processing\n  Conference, EUSIPCO 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An increasing number of systems are being designed by gathering significant\namounts of data and then optimizing the system parameters directly using the\nobtained data. Often this is done without analyzing the dataset structure. As\ntask complexity, data size, and parameters all increase to millions or even\nbillions, data summarization is becoming a major challenge. In this work, we\ninvestigate data summarization via dictionary learning~(DL), leveraging the\nproperties of recently introduced non-negative kernel regression (NNK) graphs.\nOur proposed NNK-Means, unlike previous DL techniques, such as kSVD, learns\ngeometric dictionaries with atoms that are representative of the input data\nspace. Experiments show that summarization using NNK-Means can provide better\nclass separation compared to linear and kernel versions of kMeans and kSVD.\nMoreover, NNK-Means is scalable, with runtime complexity similar to that of\nkMeans.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:17:55 GMT"},{"version":"v2","created":"Mon, 13 Jun 2022 16:56:54 GMT"}],"update_date":"2022-06-14"}
{"id":"2110.08213","submitter":"Wen-Chin Huang","authors":"Wen-Chin Huang, Bence Mark Halpern, Lester Phillip Violeta, Odette\n  Scharenborg, Tomoki Toda","title":"Towards Identity Preserving Normal to Dysarthric Voice Conversion","comments":"Submitted to ICASSP 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS q-bio.QM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a voice conversion framework that converts normal speech into\ndysarthric speech while preserving the speaker identity. Such a framework is\nessential for (1) clinical decision making processes and alleviation of patient\nstress, (2) data augmentation for dysarthric speech recognition. This is an\nespecially challenging task since the converted samples should capture the\nseverity of dysarthric speech while being highly natural and possessing the\nspeaker identity of the normal speaker. To this end, we adopted a two-stage\nframework, which consists of a sequence-to-sequence model and a nonparallel\nframe-wise model. Objective and subjective evaluations were conducted on the\nUASpeech dataset, and results showed that the method was able to yield\nreasonable naturalness and capture severity aspects of the pathological speech.\nOn the other hand, the similarity to the normal source speaker's voice was\nlimited and requires further improvements.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:18:02 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08214","submitter":"Danni Liu","authors":"Danni Liu, Changhan Wang, Hongyu Gong, Xutai Ma, Yun Tang, Juan Pino","title":"From Start to Finish: Latency Reduction Strategies for Incremental\n  Speech Synthesis in Simultaneous Speech-to-Speech Translation","comments":"Accepted by Interspeech 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech-to-speech translation (S2ST) converts input speech to speech in\nanother language. A challenge of delivering S2ST in real time is the\naccumulated delay between the translation and speech synthesis modules. While\nrecently incremental text-to-speech (iTTS) models have shown large quality\nimprovements, they typically require additional future text inputs to reach\noptimal performance. In this work, we minimize the initial waiting time of iTTS\nby adapting the upstream speech translator to generate high-quality pseudo\nlookahead for the speech synthesizer. After mitigating the initial delay, we\ndemonstrate that the duration of synthesized speech also plays a crucial role\non latency. We formalize this as a latency metric and then present a simple yet\neffective duration-scaling approach for latency reduction. Our approaches\nconsistently reduce latency by 0.2-0.5 second without sacrificing speech\ntranslation quality.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:20:28 GMT"},{"version":"v2","created":"Tue, 29 Mar 2022 16:51:40 GMT"},{"version":"v3","created":"Fri, 15 Jul 2022 16:18:36 GMT"}],"update_date":"2022-07-18"}
{"id":"2110.08215","submitter":"Yidian Chen","authors":"Yidian Chen, Mei Huang","title":"Holographic QCD model for $N_f=4$","comments":null,"journal-ref":null,"doi":"10.1103/PhysRevD.105.026021","report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We establish a holographic QCD model for four flavors, where a light scalar\nfield $X$ and a heavy scalar field $H$ are introduced, separately. The $H$\nfield is responsible for the breaking of $SU(N_f=4)$ to $SU(N_f=3)$. The ground\nstate and its Regge excitation of meson spectra in the light flavor sector and\nheavy flavor sector as well as the ligh-heavy mesons are well in agreement with\nthe Particle data group (PDG). Due to the additional introduction of the $H$\nfield in the model, different Regge slopes for light and heavy mesons can be\nachieved.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:20:41 GMT"}],"update_date":"2022-02-02"}
{"id":"2110.08216","submitter":"Srinivasa Gopalakrishnan Ganga Prasath","authors":"Gaurav Chaudhary, S Ganga Prasath, Edward Soucy, and L Mahadevan","title":"Totimorphic assemblies from neutrally-stable units","comments":null,"journal-ref":"PNAS October 19, 2021 118 (42) e2107003118","doi":"10.1073/pnas.2107003118","report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Inspired by the quest for shape-shifting structures in a range of\napplications, we show how to create morphable structural materials using a\nneutrally stable unit cell as a building block. This unit cell is a\nself-stressed hinged structure with a one-parameter family of morphing motions\nthat are all energetically equivalent; however, unlike kinematic mechanisms, it\nis not infinitely floppy and instead exhibits a tunable mechanical response\nakin to that of an ideal rigid-plastic material. Theory and simulations allow\nus to explore the properties of planar and spatial assemblies of\nneutrally-stable elements and also pose and solve the inverse problem of\ndesigning assemblies that can morph from one given shape into another. Simple\nexperimental prototypes of these assemblies corroborate our theoretical results\nand show that the addition of switchable hinges allows us to create\nload-bearing structures. All together, totimorphs pave the way for structural\nmaterials whose geometry and deformation response can be controlled\nindependently and at multiple scales.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:23:06 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08217","submitter":"Alessio Benavoli","authors":"Alessio Benavoli and Dario Azzimonti and Dario Piga","title":"Choice functions based multi-objective Bayesian optimisation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we introduce a new framework for multi-objective Bayesian\noptimisation where the multi-objective functions can only be accessed via\nchoice judgements, such as ``I pick options A,B,C among this set of five\noptions A,B,C,D,E''. The fact that the option D is rejected means that there is\nat least one option among the selected ones A,B,C that I strictly prefer over D\n(but I do not have to specify which one). We assume that there is a latent\nvector function f for some dimension $n_e$ which embeds the options into the\nreal vector space of dimension n, so that the choice set can be represented\nthrough a Pareto set of non-dominated options. By placing a Gaussian process\nprior on f and deriving a novel likelihood model for choice data, we propose a\nBayesian framework for choice functions learning. We then apply this surrogate\nmodel to solve a novel multi-objective Bayesian optimisation from choice data\nproblem.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:24:03 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08218","submitter":"Riccardo Walter Maffucci","authors":"Riccardo W. Maffucci and Maurizia Rossi","title":"Asymptotic distribution of Nodal Intersections for ARW against a Surface","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate Gaussian Laplacian eigenfunctions (Arithmetic Random Waves) on\nthe three-dimensional standard flat torus, in particular the asymptotic\ndistribution of the nodal intersection length against a fixed regular reference\nsurface. Expectation and variance have been addressed by Maffucci (2019) who\nfound that the expected length is proportional to the square root of the\neigenvalue times the area of the surface, while the asymptotic variance only\ndepends on the geometry of the surface, the projected lattice points being\nequidistributed on the two-dimensional unit sphere in the high-energy limit. He\nalso noticed that there are ``special'' surfaces, so-called static, for which\nthe variance is of smaller order; however he did not prescribe the precise\nasymptotic law in this case. In this paper, we study second order fluctuations\nof the nodal intersection length. Our first main result is a Central Limit\nTheorem for ``generic'' surfaces, while for static ones, a sphere or a\nhemisphere e.g., our main results are a non-Central Limit Theorem and a precise\nasymptotic law for the variance of the nodal intersection length, conditioned\non the existence of so-called well-separated sequences of Laplacian\neigenvalues. It turns out that, in this regime, the nodal area investigated by\nCammarota (2019) is asymptotically fully correlated with the length of the\nnodal intersections against any sphere. The main ingredients for our proofs are\nthe Kac-Rice formula for moments, the chaotic decomposition for square\nintegrable functionals of Gaussian fields, and some arithmetic estimates that\nmay be of independent interest.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:25:13 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08219","submitter":"Rahul Tiwary","authors":"F. Abudin\\'en, I. Adachi, R. Adak, K. Adamczyk, L. Aggarwal, P.\n  Ahlburg, H. Ahmed, J. K. Ahn, H. Aihara, N. Akopov, A. Aloisio, F. Ameli, L.\n  Andricek, N. Anh Ky, D. M. Asner, H. Atmacan, V. Aulchenko, T. Aushev, V.\n  Aushev, T. Aziz, V. Babu, S. Bacher, H. Bae, S. Baehr, S. Bahinipati, A. M.\n  Bakich, P. Bambade, Sw. Banerjee, S. Bansal, M. Barrett, G. Batignani, J.\n  Baudot, M. Bauer, A. Baur, A. Beaulieu, J. Becker, P. K. Behera, J. V.\n  Bennett, E. Bernieri, F. U. Bernlochner, M. Bertemes, E. Bertholet, M.\n  Bessner, S. Bettarini, V. Bhardwaj, B. Bhuyan, F. Bianchi, T. Bilka, S.\n  Bilokin, D. Biswas, A. Bobrov, D. Bodrov, A. Bolz, A. Bondar, G. Bonvicini,\n  A. Bozek, M. Bra\\v{c}ko, P. Branchini, N. Braun, R. A. Briere, T. E. Browder,\n  D. N. Brown, A. Budano, L. Burmistrov, S. Bussino, M. Campajola, L. Cao, G.\n  Caria, G. Casarosa, C. Cecchi, D. \\v{C}ervenkov, M.-C. Chang, P. Chang, R.\n  Cheaib, V. Chekelian, C. Chen, Y. Q. Chen, Y.-T. Chen, B. G. Cheon, K.\n  Chilikin, K. Chirapatpimol, H.-E. Cho, K. Cho, S.-J. Cho, S.-K. Choi, S.\n  Choudhury, D. Cinabro, L. Corona, L. M. Cremaldi, D. Cuesta, S. Cunliffe, T.\n  Czank, N. Dash, F. Dattola, E. De La Cruz-Burelo, G. de Marino, G. De Nardo,\n  M. De Nuccio, G. De Pietro, R. de Sangro, B. Deschamps, M. Destefanis, S.\n  Dey, A. De Yta-Hernandez, A. Di Canto, F. Di Capua, S. Di Carlo, J.\n  Dingfelder, Z. Dole\\v{z}al, I. Dom\\'inguez Jim\\'enez, T. V. Dong, M. Dorigo,\n  K. Dort, D. Dossett, S. Dubey, S. Duell, G. Dujany, S. Eidelman, M.\n  Eliachevitch, D. Epifanov, J. E. Fast, T. Ferber, D. Ferlewicz, T. Fillinger,\n  G. Finocchiaro, S. Fiore, P. Fischer, A. Fodor, F. Forti, A. Frey, M. Friedl,\n  B. G. Fulsom, M. Gabriel, A. Gabrielli, N. Gabyshev, E. Ganiev, M.\n  Garcia-Hernandez, R. Garg, A. Garmash, V. Gaur, A. Gaz, U. Gebauer, A.\n  Gellrich, J. Gemmler, T. Ge{\\ss}ler, D. Getzkow, R. Giordano, A. Giri, A.\n  Glazov, B. Gobbo, R. Godang, P. Goldenzweig, B. Golob, P. Gomis, G. Gong, P.\n  Grace, W. Gradl, E. Graziani, D. Greenwald, T. Gu, Y. Guan, K. Gudkova, C.\n  Hadjivasiliou, S. Halder, K. Hara, T. Hara, O. Hartbrich, K. Hayasaka, H.\n  Hayashii, S. Hazra, C. Hearty, M. T. Hedges, I. Heredia de la Cruz, M. Hern\n  andez Villanueva, A. Hershenhorn, T. Higuchi, E. C. Hill, H. Hirata, M. Hoek,\n  M. Hohmann, S. Hollitt, T. Hotta, C.-L. Hsu, Y. Hu, K. Huang, T. Humair, T.\n  Iijima, K. Inami, G. Inguglia, J. Irakkathil Jabbar, A. Ishikawa, R. Itoh, M.\n  Iwasaki, Y. Iwasaki, S. Iwata, P. Jackson, W. W. Jacobs, I. Jaegle, D. E.\n  Jaffe, E.-J. Jang, M. Jeandron, H. B. Jeon, S. Jia, Y. Jin, C. Joo, K. K.\n  Joo, H. Junkerkalefeld, I. Kadenko, J. Kahn, H. Kakuno, A. B. Kaliyar, J.\n  Kandra, K. H. Kang, P. Kapusta, R. Karl, G. Karyan, Y. Kato, H. Kawai, T.\n  Kawasaki, C. Ketter, H. Kichimi, C. Kiesling, B. H. Kim, C.-H. Kim, D. Y.\n  Kim, H. J. Kim, K.-H. Kim, K. Kim, S.-H. Kim, Y.-K. Kim, Y. Kim, T. D.\n  Kimmel, H. Kindo, K. Kinoshita, C. Kleinwort, B. Knysh, P. Kody\\v{s}, T.\n  Koga, S. Kohani, I. Komarov, T. Konno, A. Korobov, S. Korpar, N. Kovalchuk,\n  E. Kovalenko, R. Kowalewski, T. M. G. Kraetzschmar, F. Krinner, P.\n  Kri\\v{z}an, R. Kroeger, J. F. Krohn, P. Krokovny, H. Kr\\\"uger, W. Kuehn, T.\n  Kuhr, J. Kumar, M. Kumar, R. Kumar, K. Kumara, T. Kumita, T. Kunigo, M.\n  K\\\"unzel, S. Kurz, A. Kuzmin, P. Kvasni\\v{c}ka, Y.-J. Kwon, S. Lacaprara,\n  Y.-T. Lai, C. La Licata, K. Lalwani, T. Lam, L. Lanceri, J. S. Lange, M.\n  Laurenza, K. Lautenbach, P. J. Laycock, F. R. Le Diberder, I.-S. Lee, S. C.\n  Lee, P. Leitl, D. Levit, P. M. Lewis, C. Li, L. K. Li, S. X. Li, Y. B. Li, J.\n  Libby, K. Lieret, J. Lin, Z. Liptak, Q. Y. Liu, Z. A. Liu, D. Liventsev, S.\n  Longo, A. Loos, A. Lozar, P. Lu, T. Lueck, F. Luetticke, T. Luo, C. Lyu, C.\n  MacQueen, Y. Maeda, M. Maggiora, S. Maity, R. Manfredi, E. Manoni, S.\n  Marcello, C. Marinas, A. Martini, M. Masuda, T. Matsuda, K. Matsuoka, D.\n  Matvienko, J. A. McKenna, J. McNeil, F. Meggendorfer, R. Mehta, J. C. Mei, F.\n  Meier, M. Merola, F. Metzner, M. Milesi, C. Miller, K. Miyabayashi, H.\n  Miyake, H. Miyata, R. Mizuk, K. Azmi, G. B. Mohanty, H. Moon, T. Moon, J. A.\n  Mora Grimaldo, T. Morii, H.-G. Moser, M. Mrvar, F. Mueller, F. J. M\\\"uller,\n  Th. Muller, G. Muroyama, C. Murphy, R. Mussa, I. Nakamura, K. R. Nakamura, E.\n  Nakano, M. Nakao, H. Nakayama, H. Nakazawa, Z. Natkaniec, A. Natochii, M.\n  Nayak, G. Nazaryan, D. Neverov, C. Niebuhr, M. Niiyama, J. Ninkovic, N. K.\n  Nisar, S. Nishida, K. Nishimura, M. Nishimura, M. H. A. Nouxman, B. Oberhof,\n  K. Ogawa, S. Ogawa, S. L. Olsen, Y. Onishchuk, H. Ono, Y. Onuki, P. Oskin, E.\n  R. Oxford, H. Ozaki, P. Pakhlov, G. Pakhlova, A. Paladino, T. Pang, A. Panta,\n  E. Paoloni, S. Pardi, H. Park, S.-H. Park, B. Paschen, A. Passeri, A. Pathak,\n  S. Patra, S. Paul, T. K. Pedlar, I. Peruzzi, R. Peschke, R. Pestotnik, F.\n  Pham, M. Piccolo, L. E. Piilonen, G. Pinna Angioni, P. L. M. Podesta-Lerma,\n  T. Podobnik, S. Pokharel, G. Polat, V. Popov, C. Praz, S. Prell, E. Prencipe,\n  M. T. Prim, M. V. Purohit, H. Purwar, N. Rad, P. Rados, S. Raiz, R. Rasheed,\n  M. Reif, S. Reiter, M. Remnev, P. K. Resmi, I. Ripp-Baudot, M. Ritter, M.\n  Ritzert, G. Rizzo, L. B. Rizzuto, S. H. Robertson, D. Rodr\\'iguez P\\'erez, J.\n  M. Roney, C. Rosenfeld, A. Rostomyan, N. Rout, M. Rozanska, G. Russo, D.\n  Sahoo, Y. Sakai, D. A. Sanders, S. Sandilya, A. Sangal, L. Santelj, P.\n  Sartori, Y. Sato, V. Savinov, B. Scavino, M. Schram, H. Schreeck, J.\n  Schueler, C. Schwanda, A. J. Schwartz, B. Schwenker, R. M. Seddon, Y. Seino,\n  A. Selce, K. Senyo, I. S. Seong, J. Serrano, M. E. Sevior, C. Sfienti, V.\n  Shebalin, C. P. Shen, H. Shibuya, J.-G. Shiu, B. Shwartz, A. Sibidanov, F.\n  Simon, J. B. Singh, S. Skambraks, K. Smith, R. J. Sobie, A. Soffer, A.\n  Sokolov, Y. Soloviev, E. Solovieva, S. Spataro, B. Spruck, M. Stari\\v{c}, S.\n  Stefkova, Z. S. Stottler, R. Stroili, J. Strube, J. Stypula, R. Sugiura, M.\n  Sumihama, K. Sumisawa, T. Sumiyoshi, D. J. Summers, W. Sutcliffe, K. Suzuki,\n  S. Y. Suzuki, H. Svidras, M. Tabata, M. Takahashi, M. Takizawa, U. Tamponi,\n  S. Tanaka, K. Tanida, H. Tanigawa, N. Taniguchi, Y. Tao, P. Taras, F.\n  Tenchini, R. Tiwary, D. Tonelli, E. Torassa, N. Toutounji, K. Trabelsi, T.\n  Tsuboyama, N. Tsuzuki, M. Uchida, I. Ueda, S. Uehara, Y. Uematsu, T. Ueno, T.\n  Uglov, K. Unger, Y. Unno, K. Uno, S. Uno, P. Urquijo, Y. Ushiroda, Y. V.\n  Usov, S. E. Vahsen, R. van Tonder, G. S. Varner, K. E. Varvell, A.\n  Vinokurova, L. Vitale, V. Vorobyev, A. Vossen, B. Wach, E. Waheed, H. M.\n  Wakeling, K. Wan, W. Wan Abdullah, B. Wang, C. H. Wang, E. Wang, M.-Z. Wang,\n  X. L. Wang, A. Warburton, M. Watanabe, S. Watanuki, J. Webb, S. Wehle, M.\n  Welsch, C. Wessel, J. Wiechczynski, P. Wieduwilt, H. Windel, E. Won, L. J.\n  Wu, X. P. Xu, B. D. Yabsley, S. Yamada, W. Yan, S. B. Yang, H. Ye, J. Yelton,\n  I. Yeo, J. H. Yin, M. Yonenaga, Y. M. Yook, K. Yoshihara, T. Yoshinobu, C. Z.\n  Yuan, G. Yuan, Y. Yusa, L. Zani, J. Z. Zhang, Y. Zhang, Z. Zhang, V. Zhilich,\n  J. Zhou, Q. D. Zhou, X. Y. Zhou, V. I. Zhukova, and V. Zhulanov","title":"Measurements of the branching fractions for $B \\to K^{*}\\gamma$ decays\n  at Belle II","comments":null,"journal-ref":null,"doi":null,"report-no":"BELLE2-CONF-PH-2021-014","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper reports a study of $B \\to K^{*}\\gamma$ decays using $62.8\\pm 0.6$\nfb$^{-1}$ of data collected during 2019--2020 by the Belle II experiment at the\nSuperKEKB $e^{+}e^{-}$ asymmetric-energy collider, corresponding to $(68.2 \\pm\n0.8) \\times 10^6$ $B\\overline{B}$ events. We find $454 \\pm 28$, $50 \\pm 10$,\n$169 \\pm 18$, and $160 \\pm 17$ signal events in the decay modes $B^{0} \\to\nK^{*0}[K^{+}\\pi^{-}]\\gamma$, $B^{0} \\to K^{*0}[K^0_{\\rm S}\\pi^{0}]\\gamma$,\n$B^{+} \\to K^{*+}[K^{+}\\pi^{0}]\\gamma$, and $B^{+} \\to\nK^{*+}[K^{+}\\pi^{0}]\\gamma$, respectively. The uncertainties quoted for the\nsignal yield are statistical only. We report the branching fractions of these\ndecays: $$\\mathcal{B} [B^{0} \\to K^{*0}[K^{+}\\pi^{-}]\\gamma] = (4.5 \\pm 0.3 \\pm\n0.2) \\times 10^{-5}, $$ $$\\mathcal{B} [B^{0} \\to K^{*0}[K^0_{\\rm\nS}\\pi^{0}]\\gamma] = (4.4 \\pm 0.9 \\pm 0.6) \\times 10^{-5},$$ $$\\mathcal{B}\n[B^{+} \\to K^{*+}[K^{+}\\pi^{0}]\\gamma] = (5.0 \\pm 0.5 \\pm 0.4)\\times\n10^{-5},\\text{ and}$$ $$\\mathcal{B} [B^{+} \\to K^{*+}[K^0_{\\rm\nS}\\pi^{+}]\\gamma] = (5.4 \\pm 0.6 \\pm 0.4) \\times 10^{-5},$$ where the first\nuncertainty is statistical, and the second is systematic. The results are\nconsistent with world-average values.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:30:33 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.08220","submitter":"Saachi Jain","authors":"Saachi Jain, Dimitris Tsipras, Aleksander Madry","title":"Combining Diverse Feature Priors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To improve model generalization, model designers often restrict the features\nthat their models use, either implicitly or explicitly. In this work, we\nexplore the design space of leveraging such feature priors by viewing them as\ndistinct perspectives on the data. Specifically, we find that models trained\nwith diverse sets of feature priors have less overlapping failure modes, and\ncan thus be combined more effectively. Moreover, we demonstrate that jointly\ntraining such models on additional (unlabeled) data allows them to correct each\nother's mistakes, which, in turn, leads to better generalization and resilience\nto spurious correlations. Code available at\nhttps://github.com/MadryLab/copriors\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:31:10 GMT"},{"version":"v2","created":"Thu, 14 Jul 2022 22:43:44 GMT"}],"update_date":"2022-07-18"}
{"id":"2110.08221","submitter":"Matthew Leinhauser","authors":"Matthew Leinhauser, Ren\\'e Widera, Sergei Bastrakov, Alexander Debus,\n  Michael Bussmann, Sunita Chandrasekaran","title":"Metrics and Design of an Instruction Roofline Model for AMD GPUs","comments":"14 pages, 7 figures, 2 tables, 4 equations, explains how to create an\n  instruction roofline model for an AMD GPU as of Oct. 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Due to the recent announcement of the Frontier supercomputer, many scientific\napplication developers are working to make their applications compatible with\nAMD architectures (CPU-GPU), which means moving away from the traditional CPU\nand NVIDIA-GPU systems. Due to the current limitations of profiling tools for\nAMD GPUs, this shift leaves a void in how to measure application performance on\nAMD GPUs. In this paper, we design an instruction roofline model for AMD GPUs\nusing AMD's ROCProfiler and a benchmarking tool, BabelStream (the HIP\nimplementation), as a way to measure an application's performance in\ninstructions and memory transactions on new AMD hardware. Specifically, we\ncreate instruction roofline models for a case study scientific application,\nPIConGPU, an open source particle-in-cell (PIC) simulations application used\nfor plasma and laser-plasma physics on the NVIDIA V100, AMD Radeon Instinct\nMI60, and AMD Instinct MI100 GPUs. When looking at the performance of multiple\nkernels of interest in PIConGPU we find that although the AMD MI100 GPU\nachieves a similar, or better, execution time compared to the NVIDIA V100 GPU,\nprofiling tool differences make comparing performance of these two\narchitectures hard. When looking at execution time, GIPS, and instruction\nintensity, the AMD MI60 achieves the worst performance out of the three GPUs\nused in this work.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:32:59 GMT"},{"version":"v2","created":"Wed, 10 Nov 2021 15:57:28 GMT"}],"update_date":"2021-11-11"}
{"id":"2110.08222","submitter":"Prakhar Gupta","authors":"Prakhar Gupta, Chien-Sheng Wu, Wenhao Liu and Caiming Xiong","title":"DialFact: A Benchmark for Fact-Checking in Dialogue","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fact-checking is an essential tool to mitigate the spread of misinformation\nand disinformation. We introduce the task of fact-checking in dialogue, which\nis a relatively unexplored area. We construct DialFact, a testing benchmark\ndataset of 22,245 annotated conversational claims, paired with pieces of\nevidence from Wikipedia. There are three sub-tasks in DialFact: 1) Verifiable\nclaim detection task distinguishes whether a response carries verifiable\nfactual information; 2) Evidence retrieval task retrieves the most relevant\nWikipedia snippets as evidence; 3) Claim verification task predicts a dialogue\nresponse to be supported, refuted, or not enough information. We found that\nexisting fact-checking models trained on non-dialogue data like FEVER fail to\nperform well on our task, and thus, we propose a simple yet data-efficient\nsolution to effectively improve fact-checking performance in dialogue. We point\nout unique challenges in DialFact such as handling the colloquialisms,\ncoreferences and retrieval ambiguities in the error analysis to shed light on\nfuture research in this direction.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:34:35 GMT"},{"version":"v2","created":"Thu, 24 Mar 2022 17:26:00 GMT"}],"update_date":"2022-03-25"}
{"id":"2110.08223","submitter":"Cheng Zhang","authors":"Pablo Morales-Alvarez, Wenbo Gong, Angus Lamb, Simon Woodhead, Simon\n  Peyton Jones, Nick Pawlowski, Miltiadis Allamanis, Cheng Zhang","title":"Simultaneous Missing Value Imputation and Structure Learning with Groups","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning structures between groups of variables from data with missing values\nis an important task in the real world, yet difficult to solve. One typical\nscenario is discovering the structure among topics in the education domain to\nidentify learning pathways. Here, the observations are student performances for\nquestions under each topic which contain missing values. However, most existing\nmethods focus on learning structures between a few individual variables from\nthe complete data. In this work, we propose VISL, a novel scalable structure\nlearning approach that can simultaneously infer structures between groups of\nvariables under missing data and perform missing value imputations with deep\nlearning. Particularly, we propose a generative model with a structured latent\nspace and a graph neural network-based architecture, scaling to a large number\nof variables. Empirically, we conduct extensive experiments on synthetic,\nsemi-synthetic, and real-world education data sets. We show improved\nperformances on both imputation and structure learning accuracy compared to\npopular and recent approaches.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:35:20 GMT"},{"version":"v2","created":"Thu, 24 Feb 2022 18:59:19 GMT"}],"update_date":"2022-02-25"}
{"id":"2110.08226","submitter":"Nihir Vedd","authors":"Nihir Vedd, Zixu Wang, Marek Rei, Yishu Miao and Lucia Specia","title":"Guiding Visual Question Generation","comments":"14 pages including references and Appendix. 3 figures and 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In traditional Visual Question Generation (VQG), most images have multiple\nconcepts (e.g. objects and categories) for which a question could be generated,\nbut models are trained to mimic an arbitrary choice of concept as given in\ntheir training data. This makes training difficult and also poses issues for\nevaluation -- multiple valid questions exist for most images but only one or a\nfew are captured by the human references. We present Guiding Visual Question\nGeneration - a variant of VQG which conditions the question generator on\ncategorical information based on expectations on the type of question and the\nobjects it should explore. We propose two variants: (i) an explicitly guided\nmodel that enables an actor (human or automated) to select which objects and\ncategories to generate a question for; and (ii) an implicitly guided model that\nlearns which objects and categories to condition on, based on discrete latent\nvariables. The proposed models are evaluated on an answer-category augmented\nVQA dataset and our quantitative results show a substantial improvement over\nthe current state of the art (over 9 BLEU-4 increase). Human evaluation\nvalidates that guidance helps the generation of questions that are\ngrammatically coherent and relevant to the given image and objects.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:38:08 GMT"},{"version":"v2","created":"Mon, 15 Nov 2021 18:26:44 GMT"},{"version":"v3","created":"Tue, 26 Jul 2022 14:22:13 GMT"}],"update_date":"2022-07-27"}
{"id":"2110.08227","submitter":"Ryan Budney","authors":"Ryan Budney, Tomasz Kaczynski","title":"Bi-filtrations and persistence paths for 2-Morse functions","comments":"23 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the homotopy-type of bi-filtrations of compact manifolds\ninduced as the pre-image of filtrations of the plane for generic smooth\nfunctions f : M --> R^2. The primary goal of the paper is to allow for a simple\ndescription of the multi-graded persistent homology associated to such\nfiltrations. The main result of the paper is a description of the evolution of\nthe bi-filtration of f in terms of cellular attachments. An analogy of\nMorse-Conley equation and Morse inequalities along so called persistence paths\nare derived. A scheme for computing path-wise barcodes is proposed.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:38:09 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08228","submitter":"Maya Varma","authors":"Maya Varma, Laurel Orr, Sen Wu, Megan Leszczynski, Xiao Ling,\n  Christopher R\\'e","title":"Cross-Domain Data Integration for Named Entity Disambiguation in\n  Biomedical Text","comments":"Accepted to Findings of EMNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Named entity disambiguation (NED), which involves mapping textual mentions to\nstructured entities, is particularly challenging in the medical domain due to\nthe presence of rare entities. Existing approaches are limited by the presence\nof coarse-grained structural resources in biomedical knowledge bases as well as\nthe use of training datasets that provide low coverage over uncommon resources.\nIn this work, we address these issues by proposing a cross-domain data\nintegration method that transfers structural knowledge from a general text\nknowledge base to the medical domain. We utilize our integration scheme to\naugment structural resources and generate a large biomedical NED dataset for\npretraining. Our pretrained model with injected structural knowledge achieves\nstate-of-the-art performance on two benchmark medical NED datasets: MedMentions\nand BC5CDR. Furthermore, we improve disambiguation of rare entities by up to 57\naccuracy points.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:38:16 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08230","submitter":"Mukkattu Omanakuttan Ajeesh","authors":"M. O. Ajeesh, S. M. Thomas, S. K. Kushwaha, E. D. Bauer, F. Ronning,\n  J. D. Thompson, N. Harrison, and P. F. S. Rosa","title":"Ground state of Ce$_{3}$Bi$_{4}$Pd$_{3}$ unraveled by hydrostatic\n  pressure","comments":"6 pages, 4 Figures, includes Supplementary Information (6 pages, 5\n  Figures)","journal-ref":"Phys. Rev. B 106, L161105 (2022)","doi":"10.1103/PhysRevB.106.L161105","report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Noncentrosymmetric Ce$_{3}$Bi$_{4}$Pd$_{3}$ has attracted a lot of attention\nas a candidate for strongly correlated topological material, yet its\nexperimental ground state remains a matter of contention. Two conflicting\nscenarios have emerged from a comparison to prototypical Kondo insulator\nCe$_{3}$Bi$_{4}$Pt$_{3}$: either Ce$_{3}$Bi$_{4}$Pd$_{3}$ is a\nspin-orbit-driven topological semimetal or a Kondo insulator with smaller Kondo\ncoupling than its Pt counterpart. Here we determine the ground state of\nCe$_{3}$Bi$_{4}$Pd$_{3}$ via electrical resistivity measurements under\nhydrostatic pressure, which is a clean symmetry-preserving tuning parameter\nthat increases hybridization but virtually preserves spin-orbit coupling.\nCe$_{3}$Bi$_{4}$Pd$_{3}$ becomes more insulating under pressure, which is a\nsignature of Ce-based Kondo insulating materials. Its small zero-pressure gap\nincreases quadratically with pressure, similar to the behavior observed in the\nseries Ce$_{3}$Bi$_{4}$(Pt$_{1-x}$Pd$_{x}$)$_{3}$, which indicates that Pt\nsubstitution and applied pressure have a similar effect. Our result not only\ndemonstrates that Kondo coupling, rather than spin-orbit coupling, is the main\ntuning parameter in this class of materials, but it also establishes that\nCe$_{3}$Bi$_{4}$Pd$_{3}$ has a narrow-gap Kondo insulating ground state.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:39:30 GMT"}],"update_date":"2022-11-18"}
{"id":"2110.08231","submitter":"Dennis Bonatsos","authors":"Dennis Bonatsos, Andriana Martinou, I.E. Assimakis, S.K. Peroulis, S.\n  Sarantopoulou, and N. Minkov","title":"Unified picture of nucleon pairs playing leading roles in nuclear\n  collectivity","comments":"10 pages, to appear in the Proceedings of the workshop on Shapes and\n  Dynamics of Atomic Nuclei: Contemporary Aspects (SDANCA21), Sofia, Bulgaria,\n  16-18 September 2021, ed. N. Minkov. arXiv admin note: substantial text\n  overlap with arXiv:2107.08993","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Proxy-SU(3) symmetry is an approximation scheme extending the Elliott SU(3)\nalgebra of the sd shell to heavier shells. When introduced in 2017, the\napproximation had been justified by calculations carried out within the Nilsson\nmodel, with nucleon pairs differing by $\\Delta K [\\Delta N \\Delta n_z \\Delta\n\\Lambda]=0[110]$ in the Nilsson quantum numbers playing a major role in the\napproximation. Recently our group managed to map the cartesian basis of the\nElliott SU(3) model onto the spherical shell model basis, fully clarifying the\napproximations used within the proxy-SU(3) scheme and paving the way for using\nthe proxy-SU(3) approximation in shell model calculations for heavy nuclei. As\na by-product, the relation of the 0[110] Nilsson pairs used in proxy-SU(3) to\nthe earlier used de Shalit-Goldhaber pairs $|\\Delta n \\Delta l \\Delta j \\Delta\nm_j\\rangle = | 0110\\rangle$ in spherical shell model notation is clarified,\nwhile the Federman-Pittel (FP) pairs known to play a major role at the onset of\ndeformation are identified as $| 0010\\rangle$ pairs, and the FP pairs further\nincreasing the deformation after its onset are found to be $| 0110\\rangle$\npairs, i.e. identical to the de-Shalit-Goldhaber pairs. The connection between\nthe proxy-SU(3) scheme and the spherical shell model has also been worked out\nin the original framework of the Nilsson model, with identical results.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:39:36 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08232","submitter":"Sara Elkerdawy","authors":"Sara Elkerdawy, Mostafa Elhoushi, Hong Zhang, Nilanjan Ray","title":"Fire Together Wire Together: A Dynamic Pruning Approach with\n  Self-Supervised Mask Prediction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dynamic model pruning is a recent direction that allows for the inference of\na different sub-network for each input sample during deployment. However,\ncurrent dynamic methods rely on learning a continuous channel gating through\nregularization by inducing sparsity loss. This formulation introduces\ncomplexity in balancing different losses (e.g task loss, regularization loss).\nIn addition, regularization based methods lack transparent tradeoff\nhyperparameter selection to realize a computational budget. Our contribution is\ntwo-fold: 1) decoupled task and pruning losses. 2) Simple hyperparameter\nselection that enables FLOPs reduction estimation before training. Inspired by\nthe Hebbian theory in Neuroscience: \"neurons that fire together wire together\",\nwe propose to predict a mask to process k filters in a layer based on the\nactivation of its previous layer. We pose the problem as a self-supervised\nbinary classification problem. Each mask predictor module is trained to predict\nif the log-likelihood for each filter in the current layer belongs to the top-k\nactivated filters. The value k is dynamically estimated for each input based on\na novel criterion using the mass of heatmaps. We show experiments on several\nneural architectures, such as VGG, ResNet and MobileNet on CIFAR and ImageNet\ndatasets. On CIFAR, we reach similar accuracy to SOTA methods with 15% and 24%\nhigher FLOPs reduction. Similarly in ImageNet, we achieve lower drop in\naccuracy with up to 13% improvement in FLOPs reduction.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:39:53 GMT"},{"version":"v2","created":"Fri, 5 Nov 2021 16:40:55 GMT"},{"version":"v3","created":"Tue, 28 Jun 2022 17:01:43 GMT"},{"version":"v4","created":"Wed, 29 Jun 2022 01:40:15 GMT"}],"update_date":"2022-06-30"}
{"id":"2110.08233","submitter":"Laura Schaposnik","authors":"Sheryl Hsu, Fidel I. Schaposnik Massolo and Laura P. Schaposnik","title":"The Power of Many: A Physarum Swarm Steiner Tree Algorithm","comments":"25 images, 12 pages","journal-ref":"Nature Sci Rep 12, 14536 (2022)","doi":"10.1038/s41598-022-18316-3","report-no":null,"categories":"physics.bio-ph cs.NE math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We create a novel Physarum Steiner algorithm designed to solve the Euclidean\nSteiner tree problem. Physarum is a unicellular slime mold with the ability to\nform networks and fuse with other Physarum organisms. We use the simplicity and\nfusion of Physarum to create large swarms which independently operate to solve\nthe Steiner problem. The Physarum Steiner tree algorithm then utilizes a swarm\nof Physarum organisms which gradually find terminals and fuse with each other,\nsharing intelligence. The algorithm is also highly capable of solving the\nobstacle avoidance Steiner tree problem and is a strong alternative to the\ncurrent leading algorithm. The algorithm is of particular interest due to its\nnovel approach, rectilinear properties, and ability to run on varying shapes\nand topological surfaces.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:41:33 GMT"}],"update_date":"2022-10-18"}
{"id":"2110.08234","submitter":"Alexey Melnikov","authors":"A. A. Melnikov, V. E. Anikeeva, O. I. Semenova, S. V. Chekalin","title":"Terahertz Kerr effect in a methylammonium lead bromide perovskite\n  crystal","comments":"8 pages, 4 figures","journal-ref":"Phys. Rev. B 105, 174304 (2022)","doi":"10.1103/PhysRevB.105.174304","report-no":null,"categories":"cond-mat.mtrl-sci physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have observed short-lived optical birefringence in a CH$_3$NH$_3$PbBr$_3$\nsingle crystal induced by a powerful nearly single-cycle terahertz pulse. Apart\nfrom the instantaneous contribution that follows the profile of the squared\npump electric field, the recorded anisotropy signal contains an exponential\ncomponent decaying in $\\sim$ 350 fs, underdamped oscillations at the frequency\nof $\\sim$ 0.16 THz and an intermediate picosecond relaxation process with a\nGaussian tail. We associate these three non-trivial features with,\nrespectively, Kerr effect in the inorganic lattice, terahertz-induced transient\nalignment of CH$_3$NH$_3^+$ cations, and their coherent rotation excited by the\nterahertz pulse in a Raman process.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:42:09 GMT"},{"version":"v2","created":"Mon, 13 Dec 2021 17:10:12 GMT"},{"version":"v3","created":"Sun, 8 May 2022 23:22:40 GMT"}],"update_date":"2022-05-10"}
{"id":"2110.08235","submitter":"Roman Kozlov","authors":"Vladimir A. Dorodnitsyn, Evgeniy I. Kaptsov, Roman V. Kozlov, Sergey\n  V. Meleshko, Potcharapol Mukdasanit","title":"Plane one-dimensional MHD flows: symmetries and conservation laws","comments":null,"journal-ref":null,"doi":"10.1016/j.ijnonlinmec.2021.103899","report-no":null,"categories":"math-ph math.MP physics.flu-dyn","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The paper considers the plane one-dimensional flows for magnetohydrodynamics\nin the mass Lagrangian coordinates. The inviscid, thermally non-conducting\nmedium is modeled by a polytropic gas. The equations are examined for\nsymmetries and conservation laws. For the case of the finite electric\nconductivity we establish Lie group classification, i.e. we describe all cases\nof the conductivity $ \\sigma ( \\rho , p)$ for which there are symmetry\nextensions. The conservation laws are derived by the direct computation. For\nthe case of the infinite electrical conductivity the equations can be brought\ninto a variational form in the Lagrangian coordinates. Lie group classification\nis performed for the entropy function as an arbitrary element. Using the\nvariational structure, we employ the Noether theorem for obtaining conservation\nlaws. The conservation laws are also given in the physical variables.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:43:32 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 14:45:02 GMT"}],"update_date":"2022-02-23"}
{"id":"2110.08236","submitter":"Herwig Hauser","authors":"Herwig Hauser, Sebastian Woblistin","title":"Arquile varieties -- varieties consisting of power series in a single\n  variable","comments":"To appear in Forum Math:Sigma. 41 pages, including table of symbols","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.AC math.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Arquile varieties are zerosets of polynomial, algebraic, analytic, or formal\nequations f(t,y_1,...,y_m) = 0 with solutions y(t) = (y_1(t),...,y_m(t)) in\naffine m-space over an algebraic, convergent or formal power series ring k<t>,\nk{t}, or k[[t]]. As such they generalize the concept of the arc space of an\nalgebraic variety.\n  In the article, the geometry of arquile varieties is studied in detail. Among\nother things, it is shown that, after a suitable stratification, their\nsingularities, once defined appropriately, are confined to a finite dimensional\npart. The main technique to do this is to combine, as is standard in the theory\nof arc spaces, tools from algebraic geometry and commutative algebra with the\nadditional knowledge that the points of arquile varieties are not just abstract\nobjects (as they are in classical algebraic and analytic geometry) but concrete\npower series having their proper series expansion.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:45:10 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08237","submitter":"Leonid Positselski","authors":"Leonid Positselski","title":"Exact DG-categories and fully faithful triangulated inclusion functors","comments":"LaTeX 2e with xy-pic, 151 pages, 53 commutative diagrams; v.6:\n  Section 9 added -- this is intended as a complete version; v.9: Examples 3.2\n  and 3.3 expanded, proof of Lemma 6.10(b) partly rewritten, explanations and\n  details added in Examples 3.15 and in proofs of Lemmas 8.3 and 9.18, Remark\n  9.43 inserted, many references added, many misprints corrected","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CT math.AG math.RA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We construct an \"almost involution\" assigning a new DG-category to a given\none, and use this construction in order to recover, say, the abelian category\nof graded modules over the graded ring $R^*$ from the DG-category of DG-modules\nover a DG-ring $(R^*,d)$. This provides an appropriate technical background for\nthe definition and discussion of abelian and exact DG-categories. In the\nsetting of exact DG-categories, derived categories of the second kind are\ndefined in the maximal natural generality. We develop the related abstract\ncategory-theoretic language and use it in order to formulate and prove several\nfull-and-faithfulness theorems for triangulated functors induced by the\ninclusions of fully exact DG-subcategories. Such functors are fully faithful\nfor derived categories of the second kind more often than for the conventional\nderived categories. Examples and applications range from the categories of\ncomplexes in abelian/exact categories to matrix factorization categories, and\nfrom curved DG-modules over curved DG-rings to quasi-coherent CDG-modules over\nquasi-coherent CDG-quasi-algebras over schemes.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:45:53 GMT"},{"version":"v2","created":"Fri, 8 Apr 2022 15:29:27 GMT"},{"version":"v3","created":"Tue, 19 Apr 2022 13:56:11 GMT"},{"version":"v4","created":"Tue, 26 Apr 2022 09:18:49 GMT"},{"version":"v5","created":"Wed, 4 May 2022 10:43:10 GMT"},{"version":"v6","created":"Tue, 10 May 2022 12:00:22 GMT"},{"version":"v7","created":"Tue, 17 May 2022 16:49:17 GMT"},{"version":"v8","created":"Wed, 18 May 2022 15:42:45 GMT"},{"version":"v9","created":"Mon, 12 Dec 2022 20:30:35 GMT"}],"update_date":"2022-12-14"}
{"id":"2110.08238","submitter":"Hyunchul Park","authors":"Hyunchul Park and Yimin Xiao","title":"Spectral heat content on a class of fractal sets for subordinate killed\n  Brownian motions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the spectral heat content for a class of open sets with fractal\nboundaries determined by similitudes in $\\mathbb{R}^{d}$, $d\\geq 1$, with\nrespect to subordinate killed Brownian motions via $\\alpha/2$-stable\nsubordinators and establish the asymptotic behavior of the spectral heat\ncontent as $t\\to 0$ for the full range of $\\alpha\\in (0,2)$. Our main theorems\nshow that these asymptotic behaviors depend on whether the sequence of\nlogarithms of the coefficients of the similitudes is arithmetic when $\\alpha\\in\n[d-\\b,2)$, where $\\b$ is the interior Minkowski dimension of the boundary of\nthe open set. The main tools for proving the theorems are the previous results\non the spectral heat content for Brownian motions and the renewal theorem.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:46:19 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08239","submitter":"Weiyao Wang","authors":"Weiyao Wang, Marin Kobilarov and Gregory D. Hager","title":"Learn Proportional Derivative Controllable Latent Space from Pixels","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent advances in latent space dynamics model from pixels show promising\nprogress in vision-based model predictive control (MPC). However, executing MPC\nin real time can be challenging due to its intensive computational cost in each\ntimestep. We propose to introduce additional learning objectives to enforce\nthat the learned latent space is proportional derivative controllable. In\nexecution time, the simple PD-controller can be applied directly to the latent\nspace encoded from pixels, to produce simple and effective control to systems\nwith visual observations. We show that our method outperforms baseline methods\nto produce robust goal reaching and trajectory tracking in various\nenvironments.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:47:07 GMT"},{"version":"v2","created":"Sun, 5 Feb 2023 20:47:15 GMT"}],"update_date":"2023-02-07"}
{"id":"2110.08240","submitter":"Robert Mattias Granberg Olsson","authors":"Mattias Granberg Olsson (1), Graham E. Leigh (1) ((1) University of\n  Gothenburg)","title":"Revisiting the conservativity of fixpoints over intuitionistic\n  arithmetic","comments":"24 pages, 0 figures; v2: added and emphasized references in section\n  1, added reference in section 5.2; v3: corrected notational error in theorem\n  4.9 and removed unused notations in definition 4.7, corrected some typos","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents a novel proof of the conservativity of the intuitionistic\ntheory of strictly positive fixpoints,\n$\\widehat{\\mathrm{ID}}{}_{1}^{\\mathrm{i}}$, over Heyting arithmetic (HA),\noriginally proved in full generality by Arai (2011). The proof embeds\n$\\widehat{\\mathrm{ID}}{}_{1}^{\\mathrm{i}}$ into the corresponding theory over\nBeeson's logic of partial terms and then uses two consecutive interpretations,\na realizability interpretation of this theory into the subtheory generated by\nalmost negative fixpoints, and a direct interpretation into Heyting arithmetic\nwith partial terms using a hierarchy of satisfaction predicates for almost\nnegative formulae. It concludes by applying van den Berg and van Slooten's\nresult (2018) that Heyting arithmetic with partial terms plus the schema of\nself realizability for arithmetic formulae is conservative over HA.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:50:47 GMT"},{"version":"v2","created":"Fri, 5 Nov 2021 11:05:09 GMT"},{"version":"v3","created":"Tue, 21 Dec 2021 15:50:16 GMT"}],"update_date":"2021-12-22"}
{"id":"2110.08241","submitter":"Hiun Kim","authors":"Hiun Kim, Jisu Jeong, Kyung-Min Kim, Dongjun Lee, Hyun Dong Lee,\n  Dongpil Seo, Jeeseung Han, Dong Wook Park, Ji Ae Heo, Rak Yeong Kim","title":"Intent-based Product Collections for E-commerce using Pretrained\n  Language Models","comments":"Accepted to IEEE International Workshop on Data Mining for Service\n  (DMS2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Building a shopping product collection has been primarily a human job. With\nthe manual efforts of craftsmanship, experts collect related but diverse\nproducts with common shopping intent that are effective when displayed\ntogether, e.g., backpacks, laptop bags, and messenger bags for freshman bag\ngifts. Automatically constructing a collection requires an ML system to learn a\ncomplex relationship between the customer's intent and the product's\nattributes. However, there have been challenging points, such as 1) long and\ncomplicated intent sentences, 2) rich and diverse product attributes, and 3) a\nhuge semantic gap between them, making the problem difficult. In this paper, we\nuse a pretrained language model (PLM) that leverages textual attributes of\nweb-scale products to make intent-based product collections. Specifically, we\ntrain a BERT with triplet loss by setting an intent sentence to an anchor and\ncorresponding products to positive examples. Also, we improve the performance\nof the model by search-based negative sampling and category-wise positive pair\naugmentation. Our model significantly outperforms the search-based baseline\nmodel for intent-based product matching in offline evaluations. Furthermore,\nonline experimental results on our e-commerce platform show that the PLM-based\nmethod can construct collections of products with increased CTR, CVR, and\norder-diversity compared to expert-crafted collections.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:52:42 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08242","submitter":"Kristine Heiney","authors":"J{\\o}rgen Jensen Farner, H{\\aa}kon Weydahl, Ruben Jahren, Ola Huse\n  Ramstad, Stefano Nichele, Kristine Heiney","title":"Evolving spiking neuron cellular automata and networks to emulate in\n  vitro neuronal activity","comments":"To be published in proceedings of IEEE SSCI 2021 as part of ICES\n  symposium (International Conference on Evolvable Systems, IEEE Symposium\n  Series on Computational Intelligence 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neuro-inspired models and systems have great potential for applications in\nunconventional computing. Often, the mechanisms of biological neurons are\nmodeled or mimicked in simulated or physical systems in an attempt to harness\nsome of the computational power of the brain. However, the biological\nmechanisms at play in neural systems are complicated and challenging to capture\nand engineer; thus, it can be simpler to turn to a data-driven approach to\ntransfer features of neural behavior to artificial substrates. In the present\nstudy, we used an evolutionary algorithm (EA) to produce spiking neural systems\nthat emulate the patterns of behavior of biological neurons in vitro. The aim\nof this approach was to develop a method of producing models capable of\nexhibiting complex behavior that may be suitable for use as computational\nsubstrates. Our models were able to produce a level of network-wide synchrony\nand showed a range of behaviors depending on the target data used for their\nevolution, which was from a range of neuronal culture densities and maturities.\nThe genomes of the top-performing models indicate the excitability and density\nof connections in the model play an important role in determining the\ncomplexity of the produced activity.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:55:04 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08243","submitter":"Chenxu Hu","authors":"Chenxu Hu, Qiao Tian, Tingle Li, Yuping Wang, Yuxuan Wang, Hang Zhao","title":"Neural Dubber: Dubbing for Videos According to Scripts","comments":"Accepted by NeurIPS 2021; Project page at\n  https://tsinghua-mars-lab.github.io/NeuralDubber/","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.CV cs.LG cs.SD eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dubbing is a post-production process of re-recording actors' dialogues, which\nis extensively used in filmmaking and video production. It is usually performed\nmanually by professional voice actors who read lines with proper prosody, and\nin synchronization with the pre-recorded videos. In this work, we propose\nNeural Dubber, the first neural network model to solve a novel automatic video\ndubbing (AVD) task: synthesizing human speech synchronized with the given video\nfrom the text. Neural Dubber is a multi-modal text-to-speech (TTS) model that\nutilizes the lip movement in the video to control the prosody of the generated\nspeech. Furthermore, an image-based speaker embedding (ISE) module is developed\nfor the multi-speaker setting, which enables Neural Dubber to generate speech\nwith a reasonable timbre according to the speaker's face. Experiments on the\nchemistry lecture single-speaker dataset and LRS2 multi-speaker dataset show\nthat Neural Dubber can generate speech audios on par with state-of-the-art TTS\nmodels in terms of speech quality. Most importantly, both qualitative and\nquantitative evaluations show that Neural Dubber can control the prosody of\nsynthesized speech by the video, and generate high-fidelity speech temporally\nsynchronized with the video. Our project page is at\nhttps://tsinghua-mars-lab.github.io/NeuralDubber/ .\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:56:07 GMT"},{"version":"v2","created":"Tue, 16 Nov 2021 16:41:40 GMT"},{"version":"v3","created":"Tue, 15 Mar 2022 14:37:46 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08244","submitter":"Ryan Jacobs","authors":"Ryan Jacobs, Mingren Shen, Yuhan Liu, Wei Hao, Xiaoshan Li, Ruoyu He,\n  Jacob RC Greaves, Donglin Wang, Zeming Xie, Zitong Huang, Chao Wang, Kevin G.\n  Field, Dane Morgan","title":"Performance, Successes and Limitations of Deep Learning Semantic\n  Segmentation of Multiple Defects in Transmission Electron Micrographs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we perform semantic segmentation of multiple defect types in\nelectron microscopy images of irradiated FeCrAl alloys using a deep learning\nMask Regional Convolutional Neural Network (Mask R-CNN) model. We conduct an\nin-depth analysis of key model performance statistics, with a focus on\nquantities such as predicted distributions of defect shapes, defect sizes, and\ndefect areal densities relevant to informing modeling and understanding of\nirradiated Fe-based materials properties. To better understand the performance\nand present limitations of the model, we provide examples of useful evaluation\ntests which include a suite of random splits, and dataset size-dependent and\ndomain-targeted cross validation tests. Overall, we find that the current model\nis a fast, effective tool for automatically characterizing and quantifying\nmultiple defect types in microscopy images, with a level of accuracy on par\nwith human domain expert labelers. More specifically, the model can achieve\naverage defect identification F1 scores as high as 0.8, and, based on random\ncross validation, have low overall average (+/- standard deviation) defect size\nand density percentage errors of 7.3 (+/- 3.8)% and 12.7 (+/- 5.3)%,\nrespectively. Further, our model predicts the expected material hardening to\nwithin 10-20 MPa (about 10% of total hardening), which is about the same error\nlevel as experiments. Our targeted evaluation tests also suggest the best path\ntoward improving future models is not expanding existing databases with more\nlabeled images but instead data additions that target weak points of the model\ndomain, such as images from different microscopes, imaging conditions,\nirradiation environments, and alloy types. Finally, we discuss the first phase\nof an effort to provide an easy-to-use, open-source object detection tool to\nthe broader community for identifying defects in new images.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:57:59 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08245","submitter":"Joao Goncalves","authors":"Sanjeeb Dash and Joao Goncalves","title":"Rule Induction in Knowledge Graphs Using Linear Programming","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a simple linear programming (LP) based method to learn compact and\ninterpretable sets of rules encoding the facts in a knowledge graph (KG) and\nuse these rules to solve the KG completion problem. Our LP model chooses a set\nof rules of bounded complexity from a list of candidate first-order logic rules\nand assigns weights to them. The complexity bound is enforced via explicit\nconstraints. We combine simple rule generation heuristics with our rule\nselection LP to obtain predictions with accuracy comparable to state-of-the-art\ncodes, even while generating much more compact rule sets. Furthermore, when we\ntake as input rules generated by other codes, we often improve interpretability\nby reducing the number of chosen rules, while maintaining accuracy.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:58:16 GMT"},{"version":"v2","created":"Fri, 3 Mar 2023 21:33:16 GMT"}],"update_date":"2023-03-07"}
{"id":"2110.08246","submitter":"Dheeru Dua","authors":"Dheeru Dua, Shruti Bhosale, Vedanuj Goswami, James Cross, Mike Lewis,\n  Angela Fan","title":"Tricks for Training Sparse Translation Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Multi-task learning with an unbalanced data distribution skews model learning\ntowards high resource tasks, especially when model capacity is fixed and fully\nshared across all tasks. Sparse scaling architectures, such as BASELayers,\nprovide flexible mechanisms for different tasks to have a variable number of\nparameters, which can be useful to counterbalance skewed data distributions. We\nfind that that sparse architectures for multilingual machine translation can\nperform poorly out of the box, and propose two straightforward techniques to\nmitigate this - a temperature heating mechanism and dense pre-training.\nOverall, these methods improve performance on two multilingual translation\nbenchmarks compared to standard BASELayers and Dense scaling baselines, and in\ncombination, more than 2x model convergence speed.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:58:45 GMT"}],"update_date":"2021-10-18"}
{"id":"2110.08247","submitter":"Yangyi Chen","authors":"Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu, Maosong Sun","title":"Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks","comments":"Accepted to EMNLP 2022, main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Backdoor attacks are a kind of emergent security threat in deep learning.\nAfter being injected with a backdoor, a deep neural model will behave normally\non standard inputs but give adversary-specified predictions once the input\ncontains specific backdoor triggers. In this paper, we find two simple tricks\nthat can make existing textual backdoor attacks much more harmful. The first\ntrick is to add an extra training task to distinguish poisoned and clean data\nduring the training of the victim model, and the second one is to use all the\nclean training data rather than remove the original clean data corresponding to\nthe poisoned data. These two tricks are universally applicable to different\nattack models. We conduct experiments in three tough situations including clean\ndata fine-tuning, low-poisoning-rate, and label-consistent attacks.\nExperimental results show that the two tricks can significantly improve attack\nperformance. This paper exhibits the great potential harmfulness of backdoor\nattacks. All the code and data can be obtained at\n\\url{https://github.com/thunlp/StyleAttack}.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:58:46 GMT"},{"version":"v2","created":"Wed, 19 Oct 2022 15:37:47 GMT"}],"update_date":"2022-10-20"}
{"id":"2110.08248","submitter":"David R\\\"ugamer","authors":"David R\\\"ugamer, Philipp F.M. Baumann, Thomas Kneib, Torsten Hothorn","title":"Probabilistic Time Series Forecasts with Autoregressive Transformation\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Probabilistic forecasting of time series is an important matter in many\napplications and research fields. In order to draw conclusions from a\nprobabilistic forecast, we must ensure that the model class used to approximate\nthe true forecasting distribution is expressive enough. Yet, characteristics of\nthe model itself, such as its uncertainty or its feature-outcome relationship\nare not of lesser importance. This paper proposes Autoregressive Transformation\nModels (ATMs), a model class inspired by various research directions to unite\nexpressive distributional forecasts using a semi-parametric distribution\nassumption with an interpretable model specification. We demonstrate the\nproperties of ATMs both theoretically and through empirical evaluation on\nseveral simulated and real-world forecasting datasets.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:58:49 GMT"},{"version":"v2","created":"Mon, 14 Feb 2022 20:36:06 GMT"},{"version":"v3","created":"Sat, 9 Jul 2022 09:32:38 GMT"}],"update_date":"2022-07-12"}
{"id":"2110.08249","submitter":"Matthew Middleton","authors":"Matthew Middleton, Nick Higginbottom, Christian Knigge, Norman Khan\n  and Grzegorz Wiktorowicz","title":"Thermally driven winds in ULXs","comments":"8 pages, 9 figures, accepted to MNRAS","journal-ref":null,"doi":"10.1093/mnras/stab2991","report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The presence of radiatively driven outflows is well established in\nultraluminous X-ray sources (ULXs). These outflows are optically thick and can\nreprocess a significant fraction of the accretion luminosity. Assuming\nisotropic emission, escaping radiation from the outflow's photosphere has the\npotential to irradiate the outer disc. Here, we explore how the atmosphere of\nthe outer disc would respond to such irradiation, and specifically whether\nunstable heating may lead to significant mass loss via thermally-driven winds.\nWe find that, for a range of physically relevant system parameters, this mass\nloss may actually switch off the inflow entirely and potentially drive\nlimit-cycle behaviour (likely modulated on the timescale of the outer disc). In\nULXs harbouring neutron stars, magnetic fields tend to have a slight\ndestabilizing effect; for the strongest magnetic fields and highest accretion\nrates, this can push otherwise stable systems into the unstable regime. We\nexplore the prevalence of the instability in a simulated sample of ULXs\nobtained from a binary population synthesis calculation. We find that almost\nall neutron star and black hole ULXs with Eddington-scaled accretion rates of\n$\\dot{m}_0 < 100$ should be able to drive powerful outflows from their outer\ndiscs. Several known ULXs are expected to lie in this regime; the persistence\nof accretion in these sources implies the irradiation may be anisotropic which\ncan be reconciled with the inferred reprocessed (optical) emission if some of\nthis originates in the wind photosphere or irradiation of the secondary star.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:59:03 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08250","submitter":"Xutai Ma","authors":"Xutai Ma, Hongyu Gong, Danni Liu, Ann Lee, Yun Tang, Peng-Jen Chen,\n  Wei-Ning Hsu, Phillip Koehn, Juan Pino","title":"Direct Simultaneous Speech-to-Speech Translation with Variational\n  Monotonic Multihead Attention","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a direct simultaneous speech-to-speech translation (Simul-S2ST)\nmodel, Furthermore, the generation of translation is independent from\nintermediate text representations. Our approach leverages recent progress on\ndirect speech-to-speech translation with discrete units, in which a sequence of\ndiscrete representations, instead of continuous spectrogram features, learned\nin an unsupervised manner, are predicted from the model and passed directly to\na vocoder for speech synthesis on-the-fly. We also introduce the variational\nmonotonic multihead attention (V-MMA), to handle the challenge of inefficient\npolicy learning in speech simultaneous translation. The simultaneous policy\nthen operates on source speech features and target discrete units. We carry out\nempirical studies to compare cascaded and direct approach on the Fisher\nSpanish-English and MuST-C English-Spanish datasets. Direct simultaneous model\nis shown to outperform the cascaded model by achieving a better tradeoff\nbetween translation quality and latency.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:59:15 GMT"},{"version":"v2","created":"Wed, 12 Jan 2022 22:30:25 GMT"}],"update_date":"2022-01-14"}
{"id":"2110.08251","submitter":"Konrad Viebahn","authors":"Kilian Sandholzer, Anne-Sophie Walter, Joaqu\\'in Minguzzi, Zijie Zhu,\n  Konrad Viebahn, and Tilman Esslinger","title":"Floquet engineering of individual band gaps in an optical lattice using\n  a two-tone drive","comments":"18 pages, 8 figures","journal-ref":"Phys. Rev. Research 4, 013056 (2022)","doi":"10.1103/PhysRevResearch.4.013056","report-no":null,"categories":"cond-mat.quant-gas physics.atom-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The dynamic engineering of band structures for ultracold atoms in optical\nlattices represents an innovative approach to understand and explore the\nfundamental principles of topological matter. In particular, the folded Floquet\nspectrum determines the associated band topology via band inversion. We\nexperimentally and theoretically study two-frequency phase modulation to\nasymmetrically hybridize the lowest two bands of a one-dimensional lattice.\nUsing quasi-degenerate perturbation theory in the extended Floquet space we\nderive an effective two-band model that quantitatively describes our setting.\nThe energy gaps are experimentally probed via Landau-Zener transitions between\nFloquet-Bloch bands using an accelerated Bose-Einstein condensate. Separate and\nsimultaneous control over the closing and reopening of these band gaps is\ndemonstrated. We find good agreement between experiment and theory,\nestablishing an analytic description for resonant Floquet-Bloch engineering\nthat includes single- and multi-photon couplings, as well as interference\neffects between several commensurate drives.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:59:56 GMT"},{"version":"v2","created":"Tue, 21 Dec 2021 18:57:10 GMT"}],"update_date":"2022-09-01"}
{"id":"2110.08271","submitter":"Xinyu Zhang","authors":"Xinyu Zhang, Ian Colbert, Ken Kreutz-Delgado, Srinjoy Das","title":"Training Deep Neural Networks with Joint Quantization and Pruning of\n  Weights and Activations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantization and pruning are core techniques used to reduce the inference\ncosts of deep neural networks. State-of-the-art quantization techniques are\ncurrently applied to both the weights and activations; however, pruning is most\noften applied to only the weights of the network. In this work, we jointly\napply novel uniform quantization and unstructured pruning methods to both the\nweights and activations of deep neural networks during training. Using our\nmethods, we empirically evaluate the currently accepted prune-then-quantize\nparadigm across a wide range of computer vision tasks and observe a\nnon-commutative nature when applied to both the weights and activations of deep\nneural networks. Informed by these observations, we articulate the\nnon-commutativity hypothesis: for a given deep neural network being trained for\na specific task, there exists an exact training schedule in which quantization\nand pruning can be introduced to optimize network performance. We identify that\nthis optimal ordering not only exists, but also varies across discriminative\nand generative tasks. Using the optimal training schedule within our training\nframework, we demonstrate increased performance per memory footprint over\nexisting solutions.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:14:36 GMT"},{"version":"v2","created":"Mon, 1 Nov 2021 09:06:55 GMT"}],"update_date":"2021-11-02"}
{"id":"2110.08272","submitter":"Enea Parimbelli","authors":"Enea Parimbelli, Giovanna Nicora, Szymon Wilk, Wojtek Michalowski,\n  Riccardo Bellazzi","title":"Tree-based local explanations of machine learning model predictions,\n  AraucanaXAI","comments":"XAI Healthcare workshop 2021, AIME 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Increasingly complex learning methods such as boosting, bagging and deep\nlearning have made ML models more accurate, but harder to understand and\ninterpret. A tradeoff between performance and intelligibility is often to be\nfaced, especially in high-stakes applications like medicine. In the present\narticle we propose a novel methodological approach for generating explanations\nof the predictions of a generic ML model, given a specific instance for which\nthe prediction has been made, that can tackle both classification and\nregression tasks. Advantages of the proposed XAI approach include improved\nfidelity to the original model, the ability to deal with non-linear decision\nboundaries, and native support to both classification and regression problems\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:39:19 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08273","submitter":"Kara Farnsworth","authors":"Timothy Cohen, Kara Farnsworth, Rachel Houtz and Markus A. Luty","title":"Hamiltonian Truncation Effective Theory","comments":"51 pages, 9 figures, v2: Clarifications and additional discussion\n  added in response to referee reports. Conclusions unchanged","journal-ref":"SciPost Phys. 13, 011 (2022)","doi":"10.21468/SciPostPhys.13.2.011","report-no":null,"categories":"hep-th cond-mat.str-el hep-lat hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Hamiltonian truncation is a non-perturbative numerical method for calculating\nobservables of a quantum field theory. The starting point for this method is to\ntruncate the interacting Hamiltonian to a finite-dimensional space of states\nspanned by the eigenvectors of the free Hamiltonian $H_0$ with eigenvalues\nbelow some energy cutoff $E_\\text{max}$. In this work, we show how to treat\nHamiltonian truncation systematically using effective field theory methodology.\nWe define the finite-dimensional effective Hamiltonian by integrating out the\nstates above $E_\\text{max}$. The effective Hamiltonian can be computed by\nmatching a transition amplitude to the full theory, and gives corrections order\nby order as an expansion in powers of $1/E_\\text{max}$. The effective\nHamiltonian is non-local, with the non-locality controlled in an expansion in\npowers of $H_0/E_\\text{max}$. The effective Hamiltonian is also non-Hermitian,\nand we discuss whether this is a necessary feature or an artifact of our\ndefinition. We apply our formalism to 2D $\\lambda \\phi^4$ theory, and compute\nthe the leading $1/E_\\text{max}^2$ corrections to the effective Hamiltonian. We\nshow that these corrections non-trivially satisfy the crucial property of\nseparation of scales. Numerical diagonalization of the effective Hamiltonian\ngives residual errors of order $1/E_\\text{max}^3$, as expected by our power\ncounting. We also present the power counting for 3D $\\lambda \\phi^4$ theory and\nperform calculations that demonstrate the separation of scales in this theory.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:00 GMT"},{"version":"v2","created":"Fri, 15 Apr 2022 15:09:42 GMT"}],"update_date":"2022-08-10"}
{"id":"2110.08274","submitter":"Stefano Forte","authors":"Richard D. Ball, Stefano Forte and Roy Stegeman","title":"Correlation and Combination of Sets of Parton Distributions","comments":"21 pages, 9 figures. Final version published in EPJC: clarifications\n  on data replicas and functional uncertainties added, typos corrected,\n  references updated","journal-ref":null,"doi":null,"report-no":"Edinburgh 2021/19, TIF-UNIMI-2021-5","categories":"hep-ph hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the correlation between different sets of parton distributions\n(PDFs). Specifically, viewing different PDF sets as distinct determinations,\ngenerally correlated, of the same underlying physical quantity, we examine the\nextent to which the correlation between them is due to the underlying data. We\ndo this both for pairs of PDF sets determined using a given fixed methodology,\nand between sets determined using different methodologies. We show that\ncorrelations have a sizable component that is not due to the underlying data,\nbecause the data do not determine the PDF uniquely. We show that the\ndata-driven correlations can be used to assess the efficiency of methodologies\nused for PDF determination. We also show that the use of data-driven\ncorrelations for the combination of different PDFs into a joint set can lead to\ninconsistent results, and thus that the statistical combination used in\nconstructing the widely used PDF4LHC15 PDF set remains the most reliable\nmethod.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:00 GMT"},{"version":"v2","created":"Wed, 8 Dec 2021 11:39:31 GMT"}],"update_date":"2021-12-09"}
{"id":"2110.08275","submitter":"Siyao Xu","authors":"Siyao Xu","title":"Mirror diffusion of cosmic rays in highly compressible turbulence near\n  supernova remnants","comments":"11 pages, 3 figures, accepted for publication in ApJ","journal-ref":null,"doi":"10.3847/1538-4357/ac2d8f","report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent gamma-ray observations reveal inhomogeneous diffusion of cosmic rays\n(CRs) in the interstellar medium (ISM). This is expected as the diffusion of\nCRs depends on the properties of turbulence, which can vary widely in the\nmulti-phase ISM. We focus on the mirror diffusion arising in highly\ncompressible turbulence in molecular clouds (MCs) around supernova remnants\n(SNRs), where the magnetic mirroring effect results in significant suppression\nof diffusion of CRs near CR sources. Significant energy loss via proton-proton\ninteractions due to slow diffusion flattens the low-energy CR spectrum, while\nthe high-energy CR spectrum is steepened due to the strong dependence of mirror\ndiffusion on CR energy. The resulting broken power law spectrum of CRs matches\nwell the gamma-ray spectrum observed from SNR/MC systems, e.g., IC443 and W44.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:00 GMT"}],"update_date":"2021-12-15"}
{"id":"2110.08276","submitter":"Pieter Bomans","authors":"Pieter Bomans, Davide Cassani, Giuseppe Dibitetto and Nicolo Petri","title":"Bubble instability of mIIA on $\\mathrm{AdS}_4\\times S^6$","comments":"27 pages, 6 figures. Published version","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider compactifications of massive IIA supergravity on a six-sphere.\nThis setup is known to give rise to non-supersymmetric AdS$_4$ vacua preserving\nSO$(7)$ as well as G$_2$ residual symmetry. Both solutions have a round $S^6$\nmetric and are supported by the Romans' mass and internal $F_6$ flux. While the\nSO$(7)$ invariant vacuum is known to be perturbatively unstable, the G$_2$\ninvariant one has been found to have a fully stable Kaluza-Klein spectrum.\nMoreover, it has been shown to be protected against brane-jet instabilities.\nMotivated by these results, we study possible bubbling solutions connected to\nthe G$_2$ vacuum, representing non-perturbative instabilities of the latter. We\nindeed find an instability channel represented by the nucleation of a bubble of\nnothing dressed up with a homogeneous D2 brane charge distribution in the\ninternal space. Our solution generalizes to the case where $S^6$ is replaced by\nany six-dimensional nearly-K\\\"ahler manifold.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:01 GMT"},{"version":"v2","created":"Tue, 5 Apr 2022 10:22:30 GMT"}],"update_date":"2022-04-06"}
{"id":"2110.08277","submitter":"Mainak Mukhopadhyay","authors":"Mainak Mukhopadhyay, Evangelos I. Sfakianakis, Tanmay Vachaspati,\n  George Zahariade","title":"Kink-antikink scattering in a quantum vacuum","comments":"29 pages, 16 figures, published version","journal-ref":"JHEP 04 (2022) 118","doi":"10.1007/JHEP04(2022)118","report-no":null,"categories":"hep-th cond-mat.other hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study kink-antikink scattering in the sine-Gordon model in the presence of\ninteractions with an additional scalar field, $\\psi$, that is in its quantum\nvacuum. In contrast to the classical scattering, now there is quantum radiation\nof $\\psi$ quanta and the kink-antikink may form bound states that resemble\nbreathers of the sine-Gordon model. We quantify the rate of radiation and map\nthe parameters for which bound states are formed. Even these bound states\nradiate and decay, and eventually there is a transition into long-lived\noscillons.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:01 GMT"},{"version":"v2","created":"Mon, 16 May 2022 21:54:21 GMT"}],"update_date":"2022-05-18"}
{"id":"2110.08278","submitter":"Achim Kempf","authors":"Achim Kempf","title":"Replacing the Notion of Spacetime Distance by the Notion of Correlation","comments":"8 pages","journal-ref":"Front. Phys., Vol.9, 655857 (2021)","doi":"10.3389/fphy.2021.655857","report-no":null,"categories":"gr-qc quant-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Spacetime is conventionally viewed as a stage on which actors, in the form of\nfields, move. Here, we explore what may lie beyond this picture. The starting\npoint is the observation that quantum fluctuations of fields are the more\nstrongly correlated the shorter their spacetime distance. As a consequence, the\nnotion of spacetime distance, including the metric as its infinitesimal\nversion, can be replaced by the notion of correlation strength. This suggests a\nnew picture in which abstract (2-point and multi-point) correlators are the\nprimary structure. In general, these abstract correlators can only be described\nas information theoretic structures and, in principle, they need not bear any\nrelationship to quantum fields or spacetimes. These correlators may allow\napproximations, however, so that, in certain regimes, they can be\nmathematically approximately represented as the 2-point and multi-point\nfunctions of quantum fields living on a spacetime. In this way, the standard\npicture of a curved spacetime with fields whose correlators arise from Feynman\nrules would merely be a convenient approximate picture, while the underlying\npicture is that of a spacetime-less and field-less information-theoretic\nstructure of abstract correlations.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:01 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08279","submitter":"Alejandro Benitez-Llambay","authors":"Alejandro Benitez-Llambay, Michele Fumagalli","title":"The Tail of Late-forming Dwarf Galaxies in $\\Lambda$CDM","comments":"Published version in ApJL","journal-ref":null,"doi":"10.3847/2041-8213/ac3006","report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use a robust analytical model together with a high-resolution\nhydrodynamical cosmological simulation to demonstrate that in a $\\Lambda$ cold\ndark matter ($\\Lambda$CDM) universe, a small fraction of dwarf galaxies\ninhabiting dark matter (DM) halos in the mass range $3\\times 10^{9} \\lesssim\nM_{200} / M_{\\odot} \\lesssim 10^{10}$ form unusually late ($z<3$) compared to\nthe bulk population of galaxies. These galaxies originate from the interplay\nbetween the stochastic growth of DM halos and the existence of a time-dependent\nDM halo mass below which galaxies do not form. The formation epoch of the\nsimulated late-forming galaxies traces remarkably well the time when their host\nDM halos first exceeded a nontrivial (but well-understood) time-dependent\ncritical mass, thus making late-forming dwarfs attractive cosmological probes\nwith constraining power over the past growth history of their host halos. The\nagreement between our model and the simulation results demonstrates that the\npopulation of simulated late-forming dwarfs is a robust cosmological outcome\nand largely independent of the specific galaxy formation model included in the\nsimulations provided: (1) the universe underwent cosmic reionization before\n$z_{\\rm re} \\sim 8$; (2) star formation proceeds in gas that self-gravitates;\nand (3) galaxy formation is largely restricted to atomic-cooling halos before\n$z_{\\rm re}$. The scarcity of massive late-forming dwarfs expected in\n$\\Lambda$CDM implies that the great majority of bright, metal-poor, and\nactively star-forming dwarfs observed in our local universe--the most obvious\ncandidates for these late-forming galaxies--cannot be undergoing their\nformation for the first time at the present day in a $\\Lambda$CDM universe.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:02 GMT"},{"version":"v2","created":"Thu, 28 Oct 2021 17:22:39 GMT"}],"update_date":"2021-10-29"}
{"id":"2110.08280","submitter":"Chong Wang","authors":"Ruochen Ma, Liujun Zou and Chong Wang","title":"Edge physics at the deconfined transition between a quantum spin Hall\n  insulator and a superconductor","comments":"9 pages + references","journal-ref":"SciPost Phys. 12, 196 (2022)","doi":"10.21468/SciPostPhys.12.6.196","report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the edge physics of the deconfined quantum phase transition (DQCP)\nbetween a spontaneous quantum spin Hall (QSH) insulator and a spin-singlet\nsuperconductor (SC). Although the bulk of this transition is in the same\nuniversality class as the paradigmatic deconfined Neel to valence-bond-solid\ntransition, the boundary physics has a richer structure due to proximity to a\nquantum spin Hall state. We use the parton trick to write down an effective\nfield theory for the QSH-SC transition in the presence of a boundary. We\ncalculate various edge properties in an $N\\to\\infty$ limit. We show that the\nboundary Luttinger liquid in the QSH state survives at the phase transition,\nbut only as \"fractional\" degrees of freedom that carry charge but not spin. The\nphysical fermion remains gapless on the edge at the critical point, with a\nuniversal jump in the fermion scaling dimension as the system approaches the\ntransition from the QSH side. The critical point could be viewed as a gapless\nanalogue of the quantum spin Hall state but with the full $SU(2)$ spin rotation\nsymmetry, which cannot be realized if the bulk is gapped.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:02 GMT"},{"version":"v2","created":"Fri, 17 Jun 2022 01:31:31 GMT"}],"update_date":"2022-06-20"}
{"id":"2110.08281","submitter":"Matti Jarvinen","authors":"Matti Jarvinen","title":"Holographic modeling of nuclear matter and neutron stars","comments":"Review article published in Eur.Phys.J.C. 58 pages, 24 figures, 2\n  tables. v2: references and comments added","journal-ref":"Eur.Phys.J.C 82 (2022) 4, 282","doi":"10.1140/epjc/s10052-022-10227-x","report-no":"APCTP Pre2021 - 024","categories":"hep-ph astro-ph.HE hep-th nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  I review holographic models for (dense and cold) nuclear matter, neutron\nstars, and their mergers. I start by a brief general discussion on current\nknowledge of cold QCD matter and neutron stars, and go on discussing various\napproaches to model cold nuclear and quark matter by using gauge/gravity\nduality, pointing out their strengths and weaknesses. Then I focus on recent\nresults for a complex bottom-up holographic framework (V-QCD), which also takes\ninput from lattice QCD results, effective field theory, and perturbative QCD.\nDense nuclear matter is modeled in V-QCD through a homogeneous non-Abelian bulk\ngauge field. Feasible \"hybrid\" equations of state for cold nuclear (and quark)\nmatter can be constructed by using traditional methods (e.g., effective field\ntheory) at low densities and the holographic V-QCD model at higher densities. I\ndiscuss the constraints from this approach to the properties of the nuclear to\nquark matter transition as well as to properties of neutron stars. Using such\nhybrid equations of state as an input for numerical simulations of neutron star\nmergers, I also derive predictions for the spectrum of produced gravitational\nwaves.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:02 GMT"},{"version":"v2","created":"Tue, 12 Jul 2022 07:27:20 GMT"}],"update_date":"2022-07-13"}
{"id":"2110.08282","submitter":"Siyao Xu","authors":"Siyao Xu","title":"Diffusion of cosmic rays in MHD turbulence","comments":"17 pages, 7 figures, Proceedings of Science, PoS(ICRC2021)041","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We review some recent findings on diffusion of cosmic rays (CRs) in\nmagnetohydrodynamic (MHD) turbulence obtained by adopting the\nnumerically-tested model of MHD turbulence, including perpendicular\nsuperdiffusion of CRs, inefficient gyroresonant scattering by Alfv\\'{e}n and\nslow modes with scale-dependent turbulence anisotropy, resonance-broadened\nTransit Time Damping (TTD) interaction, and mirror diffusion. As the diffusion\nbehavior of CRs strongly depends on the properties of MHD turbulence,\ntheoretical modeling of CR diffusion, its numerical testing, and interpretation\nof CR-related observations require proper modeling of MHD turbulence.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:04 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08283","submitter":"Kevin Kavanagh","authors":"K. Kavanagh, S. Dooley, J. K. Slingerland, G. Kells","title":"Effects of Quantum Pair Creation and Annihilation on a Classical\n  Exclusion Process: the transverse XY model with TASEP","comments":"14 pages, 10 figures","journal-ref":null,"doi":"10.1088/1367-2630/ac4ee1","report-no":"DIAS-STP-21-14","categories":"cond-mat.stat-mech cond-mat.str-el quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate how particle pair creation and annihilation, within the\nquantum transverse XY model, affects the non-equilibrium steady state (NESS)\nand Liouvillian gap of the stochastic Totally Asymmetric Exclusion Process\n(TASEP). By utilising operator quantization we formulate a perturbative\ndescription of the NESS. Furthermore, we estimate the Liouvillian gap by\nexploiting a Majorana canonical basis as the basis of super-operators. In this\nmanner we show that the Liouvillian gap can remain finite in the thermodynamic\nlimit provided the XY model anisotropy parameter remains non-zero.\nAdditionally, we show that the character of the gap with respect to the\nanisotropy parameter differs depending on the phase of the XY model. The change\nof character corresponds to the quantum phase transition of the XY model.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:05 GMT"}],"update_date":"2022-03-02"}
{"id":"2110.08284","submitter":"Alejandro Kunold","authors":"A. Aguirre-Perez, R. S. Joshya, H. Carr\\`ere, X. Marie, T. Amand, A.\n  Balocchi, A. Kunold","title":"Machine learning assisted GaAsN circular polarimeter","comments":"20 pages, 13 figures","journal-ref":null,"doi":"10.1088/2040-8986/ac3f92","report-no":null,"categories":"cond-mat.other physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We demonstrate the application of a two stage machine learning algorithm that\nenables to correlate the electrical signals from a GaAs$_x$N$_{1-x}$ circular\npolarimeter with the intensity, degree of circular polarization and handedness\nof an incident light beam. Specifically, we employ a multimodal logistic\nregression to discriminate the handedness of light and a 6-layer neural network\nto establish the relationship between the input voltages, the intensity and\ndegree of circular polarization. We have developed a particular neural network\ntraining strategy that substantially improves the accuracy of the device. The\nalgorithm was trained and tested on theoretically generated photoconductivity\nand on photoluminescence experimental results. Even for a small training\nexperimental dataset (70 instances), it is shown that the proposed algorithm\ncorrectly predicts linear, right and left circularly polarized light\nmisclassifying less than $1.5\\%$ of the cases and attains an accuracy larger\nthan $97\\%$ in the vast majority of the predictions ($92\\%$) for intensity and\ndegree of circular polarization. These numbers are significantly improved for\nthe larger theoretically generated datasets (4851 instances). The algorithm is\nversatile enough that it can be easily adjusted to other device configurations\nwhere a map needs to be established between the input parameters and the device\nresponse. Training and testing data files as well as the algorithm are provided\nas supplementary material.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:05 GMT"}],"update_date":"2022-03-23"}
{"id":"2110.08285","submitter":"Thomas W. Baumgarte","authors":"Sophia C. Schnauck, Thomas W. Baumgarte, and Stuart L. Shapiro","title":"Accretion onto black holes inside neutron stars with\n  piecewise-polytropic equations of state: analytic and numerical treatments","comments":"10 pages, 3 figures; version accepted for publication in Phys. Rev. D","journal-ref":null,"doi":"10.1103/PhysRevD.104.123021","report-no":null,"categories":"astro-ph.HE gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider spherically symmetric accretion onto a small, possibly\nprimordial, black hole residing at the center of a neutron star governed by a\ncold nuclear equation of state (EOS). We generalize the relativistic Bondi\nsolution for such EOSs, approximated by piecewise polytropes, and thereby\nobtain analytical expressions for the steady-state matter profiles and\naccretion rates. We compare these rates with those found by time-dependent,\ngeneral relativistic hydrodynamical simulations upon relaxation and find\nexcellent agreement. We consider several different candidate EOSs, neutron star\nmasses and central densities and find that the accretion rates vary only\nlittle, resulting in an accretion rate that depends primarily on the black hole\nmass, and only weakly on the properties of the neutron star.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:06 GMT"},{"version":"v2","created":"Tue, 7 Dec 2021 18:26:38 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08286","submitter":"Merel van 't Hoff PhD","authors":"Merel L.R. van 't Hoff, Daniel Harsono, Martijn L. van Gelder,\n  Tien-Hao Hsieh, John J. Tobin, Sigurd S. Jensen, Naomi Hirano, Jes K.\n  J{\\o}rgensen, Edwin A. Bergin, and Ewine F. van Dishoeck","title":"Imaging the water snowline around protostars with water and HCO$^+$\n  isotopologues","comments":"Accepted for publication in ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The water snowline location in protostellar envelopes provides crucial\ninformation about the thermal structure and the mass accretion process as it\ncan inform about the occurrence of recent ($\\lesssim$1,000 yr) accretion\nbursts. In addition, the ability to image water emission makes these sources\nexcellent laboratories to test indirect snowline tracers such as\nH$^{13}$CO$^+$. We study the water snowline in five protostellar envelopes in\nPerseus using a suite of molecular line observations taken with the Atacama\nLarge Millimeter/submillimeter Array (ALMA) at\n$\\sim$0.2$^{\\prime\\prime}-$0.7$^{\\prime\\prime}$ (60--210 au) resolution. B1-c\nprovides a textbook example of compact H$_2^{18}$O ($3_{1,3}-2_{2,0}$) and HDO\n($3_{1,2}-2_{2,1}$) emission surrounded by a ring of H$^{13}$CO$^+$ ($J=2-1$)\nand HC$^{18}$O$^+$ ($J=3-2$). Compact HDO surrounded by H$^{13}$CO$^+$ is also\ndetected toward B1-bS. The optically thick main isotopologue HCO$^+$ is not\nsuited to trace the snowline and HC$^{18}$O$^+$ is a better tracer than\nH$^{13}$CO$^+$ due to a lower contribution from the outer envelope. However,\nsince a detailed analysis is needed to derive a snowline location from\nH$^{13}$CO$^+$ or HC$^{18}$O$^+$ emission, their true value as snowline tracer\nwill lie in the application in sources where water cannot be readily detected.\nFor protostellar envelopes, the most straightforward way to locate the water\nsnowline is through observations of H$_2^{18}$O or HDO. Including all\nsub-arcsecond resolution water observations from the literature, we derive an\naverage burst interval of $\\sim$10,000 yr, but high-resolution water\nobservations of a larger number of protostars is required to better constrain\nthe burst frequency.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:07 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08287","submitter":"Preet Patel","authors":"Preet B. Patel, Sarah R. Loebman, Andrew Wetzel, Claude-Andr\\'e\n  Faucher-Gigu\\`ere, Kareem El-Badry, Jeremy Bailin","title":"Predictions for Complex Distributions of Stellar Elemental Abundances in\n  Low-Mass Galaxies","comments":"v1: 14 pages, 8 figures. Submitted to MNRAS on Oct. 18th, 2021 | v2:\n  15 pages, 8 figures. Accepted by MNRAS on Mar. 17th, 2022","journal-ref":null,"doi":"10.1093/mnras/stac834","report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate stellar elemental abundance patterns at z = 0 in 8 low-mass\n(M_* = 10^6 - 10^9 M_sun) galaxies in the Feedback in Realistic Environments\n(FIRE-2) cosmological simulations. Using magnesium (Mg) as a representative\nalpha-element, we explore stellar abundance patterns in [Mg/Fe] versus [Fe/H],\nwhich follow an overall monotonic trend that evolved slowly over time. Beyond\nthis, we explore 3 notable secondary features in enrichment (found in three\ndifferent case-study galaxies) that arise from a galaxy merger or bursty star\nformation. First, we observe a secondary track with a lower [Mg/Fe] than the\nmain trend. At z = 0, stars from this track are predominantly found within 2-6\nkpc of the center; they were accreted in a 1:3 total-mass-ratio merger ~ 0.4\nGyr ago. Second, we find a distinct elemental bi-modality that forms following\na strong burst in star formation in a galaxy at t_lookback ~ 10 Gyr. This burst\nquenched star formation for ~ 0.66 Gyr, allowing Ia supernovae to enrich the\nsystem with iron before star formation resumed. Third, we examine stripes in\nenrichment that run roughly orthogonal to the dominant [Mg/Fe] versus [Fe/H]\ntrend; these stripes correspond to short bursts of star formation during which\ncore-collapse supernovae enrich the surrounding medium with Mg (and Fe) on\nshort timescales. If observed, these features would substantiate the utility of\nelemental abundances in revealing the assembly and star formation histories of\ndwarf galaxies. We explore the observability of these features for upcoming\nspectroscopic studies. Our results show that precise measurements of elemental\nabundance patterns can reveal critical events in the formation histories of\nlow-mass galaxies.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:07 GMT"},{"version":"v2","created":"Wed, 23 Mar 2022 18:55:10 GMT"}],"update_date":"2022-03-25"}
{"id":"2110.08288","submitter":"Prabh Bhambra","authors":"Prabh Bhambra, Benjamin Joachimi, Ofer Lahav","title":"Explaining deep learning of galaxy morphology with saliency mapping","comments":"11 pages, 5 figures, 2 tables, 2 appendices. Accepted for publication\n  by Monthly Notices of the Royal Astronomical Society","journal-ref":null,"doi":"10.1093/mnras/stac368","report-no":null,"categories":"astro-ph.IM astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We successfully demonstrate the use of explainable artificial intelligence\n(XAI) techniques on astronomical datasets in the context of measuring galactic\nbar lengths. The method consists of training convolutional neural networks on\nhuman classified data from Galaxy Zoo in order to predict general galaxy\nmorphologies, and then using SmoothGrad (a saliency mapping technique) to\nextract the bar for measurement by a bespoke algorithm. We contrast this to\nanother method of using a convolutional neural network to directly predict\ngalaxy bar lengths. These methods achieved correlation coefficients of 0.76 and\n0.59, and root mean squared errors of 1.69 and 2.10 respective to human\nmeasurements. We conclude that XAI methods outperform conventional deep\nlearning in this case, which could be reasonably explained by the larger\ndatasets available when training the models. We suggest that our XAI method can\nbe used to extract other galactic features (such as the bulge-to-disk ratio)\nwithout needing to collect new datasets or train new models. We also suggest\nthat these techniques can be used to refine deep learning models as well as\nidentify and eliminate bias within training datasets.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:25 GMT"},{"version":"v2","created":"Mon, 14 Feb 2022 12:54:11 GMT"}],"update_date":"2022-02-23"}
{"id":"2110.08289","submitter":"Karol Palczynski","authors":"Mila Miletic and Karol Palczynski and Joachim Dzubiella","title":"Growth modes of partially fluorinated organic molecules on amorphous\n  silicon dioxide","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the influence of fluorination on nucleation and growth of the\norganic para-sexiphenyl molecule (p-6P) on amorphous silicon dioxide\n($\\alpha$-SiO$_2$) by means of atomistically resolved classical molecular\ndynamics computer simulations. We use a simulation model that mimics the\nexperimental deposition from the vapor and subsequent self-assembly onto the\nunderlying surface. Our model reproduces the experimentally observed\norientational changes from lying to upright standing configurations of the\ngrown layers. We demonstrate that the increase in the number of fluorinated\ngroups inside the p-6P leads to a smoother, layer-by-layer growth on the\n$\\alpha$-SiO$_2$ surface: We observe that in the first layers, due to strong\nmolecule-substrate interactions the molecules first grow in chiral (fan-like)\nstructures, where each consecutive molecule has a higher angle, supported by\nmolecules lying underneath. Subsequently deposited molecules bind to the\nalready standing molecules of the chiral structures until all molecules are\nstanding. The growth of chiral islands is the main mechanism for growth of the\nfluorinated p-6P derivative, while the p-6P, due to the lower interaction with\nthe underlying substrate, forms less chiral structures. This leads to a lower\nenergy barrier for step-edge crossing for the fluorinated molecules. We find\nthat partial fluorination of the p-6P molecule can in this way significantly\nalter its growth behaviour by modifying the rough, 3D growth into a smooth,\nlayer-by-layer growth. This has implications for the rational design of\nmolecules and their functionalized forms which could be tailored for a desired\ngrowth behavior and structure formation.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:27 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08290","submitter":"Renato Fonseca","authors":"Renato M. Fonseca","title":"Boundedness from below of SU(n) potentials","comments":"19 pages, 4 figures","journal-ref":null,"doi":"10.1103/PhysRevD.105.075014","report-no":null,"categories":"hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vacuum stability requires that the scalar potential is bounded from below.\nWhether or not this is true depends on the scalar quartic interactions alone,\nbut even so the analysis is arduous and has only been carried out for a limited\nset of models. Complementing the existing literature, this work contains the\nnecessary and sufficient conditions for two SU(n) invariant potentials to be\nbounded from below. In particular, expressions are given for models with the\nfundamental and the 2-index (anti)symmetric representations of this group. A\nsufficient condition for vacuum stability is also provided for models with the\nfundamental and the adjoint representations. Finally, some considerations are\nmade concerning the model with the gauge group SU(2) and the scalar\nrepresentations $\\boldsymbol{1}$, $\\boldsymbol{2}$ and $\\boldsymbol{3}$; such a\nsetup is particularly important for neutrino mass generation and lepton number\nviolation.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:00:57 GMT"}],"update_date":"2022-04-27"}
{"id":"2110.08291","submitter":"Akira Harada","authors":"Akira Harada, Hiroki Nagakura","title":"Prospects of fast flavor neutrino conversion in rotating core-collapse\n  supernovae","comments":"8 pages, 5 figures, accepted for publication in the ApJ","journal-ref":null,"doi":"10.3847/1538-4357/ac38a0","report-no":"RIKEN-iTHEMS-Report-21","categories":"astro-ph.HE hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is mounting evidence that neutrinos undergo fast flavor conversion\n(FFC) in core-collapse supernova (CCSN). In this letter, we investigate the\nroles of stellar rotation on the occurrence of FFC by carrying out axisymmetric\nCCSN simulations with full Boltzmann neutrino transport. Our result suggests\nthat electron neutrino lepton number (ELN) angular crossings, which are the\nnecessary and sufficient condition to trigger FFC, preferably occur in the\nequatorial region for rotating CCSNe. By scrutinizing the neutrino--matter\ninteraction and neutrino radiation field, we find some pieces of evidence that\nthe stellar rotation facilitates the occurrence of FFC. The\nlow-electron-fraction region in the post-shock layer expands by centrifugal\nforce, enhancing the disparity of neutrino absorption between electron-type\nneutrinos ($\\nu_{\\rm e}$) and their anti-particles ($\\bar{\\nu}_{\\rm e}$). This\nhas a significant impact on the angular distribution of neutrinos in momentum\nspace, in which $\\nu_{\\rm e}$ tends to be more isotropic than $\\bar{\\nu}_{\\rm\ne}$; consequently, ELN crossings emerge. The ELN crossing found in this study\nis clearly associated with rotation, which motivates further investigation on\nhow the subsequent FFC influences explosion dynamics, nucleosynthesis, and\nneutrino signals in rotating CCSNe.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:01:06 GMT"},{"version":"v2","created":"Wed, 10 Nov 2021 09:49:55 GMT"}],"update_date":"2022-01-26"}
{"id":"2110.08292","submitter":"Oliver Hart","authors":"Oliver Hart, Andrew Lucas and Rahul Nandkishore","title":"Hidden quasiconservation laws in fracton hydrodynamics","comments":"15 pages, 8 figures; v2 is published version","journal-ref":"Phys. Rev. E 105, 044103 (2022)","doi":"10.1103/PhysRevE.105.044103","report-no":null,"categories":"cond-mat.stat-mech cond-mat.dis-nn cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the simplest universality classes of fracton hydrodynamics in\nmore than one spatial dimension, including isotropic theories of charge and\ndipole conservation, can exhibit hidden \"quasiconservation laws\", in which\ncertain higher multipole moments can only decay due to dangerously irrelevant\ncorrections to hydrodynamics. We present two simple examples of this\nphenomenon. Firstly, an isotropic dipole-conserving fluid in the infinite plane\nconserves an infinite number of \"harmonic multipole charges\" within linear\nresponse; we calculate the decay or growth of these charges due to dangerously\nirrelevant nonlinearities. Secondly, we consider a model with $xy$ and\n$x^2-y^2$ quadrupole conservation, in addition to dipole conservation, which is\ndescribed by isotropic fourth-order subdiffusion, yet has dangerously\nirrelevant sixth-order corrections necessary to relax the harmonic multipole\ncharges. We confirm our predictions for the anomalously slow decay of the\nharmonic conserved charges in each setting by using numerical simulations, both\nof the nonlinear hydrodynamic differential equations, and in quantum automaton\ncircuits on a square lattice.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:02:04 GMT"},{"version":"v2","created":"Mon, 23 May 2022 00:47:27 GMT"}],"update_date":"2022-05-24"}
{"id":"2110.08293","submitter":"Dardo Goyeneche","authors":"F. Caro Perez, V. Gonzalez Avella, D. Goyeneche","title":"Mutually unbiased frames","comments":"17 pages, 2 figures","journal-ref":"Quantum 6, 851 (2022)","doi":"10.22331/q-2022-11-03-851","report-no":null,"categories":"quant-ph math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, the concept of mutually unbiased frames is introduced as the\nmost general notion of unbiasedness for sets composed by linearly independent\nand normalized vectors. It encompasses the already existing notions of\nunbiasedness for orthonormal bases, regular simplices, equiangular tight\nframes, positive operator valued measure, and also includes symmetric\ninformationally complete quantum measurements. After introducing the tool, its\npower is shown by finding the following results about the last mentioned class\nof constellations: (i) real fiducial states do not exist in any even dimension,\nand (ii) unknown $d$-dimensional fiducial states are parameterized, a priori,\nwith roughly $3d/2$ real variables only, without loss of generality.\nFurthermore, multi-parametric families of pure quantum states having minimum\nuncertainty with regard to several choices of $d+1$ orthonormal bases are\nshown, in every dimension $d$. These last families contain all existing\nfiducial states in every finite dimension, and the bases include maximal sets\nof $d+1$ mutually unbiased bases, when $d$ is a prime number.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:04:20 GMT"},{"version":"v2","created":"Thu, 27 Oct 2022 07:24:29 GMT"}],"update_date":"2022-11-09"}
{"id":"2110.08294","submitter":"Nikolay Malkin","authors":"Nikolay Malkin, Zhen Wang, Nebojsa Jojic","title":"Coherence boosting: When your pretrained language model is not paying\n  enough attention","comments":"ACL 2022; code: https://github.com/zhenwang9102/coherence-boosting","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Long-range semantic coherence remains a challenge in automatic language\ngeneration and understanding. We demonstrate that large language models have\ninsufficiently learned the effect of distant words on next-token prediction. We\npresent coherence boosting, an inference procedure that increases a LM's focus\non a long context. We show the benefits of coherence boosting with pretrained\nmodels by distributional analyses of generated ordinary text and dialog\nresponses. It is also found that coherence boosting with state-of-the-art\nmodels for various zero-shot NLP tasks yields performance gains with no\nadditional training.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:05:33 GMT"},{"version":"v2","created":"Wed, 16 Mar 2022 15:49:26 GMT"}],"update_date":"2022-03-17"}
{"id":"2110.08295","submitter":"Shady E. Ahmed","authors":"Shady E. Ahmed, Omer San, Adil Rasheed, Traian Iliescu","title":"Nonlinear proper orthogonal decomposition for convection-dominated flows","comments":null,"journal-ref":null,"doi":"10.1063/5.0074310","report-no":null,"categories":"physics.flu-dyn cs.LG math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Autoencoder techniques find increasingly common use in reduced order modeling\nas a means to create a latent space. This reduced order representation offers a\nmodular data-driven modeling approach for nonlinear dynamical systems when\nintegrated with a time series predictive model. In this letter, we put forth a\nnonlinear proper orthogonal decomposition (POD) framework, which is an\nend-to-end Galerkin-free model combining autoencoders with long short-term\nmemory networks for dynamics. By eliminating the projection error due to the\ntruncation of Galerkin models, a key enabler of the proposed nonintrusive\napproach is the kinematic construction of a nonlinear mapping between the\nfull-rank expansion of the POD coefficients and the latent space where the\ndynamics evolve. We test our framework for model reduction of a\nconvection-dominated system, which is generally challenging for reduced order\nmodels. Our approach not only improves the accuracy, but also significantly\nreduces the computational cost of training and testing.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:05:34 GMT"},{"version":"v2","created":"Fri, 5 Nov 2021 22:07:57 GMT"}],"update_date":"2021-12-15"}
{"id":"2110.08296","submitter":"Ojas Ahuja","authors":"Ojas Ahuja, Jiacheng Xu, Akshay Gupta, Kevin Horecka, Greg Durrett","title":"ASPECTNEWS: Aspect-Oriented Summarization of News Documents","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generic summaries try to cover an entire document and query-based summaries\ntry to answer document-specific questions. But real users' needs often fall in\nbetween these extremes and correspond to aspects, high-level topics discussed\namong similar types of documents. In this paper, we collect a dataset of\nrealistic aspect-oriented summaries, AspectNews, which covers different\nsubtopics about articles in news sub-domains. We annotate data across two\ndomains of articles, earthquakes and fraud investigations, where each article\nis annotated with two distinct summaries focusing on different aspects for each\ndomain. A system producing a single generic summary cannot concisely satisfy\nboth aspects. Our focus in evaluation is how well existing techniques can\ngeneralize to these domains without seeing in-domain training data, so we turn\nto techniques to construct synthetic training data that have been used in\nquery-focused summarization work. We compare several training schemes that\ndiffer in how strongly keywords are used and how oracle summaries are\nextracted. Our evaluation shows that our final approach yields (a) focused\nsummaries, better than those from a generic summarization system or from\nkeyword matching; (b) a system sensitive to the choice of keywords.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:06:21 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 06:42:38 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08297","submitter":"Joshua Padgett","authors":"Martin Hutzenthaler, Arnulf Jentzen, Benno Kuckuck, and Joshua Lee\n  Padgett","title":"Strong $L^p$-error analysis of nonlinear Monte Carlo approximations for\n  high-dimensional semilinear partial differential equations","comments":"42 pages.","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Full-history recursive multilevel Picard (MLP) approximation schemes have\nbeen shown to overcome the curse of dimensionality in the numerical\napproximation of high-dimensional semilinear partial differential equations\n(PDEs) with general time horizons and Lipschitz continuous nonlinearities.\nHowever, each of the error analyses for MLP approximation schemes in the\nexisting literature studies the $L^2$-root-mean-square distance between the\nexact solution of the PDE under consideration and the considered MLP\napproximation and none of the error analyses in the existing literature\nprovides an upper bound for the more general $L^p$-distance between the exact\nsolution of the PDE under consideration and the considered MLP approximation.\nIt is the key contribution of this article to extend the $L^2$-error analysis\nfor MLP approximation schemes in the literature to a more general $L^p$-error\nanalysis with $p\\in (0,\\infty)$. In particular, the main result of this article\nproves that the proposed MLP approximation scheme indeed overcomes the curse of\ndimensionality in the numerical approximation of high-dimensional semilinear\nPDEs with the approximation error measured in the $L^p$-sense with $p \\in\n(0,\\infty)$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:07:51 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.08298","submitter":"Alexander Davydov","authors":"Alexander Davydov, Anton V. Proskurnikov, Francesco Bullo","title":"Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Critical questions in dynamical neuroscience and machine learning are related\nto the study of continuous-time neural networks and their stability,\nrobustness, and computational efficiency. These properties can be\nsimultaneously established via a contraction analysis.\n  This paper develops a comprehensive non-Euclidean contraction theory for\ncontinuous-time neural networks. First, for non-Euclidean\n$\\ell_{1}/\\ell_{\\infty}$ logarithmic norms, we establish quasiconvexity with\nrespect to positive diagonal weights and closed-form worst-case expressions\nover certain matrix polytopes. Second, for locally Lipschitz maps (e.g.,\narising as activation functions), we show that their one-sided Lipschitz\nconstant equals the essential supremum of the logarithmic norm of their\nJacobian. Third and final, we apply these general results to classes of\ncontinuous-time neural networks, including Hopfield, firing rate, Persidskii,\nLur'e and other models. For each model, we compute the optimal contraction rate\nand corresponding weighted non-Euclidean norm via a linear program or, in some\nspecial cases, via a Hurwitz condition on the Metzler majorant of the synaptic\nmatrix. Our non-Euclidean analysis establishes also absolute, connective, and\ntotal contraction properties.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:13:29 GMT"},{"version":"v2","created":"Fri, 5 Nov 2021 19:01:07 GMT"},{"version":"v3","created":"Thu, 24 Mar 2022 06:14:06 GMT"},{"version":"v4","created":"Sat, 26 Nov 2022 01:52:54 GMT"}],"update_date":"2022-11-29"}
{"id":"2110.08299","submitter":"Roni Dey","authors":"R. Dey, P. K. Netrakanti, D. K. Mishra, S. P. Behera, D. Mulmule, T.\n  Patel, P. S. Sarkar, V. Jha and L. M. Pant","title":"Characterization of plastic scintillator bars using fast neutrons from\n  D-D and D-T reactions","comments":"16 pages, 8 figures","journal-ref":"JINST 16 P08029 (2021)","doi":"10.1088/1748-0221/16/08/P08029","report-no":null,"categories":"physics.ins-det nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report results of fast neutron response in plastic scintillator (PS) bars\nfrom deuterium-deuterium (D-D) and deuterium-tritium (D-T) reactions using\nPurnima Neutron Generator Facility, BARC, Mumbai. These measurements are useful\nin context of Indian Scintillator Matrix for Reactor Anti-Neutrino (ISMRAN)\ndetection, an array of 10x10 PS bars, used to measure reactor anti-neutrinos\nthrough inverse beta decay (IBD) signal. ISMRAN detector, an above-ground\nexperiment close to the reactor core (~13m), deals with an active fast neutron\nbackground inside the reactor hall. A good understanding of fast neutron\nresponse in PS bars is an essential pre-requisite for suppression and\ndiscrimination of fast neutron background from IBD events. A monoenergetic\nneutron beam from the fusion reaction of D-D at 2.45 MeV and D-T at 14.1 MeV\nare used to characterize the energy response in these bars. The neutron energy\nresponse function has been simulated using the GEANT4 package and are compared\nwith the measured data. A reasonable agreement of deposited energies by fast\nneutrons in PS bars between data and simulation are obtained for these\nreactions. The ratio of energy deposition in adjacent bars is used to\ndiscriminate between prompt IBD, fast neutron and neutron capture cascade gamma\nevents.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:16:31 GMT"},{"version":"v2","created":"Thu, 4 Nov 2021 19:01:43 GMT"}],"update_date":"2021-11-08"}
{"id":"2110.08300","submitter":"Samuel Bowman","authors":"Samuel R. Bowman","title":"The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP\n  Systems Fail","comments":"Proceedings of ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Researchers in NLP often frame and discuss research results in ways that\nserve to deemphasize the field's successes, often in response to the field's\nwidespread hype. Though well-meaning, this has yielded many misleading or false\nclaims about the limits of our best technology. This is a problem, and it may\nbe more serious than it looks: It harms our credibility in ways that can make\nit harder to mitigate present-day harms, like those involving biased systems\nfor content moderation or resume screening. It also limits our ability to\nprepare for the potentially enormous impacts of more distant future advances.\nThis paper urges researchers to be careful about these claims and suggests some\nresearch directions and communication strategies that will make it easier to\navoid or rebut them.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:19:19 GMT"},{"version":"v2","created":"Tue, 8 Mar 2022 00:01:04 GMT"},{"version":"v3","created":"Thu, 10 Mar 2022 17:14:16 GMT"}],"update_date":"2022-03-11"}
{"id":"2110.08301","submitter":"Giuseppe Dibitetto","authors":"Giuseppe Dibitetto","title":"Positive energy and non-SUSY flows in ISO(7) gauged supergravity","comments":"Minor changes, refs added, published version; 18 pages, 6 figures","journal-ref":"Universe 2022, 8(5), 293","doi":"10.3390/universe8050293","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider maximal gauged supergravity in 4D with ISO(7) gauge group, which\narises from a consistent truncation of massive IIA supergravity on a\nsix-sphere. Within its G$_2$ invariant sector, the theory is known to possess a\nsupersymmetric AdS extremum as well as two non-supersymmetric ones. In this\ncontext we provide a first order formulation of the theory by making use of the\nHamilton-Jacobi (HJ) formalism. This allows us to derive a positive energy\ntheorem for both non-supersymmetric extrema. Subsequently, we also find novel\nnon-supersymmetric domain walls (DW) interpolating between the supersymmetric\nextremum and each of the other two. Finally, we discuss a perturbative HJ\ntechnique that may be used in order to solve for curved DW geometries.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:20:13 GMT"},{"version":"v2","created":"Sat, 28 May 2022 08:13:23 GMT"}],"update_date":"2022-07-19"}
{"id":"2110.08302","submitter":"Pablo Sala","authors":"Pablo Sala and Julius Lehmann and Tibor Rakovszky and Frank Pollmann","title":"Dynamics in Systems with Modulated Symmetries","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We extend the notions of multipole and subsystem symmetries to more general\n{\\it spatially modulated} symmetries. We uncover two instances with exponential\nand (quasi)-periodic modulations, and provide simple microscopic models in one,\ntwo and three dimensions. Seeking to understand their effect in the long-time\ndynamics, we numerically study a stochastic cellular automaton evolution that\nobeys such symmetries. We prove that in one dimension, the periodically\nmodulated symmetries lead to a diffusive scaling of correlations modulated by a\nfinite microscopic momentum. In higher dimensions, these symmetries take the\nform of lines and surfaces of conserved momenta. These give rise to exotic\nforms of sub-diffusive behavior with a rich spatial structure influenced by\nlattice-scale features. Exponential modulation, on the other hand, can lead to\ncorrelations that are infinitely long-lived at the boundary, while decaying\nexponentially in the bulk.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:21:51 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08303","submitter":"Liwei Guo","authors":"Liwei Guo, Felix Xiaozhu Lin","title":"Minimum Viable Device Drivers for ARM TrustZone","comments":"Eurosys 2022","journal-ref":null,"doi":"10.1145/3492321.3519565","report-no":null,"categories":"cs.OS cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  While TrustZone can isolate IO hardware, it lacks drivers for modern IO\ndevices. Rather than porting drivers, we propose a novel approach to deriving\nminimum viable drivers: developers exercise a full driver and record the\ndriver/device interactions; the processed recordings, dubbed driverlets, are\nreplayed in the TEE at run time to access IO devices.\n  Driverlets address two key challenges: correctness and expressiveness, for\nwhich they build on a key construct called interaction template. The\ninteraction template ensures faithful reproduction of recorded IO jobs (albeit\non new IO data); it accepts dynamic input values; it tolerates nondeterministic\ndevice behaviors.\n  We demonstrate driverlets on a series of sophisticated devices, making them\naccessible to TrustZone for the first time to our knowledge. Our experiments\nshow that driverlets are secure, easy to build, and incur acceptable overhead\n(1.4x -2.7x compared to native drivers). Driverlets fill a critical gap in the\nTrustZone TEE, realizing its long-promised vision of secure IO.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:22:10 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 15:50:04 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08304","submitter":"Kohei Kawabata","authors":"Kohei Kawabata and Masahito Ueda","title":"Nonlinear Landauer formula: Nonlinear response theory of disordered and\n  topological materials","comments":"39 pages, 7 figures, 1 table","journal-ref":"Phys. Rev. B 106, 205104 (2022)","doi":"10.1103/PhysRevB.106.205104","report-no":null,"categories":"cond-mat.mes-hall cond-mat.stat-mech quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Landauer formula provides a general scattering formulation of electrical\nconduction. Despite its utility, it has been mainly applied to the\nlinear-response regime, and a scattering theory of nonlinear response has yet\nto be fully developed. Here, we extend the Landauer formula to the\nnonlinear-response regime. We show that while the linear conductance is\ndirectly related to the transmission probability, the nonlinear conductance is\ngiven by its derivatives with respect to energy. This sensitivity to the energy\nderivatives is shown to produce unique nonlinear transport phenomena of\nmesoscopic systems including disordered and topological materials. By way of\nillustration, we investigate nonlinear conductance of disordered chains and\nidentify their universal behavior according to symmetry. In particular, we find\nlarge singular nonlinear conductance for zero modes, including Majorana zero\nmodes in topological superconductors. We also show the critical behavior of\nnonlinear response around the mobility edges due to the Anderson transitions.\nMoreover, we study nonlinear response of graphene as a prime example of\ntopological materials featuring quantum anomaly. Furthermore, considering the\ngeometry of electronic wave functions, we develop a scattering theory of the\nnonlinear Hall effect. We establish a new connection between the nonlinear Hall\nresponse and the nonequilibrium quantum fluctuations. We also discuss the\ninfluence of disorder and Anderson localization on the nonlinear Hall effect.\nOur work opens a new avenue in quantum physics beyond the linear-response\nregime.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:25:26 GMT"},{"version":"v2","created":"Thu, 3 Nov 2022 16:34:31 GMT"}],"update_date":"2022-11-04"}
{"id":"2110.08305","submitter":"Ke Wang","authors":"Ke Wang, T. A. Sedrakyan","title":"Universal finite-size amplitude and anomalous entanglement entropy of\n  $z=2$ quantum Lifshitz criticalities in topological chains","comments":"22 pages, 4 figures","journal-ref":"SciPost Phys. 12, 134 (2022)","doi":"10.21468/SciPostPhys.12.4.134","report-no":null,"categories":"cond-mat.stat-mech cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider Lifshitz criticalities with dynamical exponent $z=2$ that emerge\nin a class of topological chains. There, such a criticality plays a fundamental\nrole in describing transitions between symmetry-enriched conformal field\ntheories (CFTs). We report that, at such critical points in one spatial\ndimension, the finite-size correction to the energy scales with system size,\n$L$, as $\\sim L^{-2}$, with universal and anomalously large coefficient. The\nbehavior originates from the specific dispersion around the Fermi surface,\n$\\epsilon \\propto \\pm k^2$. We also show that the entanglement entropy exhibits\nat the criticality a non-logarithmic dependence on $l/L$, where $l$ is the\nlength of the sub-system. In the limit of $l\\ll L$, the maximally-entangled\nground state has the entropy, $S(l/L)=S_0+2n(l/L)\\log(l/L)$. Here $S_0$ is some\nnon-universal entropy originating from short-range correlations and $n$ is\nhalf-integer or integer depending on the degrees of freedom in the model. We\nshow that the novel entanglement originates from the long-range correlation\nmediated by a zero mode in the low energy sector. The work paves the way to\nstudy finite-size effects and entanglement entropy around Lifshitz\ncriticalities and offers an insight into transitions between symmetry-enriched\ncriticalities.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:27:34 GMT"},{"version":"v2","created":"Sun, 24 Apr 2022 01:39:24 GMT"}],"update_date":"2022-04-26"}
{"id":"2110.08306","submitter":"Qinfeng Xiao","authors":"Qinfeng Xiao, Shikuan Shao, Jing Wang","title":"Memory-augmented Adversarial Autoencoders for Multivariate Time-series\n  Anomaly Detection with Deep Reconstruction and Prediction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Detecting anomalies for multivariate time-series without manual supervision\ncontinues a challenging problem due to the increased scale of dimensions and\ncomplexity of today's IT monitoring systems. Recent progress of unsupervised\ntime-series anomaly detection mainly use deep autoencoders to solve this\nproblem, i.e. training on normal samples and producing significant\nreconstruction error on abnormal inputs. However, in practice, autoencoders can\nreconstruct anomalies so well, due to powerful capabilites of neural networks.\nBesides, these approaches can be ineffective for identifying non-point\nanomalies, e.g. contextual anomalies and collective anomalies, since they\nsolely utilze a point-wise reconstruction objective. To tackle the above\nissues, we propose MemAAE (\\textit{Memory-augmented Adversarial Autoencoders\nwith Deep Reconstruction and Prediction}), a novel unsupervised anomaly\ndetection method for time-series. By jointly training two complementary proxy\ntasks, reconstruction and prediction, with a shared network architecture, we\nshow that detecting anomalies via multiple tasks obtains superior performance\nrather than single-task training. Additionally, a compressive memory module is\nintroduced to preserve normal patterns, avoiding unexpected generalization on\nabnormal inputs. Through extensive experiments, MemAAE achieves an overall F1\nscore of 0.90 on four public datasets, significantly outperforming the best\nbaseline by 0.02.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:29:05 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08307","submitter":"Yasmeen Hitti","authors":"Yasmeen Hitti, Ionelia Buzatu, Manuel Del Verme, Mark Lefsrud, Florian\n  Golemo, Audrey Durand","title":"GrowSpace: Learning How to Shape Plants","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Plants are dynamic systems that are integral to our existence and survival.\nPlants face environment changes and adapt over time to their surrounding\nconditions. We argue that plant responses to an environmental stimulus are a\ngood example of a real-world problem that can be approached within a\nreinforcement learning (RL)framework. With the objective of controlling a plant\nby moving the light source, we propose GrowSpace, as a new RL benchmark. The\nback-end of the simulator is implemented using the Space Colonisation\nAlgorithm, a plant growing model based on competition for space. Compared to\nvideo game RL environments, this simulator addresses a real-world problem and\nserves as a test bed to visualize plant growth and movement in a faster way\nthan physical experiments. GrowSpace is composed of a suite of challenges that\ntackle several problems such as control, multi-stage learning,fairness and\nmulti-objective learning. We provide agent baselines alongside case studies to\ndemonstrate the difficulty of the proposed benchmark.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:29:46 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08308","submitter":"Sahil Dhoked","authors":"Sahil Dhoked, Neeraj Mittal","title":"Adaptive and Fair Transformation for Recoverable Mutual Exclusion","comments":"arXiv admin note: substantial text overlap with arXiv:2006.07086","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mutual exclusion is one of the most commonly used techniques to handle\ncontention in concurrent systems. Traditionally, mutual exclusion algorithms\nhave been designed under the assumption that a process does not fail while\nacquiring/releasing a lock or while executing its critical section. However,\nfailures do occur in real life, potentially leaving the lock in an inconsistent\nstate. This gives rise to the problem of recoverable mutual exclusion (RME)\nthat involves designing a mutual exclusion (ME) algorithm that can tolerate\nfailures, while maintaining safety and liveness properties.\n  In this work, we present a framework that transforms any algorithm that\nsolves the RME problem into an algorithm that can also simultaneously adapt to\n(1) the number of processes competing for the lock, as well as (2) the number\nof failures that have occurred in the recent past, while maintaining the\ncorrectness and performance properties of the underlying RME algorithm.\nAdditionally, the algorithm constructed as a result of this transformation adds\ncertain desirable properties like fairness (a variation of FCFS) and bounded\nrecovery. Assume that the worst-case RMR complexity of a critical section\nrequest in the underlying RME algorithm is $R(n)$. Then, our framework yields\nan RME algorithm for which the worst-case RMR complexity of a critical section\nrequest is given by $\\mathcal{O}(\\min \\{\\ddot{c}, \\sqrt{F+1}, R(n)\\})$, where\n$\\ddot{c}$ denotes the point contention of the request and $F$ denotes the\nnumber of failures in the recent past of the request.\n  We further extend our framework by presenting a novel memory reclamation\nalgorithm to bound the worst-case space complexity of the RME algorithm. The\nmemory reclamation techniques maintain the fairness, performance and\ncorrectness properties of our transformation and is general enough to be\nemployed to bound the space of other RME algorithms.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:35:24 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08309","submitter":"Andr\\'e Carvalho","authors":"Andr\\'e Carvalho","title":"On endomorphisms of automatic groups","comments":"36 pages, comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose two geometric versions of the bounded reduction property and find\nconditions for them to coincide. In particular, for the natural automatic\nstructure on a hyperbolic group, the two notions are equivalent. We study\nendomorphisms with $L$-quasiconvex image and prove that those with finite\nkernel satisfy a synchronous version of the bounded reduction property.\nFinally, we use these techniques to prove $L$-quasiconvexity of the equalizer\nof two endomorphisms under certain (strict) conditions.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:39:08 GMT"},{"version":"v2","created":"Fri, 7 Jan 2022 16:31:54 GMT"}],"update_date":"2022-01-10"}
{"id":"2110.08310","submitter":"Han Wu","authors":"Zhilin Luo, Qinghua Pi, Han Wu","title":"Bias of Root Numbers for Hilbert Newforms of Cubic Level","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give a general formula of the bias of root numbers for Hilbert modular\nnewforms of cubic level. Explicit calculation is given when the base field is\n$\\mathbb{Q}, \\mathbb{Q}(\\sqrt{2}), \\mathbb{Q}(\\sqrt{5})$ and the level is the\ncube of certain rational integers. This complements a previous result of the\nsecond author and extends the bias phenomenon to the number fields. Our method\nis based on Jacquet-Zagier's trace formula, and the explicit calculation works\ngenerally for all real quadratic fields of narrow class number one and for\nrational cubic levels.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:40:31 GMT"},{"version":"v2","created":"Sat, 28 May 2022 10:56:16 GMT"}],"update_date":"2022-05-31"}
{"id":"2110.08311","submitter":"Pierre-Yves Coursolle","authors":"Pierre-Yves Coursolle and Emmanuel Haucourt","title":"Non-existing and ill-behaved coequalizers of locally ordered spaces","comments":"21 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GN cs.LO math.CT","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Categories of locally ordered spaces are especially well-adapted to the\nrealization of most precubical sets, though their colimits are not so easy to\ndetermine (in comparison with colimits in the category of d-spaces for\nexample). We use the plural here, as the notion of a locally ordered space vary\nfrom an author to another, only differing according to seemingly anodyne\ntechnical details. As we explain in this article, these differences have\ndramatic consequences on colimits. In particular, we show that most categories\nof locally ordered spaces are not cocomplete, thus answering a question that\nwas neglected so far. The strategy is the following: given a directed loop\n{\\gamma} on a locally ordered space X, we try to identify the image of {\\gamma}\nwith a single point. If it were taken in the category of d-spaces, such an\nidentification would be likely to create a vortex, while locally ordered spaces\nhave no vortices. Concretely, the antisymmetry of local orders gets more points\nto be identified than in a mere topological quotient. However, the effect of\nthis phenomenon is in some sense limited to the neighbourhood of (the image of)\n{\\gamma}. So the existence and the nature of the corresponding coequalizer\nstrongly depends on the topology around the image of {\\gamma}. As an extreme\nexample, if the latter forms a connected component, the coequalizer exists and\nits underlying space matches with the topological coequalizer.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:41:07 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08312","submitter":"Victoria Chayes","authors":"Victoria M. Chayes","title":"Hanner's Inequality For Positive Semidefinite Matrices","comments":"Error in Theorem 3.1 requires significant correction","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.OA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove an analogous Hanner's Inequality of $L^p$ spaces for positive\nsemidefinite matrices. Let $||X||_p=\\text{Tr}[(X^\\ast X)^{p/2}]^{1/p}$ denote\nthe $p$-Schatten norm of a matrix $X\\in M_{n\\times n}(\\mathbb{C})$. We show\nthat the inequality $||X+Y||_p^p+||X-Y||_p^p\\geq\n(||X||_p+||Y||_p)^p+(|||X||_p-||Y||_p|)^p$ holds for $1\\leq p\\leq 2$ and\nreverses for $p\\geq 2$ when $X,Y\\in M_{n\\times n}(\\mathbb{C})^+$. This was\npreviously known in the $1<p\\leq 4/3$, $p=2$, and $p\\geq 4$ cases, or with\nadditional special assumptions. We outline these previous methods, and comment\non their failure to extend to the general case. We further show that there is\nequality if and only if $Y=cX$, which is analogous to the equality case in\n$L^p$. With the general inequality, it is confirmed that the unit ball in\n$C^{p}_+$ has the same moduli of smoothness and convexity as the unit ball in\n$L^p$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:41:08 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 20:26:38 GMT"},{"version":"v3","created":"Wed, 18 May 2022 14:06:49 GMT"}],"update_date":"2022-05-19"}
{"id":"2110.08313","submitter":"Shweta Singh","authors":"William Farlessyost and Shweta Singh","title":"Reduced Order Dynamical Models For Complex Dynamics in Manufacturing and\n  Natural Systems Using Machine Learning","comments":"16 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.LG cs.SY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Dynamical analysis of manufacturing and natural systems provides critical\ninformation about production of manufactured and natural resources\nrespectively, thus playing an important role in assessing sustainability of\nthese systems. However, current dynamic models for these systems exist as\nmechanistic models, simulation of which is computationally intensive and does\nnot provide a simplified understanding of the mechanisms driving the overall\ndynamics. For such systems, lower-order models can prove useful to enable\nsustainability analysis through coupled dynamical analysis. There have been few\nattempts at finding low-order models of manufacturing and natural systems, with\nexisting work focused on model development of individual mechanism level. This\nwork seeks to fill this current gap in the literature of developing simplified\ndynamical models for these systems by developing reduced-order models using a\nmachine learning (ML) approach. The approach is demonstrated on an entire\nsoybean-oil to soybean-diesel process plant and a lake system. We use a\ngrey-box ML method with a standard nonlinear optimization approach to identify\nrelevant models of governing dynamics as ODEs using the data simulated from\nmechanistic models. Results show that the method identifies a high accuracy\nlinear ODE models for the process plant, reflective of underlying linear\nstoichiometric mechanisms and mass balance driving the dynamics. For the\nnatural systems, we modify the ML approach to include the effect of past\ndynamics, which gives non-linear ODE. While the modified approach provides a\nbetter match to dynamics of stream flow, it falls short of completely\nrecreating the dynamics. We conclude that the proposed ML approach work well\nfor systems where dynamics is smooth, such as in manufacturing plant whereas\ndoes not work perfectly well in case of chaotic dynamics such as water stream\nflow.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:44:27 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08314","submitter":"Jie Yang","authors":"Yili Ren and Jie Yang","title":"3D Human Pose Estimation for Free-form Activity Using WiFi Signals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  WiFi human sensing has become increasingly attractive in enabling emerging\nhuman-computer interaction applications. The corresponding technique has\ngradually evolved from the classification of multiple activity types to more\nfine-grained tracking of 3D human poses. However, existing WiFi-based 3D human\npose tracking is limited to a set of predefined activities. In this work, we\npresent Winect, a 3D human pose tracking system for free-form activity using\ncommodity WiFi devices. Our system tracks free-form activity by estimating a 3D\nskeleton pose that consists of a set of joints of the human body. In\nparticular, we combine signal separation and joint movement modeling to achieve\nfree-form activity tracking. Our system first identifies the moving limbs by\nleveraging the two-dimensional angle of arrival of the signals reflected off\nthe human body and separates the entangled signals for each limb. Then, it\ntracks each limb and constructs a 3D skeleton of the body by modeling the\ninherent relationship between the movements of the limb and the corresponding\njoints. Our evaluation results show that Winect is environment-independent and\nachieves centimeter-level accuracy for free-form activity tracking under\nvarious challenging environments including the none-line-of-sight (NLoS)\nscenarios.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:47:16 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08315","submitter":"Naoki Koseki","authors":"Naoki Koseki","title":"Categorical blow-up formula for Hilbert schemes of points","comments":"12 pages, improvements based on referee's comments","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $S$ be a smooth projective surface, and $\\hat{S}$ be its blow-up at a\npoint. In this paper, we study the derived category of the Hilbert scheme of\npoints on the blow-up $\\hat{S}$. We obtain a semi-orthogonal decomposition\nconsisting of the derived categories of the Hilbert schemes on the original\nsurface $S$, which recovers the blow-up formula for the Euler characteristics\nobtained by G\\\"ottsche and Nakajima-Yoshioka. The proof uses the Quot formula,\nwhich was conjectured by Jiang and recently proved by Toda.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:49:28 GMT"},{"version":"v2","created":"Wed, 3 Nov 2021 10:24:25 GMT"},{"version":"v3","created":"Sat, 10 Sep 2022 14:24:26 GMT"}],"update_date":"2022-09-13"}
{"id":"2110.08316","submitter":"Eric Keto","authors":"Eric Keto and Rolf Kuiper","title":"Stability of an Ionization Front in Bondi Accretion","comments":"Accepted MNRAS; 8 pages, 5 figures","journal-ref":null,"doi":"10.1093/mnras/stab3011","report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Spherical Bondi accretion is used in astrophysics as an approximation to\ninvestigate many types of accretion processes. Two-phase accretion flows that\ntransition from neutral to ionized have observational support in high-mass star\nformation, and have application to accretion flows around any ionizing source,\nbut the hydrodynamic stability of two-phase Bondi accretion is not understood.\nWith both semi-analytic and fully numerical methods we find that these flows\nmay be stable, conditionally stable or unstable depending on the initial\nconditions. The transition from an R-type to a D-type ionization front plays a\nkey role in conditionally stable and unstable flows.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:51:33 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08317","submitter":"Anastasios Papazafeiropoulos","authors":"Anastasios Papazafeiropoulos, Pandelis Kourtessis, Symeon Chatzinotas,\n  John M. Senior","title":"Coverage Probability of Double-IRS Assisted Communication Systems","comments":"accepted in IEEE Wireless Communications Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we focus on the coverage probability of a double-intelligent\nreflecting surface (IRS) assisted wireless network and study the impact of\nmultiplicative beamforming gain and correlated Rayleigh fading. In particular,\nwe obtain a novel closed-form expression of the coverage probability of a\nsingle-input single-output (SISO) system assisted by two large IRSs while being\ndependent on the corresponding arbitrary reflecting beamforming matrices (RBMs)\nand large-scale statistics in terms of correlation matrices. Taking advantage\nof the large-scale statistics, i.e., statistical channel state information\n(CSI), we perform optimization of the RBMs of both IRSs once per several\ncoherence intervals rather than at each interval. Hence, we achieve a reduction\nof the computational complexity, otherwise increased in multi-IRS-assisted\nnetworks during their RBM optimization. Numerical results validate the\nanalytical expressions even for small IRSs, confirm enhanced performance over\nthe conventional single-IRS counterpart, and reveal insightful properties.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:53:02 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08318","submitter":"Harsha Kokel","authors":"Harsha Kokel, Arjun Manoharan, Sriraam Natarajan, Balaraman Ravindran,\n  Prasad Tadepalli","title":"Dynamic probabilistic logic models for effective abstractions in RL","comments":"Accepted at StarAI 2021 (held in conjunction with IJCLR 2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  State abstraction enables sample-efficient learning and better task transfer\nin complex reinforcement learning environments. Recently, we proposed RePReL\n(Kokel et al. 2021), a hierarchical framework that leverages a relational\nplanner to provide useful state abstractions for learning. We present a brief\noverview of this framework and the use of a dynamic probabilistic logic model\nto design these state abstractions. Our experiments show that RePReL not only\nachieves better performance and efficient learning on the task at hand but also\ndemonstrates better generalization to unseen tasks.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:53:04 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08319","submitter":"Sam Miller","authors":"Sam K. Miller, Arthur T. Benjamin","title":"Optimal Leapfrogging, A Complete Guide","comments":"In progress for submission","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Suppose we have some checkers placed in the lower-left corner of a Go board,\nand wish to move them to the upper right corner in as few moves as possible,\nwhere the pieces move as they would in the game of Chinese Checkers. In 1993,\nAuslander, Benjamin, and Wilkerson generalized this game for integer lattices,\ndefined a measure of speed for a starting configuration of pieces, and proved\nthat a maximum speed exists, which only three configurations, called\n\"speed-of-light\" configurations can attain. It was conjectured that the maximum\nspeed of a non-speed-of-light configuration has a smaller upper bound, which we\nprove.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:54:54 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08320","submitter":"Zhenyu Cui","authors":"Jingtang Ma, Wensheng Yang, Zhenyu Cui","title":"Semimartingale and continuous-time Markov chain approximation for rough\n  stochastic local volatility models","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.MF q-fin.CP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Rough volatility models have recently been empirically shown to provide a\ngood fit to historical volatility time series and implied volatility smiles of\nSPX options. They are continuous-time stochastic volatility models, whose\nvolatility process is driven by a fractional Brownian motion with Hurst\nparameter less than half. Due to the challenge that it is neither a\nsemimartingale nor a Markov process, there is no unified method that not only\napplies to all rough volatility models, but also is computationally efficient.\nThis paper proposes a semimartingale and continuous-time Markov chain (CTMC)\napproximation approach for the general class of rough stochastic local\nvolatility (RSLV) models. In particular, we introduce the perturbed stochastic\nlocal volatility (PSLV) model as the semimartingale approximation for the RSLV\nmodel and establish its existence , uniqueness and Markovian representation. We\npropose a fast CTMC algorithm and prove its weak convergence. Numerical\nexperiments demonstrate the accuracy and high efficiency of the method in\npricing European, barrier and American options. Comparing with existing\nliterature, a significant reduction in the CPU time to arrive at the same level\nof accuracy is observed.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:01:29 GMT"},{"version":"v2","created":"Fri, 29 Oct 2021 15:40:05 GMT"}],"update_date":"2021-11-01"}
{"id":"2110.08321","submitter":"Han Xuanyuan","authors":"Han Xuanyuan, Francisco Vargas, Stephen Cummins","title":"Efficient privacy-preserving inference for convolutional neural networks","comments":"8 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The processing of sensitive user data using deep learning models is an area\nthat has gained recent traction. Existing work has leveraged homomorphic\nencryption (HE) schemes to enable computation on encrypted data. An early work\nwas CryptoNets, which takes 250 seconds for one MNIST inference. The main\nlimitation of such approaches is that of the expensive FFT-like operations\nrequired to perform operations on HE-encrypted ciphertext. Others have proposed\nthe use of model pruning and efficient data representations to reduce the\nnumber of HE operations required. We focus on improving upon existing work by\nproposing changes to the representations of intermediate tensors during CNN\ninference. We construct and evaluate private CNNs on the MNIST and CIFAR-10\ndatasets, and achieve over a two-fold reduction in the number of operations\nused for inferences of the CryptoNets architecture.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:03:35 GMT"},{"version":"v2","created":"Fri, 26 Aug 2022 16:28:39 GMT"}],"update_date":"2022-08-29"}
{"id":"2110.08322","submitter":"Vishal Rajput","authors":"Vishal Rajput","title":"Robustness of different loss functions and their impact on networks\n  learning capability","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Recent developments in AI have made it ubiquitous, every industry is trying\nto adopt some form of intelligent processing of their data. Despite so many\nadvances in the field, AIs full capability is yet to be exploited by the\nindustry. Industries that involve some risk factors still remain cautious about\nthe usage of AI due to the lack of trust in such autonomous systems.\nPresent-day AI might be very good in a lot of things but it is very bad in\nreasoning and this behavior of AI can lead to catastrophic results. Autonomous\ncars crashing into a person or a drone getting stuck in a tree are a few\nexamples where AI decisions lead to catastrophic results. To develop insight\nand generate an explanation about the learning capability of AI, we will try to\nanalyze the working of loss functions. For our case, we will use two sets of\nloss functions, generalized loss functions like Binary cross-entropy or BCE and\nspecialized loss functions like Dice loss or focal loss. Through a series of\nexperiments, we will establish whether combining different loss functions is\nbetter than using a single loss function and if yes, then what is the reason\nbehind it. In order to establish the difference between generalized loss and\nspecialized losses, we will train several models using the above-mentioned\nlosses and then compare their robustness on adversarial examples. In\nparticular, we will look at how fast the accuracy of different models decreases\nwhen we change the pixels corresponding to the most salient gradients.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:12:42 GMT"},{"version":"v2","created":"Tue, 9 Nov 2021 15:00:23 GMT"}],"update_date":"2021-11-10"}
{"id":"2110.08323","submitter":"Sankalan Pal Chowdhury","authors":"Sankalan Pal Chowdhury, Adamos Solomou, Avinava Dubey and Mrinmaya\n  Sachan","title":"On Learning the Transformer Kernel","comments":"Accepted to TMLR","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this work we introduce KERNELIZED TRANSFORMER, a generic, scalable, data\ndriven framework for learning the kernel function in Transformers. Our\nframework approximates the Transformer kernel as a dot product between spectral\nfeature maps and learns the kernel by learning the spectral distribution. This\nnot only helps in learning a generic kernel end-to-end, but also reduces the\ntime and space complexity of Transformers from quadratic to linear. We show\nthat KERNELIZED TRANSFORMERS achieve performance comparable to existing\nefficient Transformer architectures, both in terms of accuracy as well as\ncomputational efficiency. Our study also demonstrates that the choice of the\nkernel has a substantial impact on performance, and kernel learning variants\nare competitive alternatives to fixed kernel Transformers, both in long as well\nas short sequence tasks.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:20:25 GMT"},{"version":"v2","created":"Thu, 21 Jul 2022 16:07:06 GMT"}],"update_date":"2022-07-22"}
{"id":"2110.08324","submitter":"Xinyu Tang","authors":"Xinyu Tang, Saeed Mahloujifar, Liwei Song, Virat Shejwalkar, Milad\n  Nasr, Amir Houmansadr, Prateek Mittal","title":"Mitigating Membership Inference Attacks by Self-Distillation Through a\n  Novel Ensemble Architecture","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Membership inference attacks are a key measure to evaluate privacy leakage in\nmachine learning (ML) models. These attacks aim to distinguish training members\nfrom non-members by exploiting differential behavior of the models on member\nand non-member inputs. The goal of this work is to train ML models that have\nhigh membership privacy while largely preserving their utility; we therefore\naim for an empirical membership privacy guarantee as opposed to the provable\nprivacy guarantees provided by techniques like differential privacy, as such\ntechniques are shown to deteriorate model utility. Specifically, we propose a\nnew framework to train privacy-preserving models that induces similar behavior\non member and non-member inputs to mitigate membership inference attacks. Our\nframework, called SELENA, has two major components. The first component and the\ncore of our defense is a novel ensemble architecture for training. This\narchitecture, which we call Split-AI, splits the training data into random\nsubsets, and trains a model on each subset of the data. We use an adaptive\ninference strategy at test time: our ensemble architecture aggregates the\noutputs of only those models that did not contain the input sample in their\ntraining data. We prove that our Split-AI architecture defends against a large\nfamily of membership inference attacks, however, it is susceptible to new\nadaptive attacks. Therefore, we use a second component in our framework called\nSelf-Distillation to protect against such stronger attacks. The\nSelf-Distillation component (self-)distills the training dataset through our\nSplit-AI ensemble, without using any external public datasets. Through\nextensive experiments on major benchmark datasets we show that SELENA presents\na superior trade-off between membership privacy and utility compared to the\nstate of the art.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:22:52 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08325","submitter":"Elisabeth Lobe","authors":"Elisabeth Lobe, Annette Lutz","title":"Minor Embedding in Broken Chimera and Pegasus Graphs is NP-complete","comments":"36 pages, 21 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.CC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The embedding is an essential step when calculating on the D-Wave machine. In\nthis work we show the hardness of the embedding problem for both types of\nexisting hardware, represented by the Chimera and the Pegasus graphs,\ncontaining unavailable qubits. We construct certain broken Chimera graphs,\nwhere it is hard to find a Hamiltonian cycle. As the Hamiltonian cycle problem\nis a special case of the embedding problem, this proves the general complexity\nresult for the Chimera graphs. By exploiting the subgraph relation between the\nChimera and the Pegasus graphs, the proof is then further extended to the\nPegasus graphs.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:23:33 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08326","submitter":"Alexander Sietsema","authors":"Alexander N. Sietsema, Michael T. McCann, Marc L. Klasky, and\n  Saiprasad Ravishankar","title":"Comparing One-step and Two-step Scatter Correction and Density\n  Reconstruction in X-ray CT","comments":null,"journal-ref":"Proc. SPIE 12304, 7th International Conference on Image Formation\n  in X-Ray Computed Tomography, 123042E, 2022","doi":"10.1117/12.2647151","report-no":null,"categories":"eess.IV eess.SP physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we compare one-step and two-step approaches for X-ray computed\ntomography (CT) scatter correction and density reconstruction. X-ray CT is an\nimportant imaging technique in medical and industrial applications. In many\ncases, the presence of scattered X-rays leads to loss of contrast and\nundesirable artifacts in reconstructed images. Many approaches to\ncomputationally removing scatter treat scatter correction as a preprocessing\nstep that is followed by a reconstruction step. Treating scatter correction and\nreconstruction jointly as a single, more complicated optimization problem is\nless studied. It is not clear from the existing literature how these two\napproaches compare in terms of reconstruction accuracy. In this paper, we\ncompare idealized versions of these two approaches with synthetic experiments.\nOur results show that the one-step approach can offer improved reconstructions\nover the two-step approach, although the gap between them is highly\nobject-dependent.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:24:09 GMT"},{"version":"v2","created":"Fri, 13 May 2022 16:49:21 GMT"}],"update_date":"2023-01-11"}
{"id":"2110.08327","submitter":"Pascal Getreuer","authors":"Pascal Tom Getreuer, Peyman Milanfar, Xiyang Luo","title":"Solving Image PDEs with a Shallow Network","comments":"21 pages, 22 figures, references arXiv:1802.06130, arXiv:1711.10700,\n  arXiv:1606.01299","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG eess.IV math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Partial differential equations (PDEs) are typically used as models of\nphysical processes but are also of great interest in PDE-based image\nprocessing. However, when it comes to their use in imaging, conventional\nnumerical methods for solving PDEs tend to require very fine grid resolution\nfor stability, and as a result have impractically high computational cost. This\nwork applies BLADE (Best Linear Adaptive Enhancement), a shallow learnable\nfiltering framework, to PDE solving, and shows that the resulting approach is\nefficient and accurate, operating more reliably at coarse grid resolutions than\nclassical methods. As such, the model can be flexibly used for a wide variety\nof problems in imaging.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:25:30 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08328","submitter":"Carla Henr\\'iquez-B\\'aez","authors":"Carla Henr\\'iquez-B\\'aez","title":"On the stability of homogeneous black strings in AdS","comments":"6 pages, 2 figures. Based on a Contribution to the Conference XXII\n  Simposio Chileno de F\\'isica 2020. V2: typos fixed and references added","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we extend the analysis of the stability of an homogeneous black\nstring in the presence of a negative cosmological constant with minimally\ncoupled scalar fields. We recall the linear stability of this solutions under\ngeneric perturbations on the metric and of the scalar fields. Then, we extend\nthe study of the stability by presenting the existence of a non-generic\nperturbation which may lead to an unstable behavior. The later mode is\nfine-tuned since it requires the scalar field degree of freedom to be absent\nthrough the whole evolution of the system.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:31:02 GMT"},{"version":"v2","created":"Tue, 8 Feb 2022 20:36:14 GMT"}],"update_date":"2022-02-10"}
{"id":"2110.08329","submitter":"Jordan Clive","authors":"Jordan Clive, Kris Cao, Marek Rei","title":"Control Prefixes for Parameter-Efficient Text Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Prefix-tuning is a powerful lightweight technique for adapting a large\npre-trained language model to a downstream application. However, it uses the\nsame dataset-level tuned prompt for all examples in the dataset. We extend this\nidea and propose a dynamic method, Control Prefixes, which allows for the\ninclusion of conditional input-dependent information, combining the benefits of\nprompt tuning and controlled generation. The method incorporates\nattribute-level learnable representations into different layers of a\npre-trained transformer, allowing for the generated text to be guided in a\nparticular direction. We provide a systematic evaluation of the technique and\napply it to five datasets from the GEM benchmark for natural language\ngeneration (NLG). Although the aim is to develop a parameter-efficient model,\nwe show Control Prefixes can even outperform full fine-tuning methods. We\npresent state-of-the-art results on several data-to-text datasets, including\nWebNLG.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:32:17 GMT"},{"version":"v2","created":"Tue, 10 May 2022 16:54:15 GMT"}],"update_date":"2022-05-11"}
{"id":"2110.08330","submitter":"Qin Hu","authors":"Qin Hu, Shengling Wang, Zeihui Xiong, Xiuzhen Cheng","title":"Nothing Wasted: Full Contribution Enforcement in Federated Edge Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The explosive amount of data generated at the network edge makes mobile edge\ncomputing an essential technology to support real-time applications, calling\nfor powerful data processing and analysis provided by machine learning (ML)\ntechniques. In particular, federated edge learning (FEL) becomes prominent in\nsecuring the privacy of data owners by keeping the data locally used to train\nML models. Existing studies on FEL either utilize in-process optimization or\nremove unqualified participants in advance. In this paper, we enhance the\ncollaboration from all edge devices in FEL to guarantee that the ML model is\ntrained using all available local data to accelerate the learning process. To\nthat aim, we propose a collective extortion (CE) strategy under the\nimperfect-information multi-player FEL game, which is proved to be effective in\nhelping the server efficiently elicit the full contribution of all devices\nwithout worrying about suffering from any economic loss. Technically, our\nproposed CE strategy extends the classical extortion strategy in controlling\nthe proportionate share of expected utilities for a single opponent to the\nswiftly homogeneous control over a group of players, which further presents an\nattractive trait of being impartial for all participants. Moreover, the CE\nstrategy enriches the game theory hierarchy, facilitating a wider application\nscope of the extortion strategy. Both theoretical analysis and experimental\nevaluations validate the effectiveness and fairness of our proposed scheme.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:32:37 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08331","submitter":"Francisco Valente","authors":"Francisco Valente, Jorge Henriques, Sim\\~ao Paredes, Teresa Rocha,\n  Paulo de Carvalho, Jo\\~ao Morais","title":"A New Approach for Interpretability and Reliability in Clinical Risk\n  Prediction: Acute Coronary Syndrome Scenario","comments":"Accepted for publication in the Artificial Intelligence in Medicine\n  journal. Abstract abridged to respect the arXiv's characters limit","journal-ref":"Artificial Intelligence in Medicine, Volume 117, 2021","doi":"10.1016/j.artmed.2021.102113","report-no":null,"categories":"cs.LG stat.AP stat.ME","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We intend to create a new risk assessment methodology that combines the best\ncharacteristics of both risk score and machine learning models. More\nspecifically, we aim to develop a method that, besides having a good\nperformance, offers a personalized model and outcome for each patient, presents\nhigh interpretability, and incorporates an estimation of the prediction\nreliability which is not usually available. By combining these features in the\nsame approach we expect that it can boost the confidence of physicians to use\nsuch a tool in their daily activity. In order to achieve the mentioned goals, a\nthree-step methodology was developed: several rules were created by\ndichotomizing risk factors; such rules were trained with a machine learning\nclassifier to predict the acceptance degree of each rule (the probability that\nthe rule is correct) for each patient; that information was combined and used\nto compute the risk of mortality and the reliability of such prediction. The\nmethodology was applied to a dataset of patients admitted with any type of\nacute coronary syndromes (ACS), to assess the 30-days all-cause mortality risk.\nThe performance was compared with state-of-the-art approaches: logistic\nregression (LR), artificial neural network (ANN), and clinical risk score model\n(Global Registry of Acute Coronary Events - GRACE). The proposed approach\nachieved testing results identical to the standard LR, but offers superior\ninterpretability and personalization; it also significantly outperforms the\nGRACE risk model and the standard ANN model. The calibration curve also\nsuggests a very good generalization ability of the obtained model as it\napproaches the ideal curve. Finally, the reliability estimation of individual\npredictions presented a great correlation with the misclassifications rate.\nThose properties may have a beneficial application in other clinical scenarios\nas well. [abridged]\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:33:46 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08332","submitter":"Fei Zhou","authors":"Fei Zhou","title":"Topological Quantum Critical Points in Strong Coupling limits: Global\n  Symmetries and Strongly Interacting Majorana Fermions","comments":"20 pages, 4 figures. Comments are welcome","journal-ref":"Phys.Rev. B 105, 014503 (2022)","doi":"10.1103/PhysRevB.105.014503","report-no":null,"categories":"cond-mat.str-el cond-mat.supr-con","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we discuss strong coupling limits of topological quantum\ncritical points (TQCPs) where quantum phase transitions between two topological\ndistinct superconducting states take place. We illustrate that while\nsuperconducting phases on both sides of TQCPs spontaneously break same\nsymmetries, universality classes of critical states can be identified only when\nglobal symmetries in topological states are further specified. In dimensions\n$d=2,3$, we find that continuous $(d+1)$th order transitions at weakly\ninteracting TQCPs that were pointed out previously in the presence of emergent\nLorentz symmetry can be terminated by strongly interacting fixed points of\nmajorana fields. For $2d$ time reversal symmetry breaking TQCPs, termination\npoints are supersymmetric with ${\\mathcal N}=4N_f={1}$ (where $N_f$ is the\nnumber of four-component Dirac fermions and ${\\mathcal N}$ is the number of\ntwo-component real fermions) beyond which transitions are discontinuous first\norder ones. For $2d$ time reversal symmetric TQCPs without other global\nsymmetries, termination points of $(d+1)$th order continuous transition lines\nare generically conformal invariant without supersymmetry. Beyond these strong\ncoupling fixed points, there are first-order discontinuous transitions as far\nas the protecting symmetry is not spontaneously broken but no direct\ntransitions if the protecting symmetry is spontaneously broken in the presence\nof strong interactions. In $3d$, strong coupling termination points can be\nfurther effectively represented by new emergent gapless real bosons weakly\ncoupled with free gapless majorana fermions. However, in $1d$, time reversal\nsymmetric $(d+1)$th continuous transition lines of TQCPs are terminated by\nsimple free majorana fermion fixed points.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:39:05 GMT"}],"update_date":"2022-01-04"}
{"id":"2110.08333","submitter":"Sanjib Kumar Agarwalla","authors":"Anil Kumar and Sanjib Kumar Agarwalla","title":"Probing the Earth's Core using Atmospheric Neutrinos at INO","comments":"6 pages, 3 figures, 2 tables; contribution to proceedings of The\n  European Physical Society Conference on High Energy Physics (EPS-HEP2021)","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The proposed 50 kt Iron Calorimeter (ICAL) detector at the India-based\nNeutrino Observatory (INO) aims to detect atmospheric muon neutrinos and\nantineutrinos separately in the multi-GeV range of energies and over a wide\nrange of path lengths. While passing through the Earth, the upward-going\nneutrinos experience a density-dependent matter effect, which can be utilized\nto extract information about the internal structure of Earth. Since the Earth's\nmatter effect modifies the neutrino oscillation patterns differently for\nneutrinos and antineutrinos, the capability of ICAL to distinguish $\\mu^-$ and\n$\\mu^+$ events plays an important role in observing this matter effect. Taking\nadvantage of good angular resolution, ICAL would be able to observe about 331\n$\\mu^-$ and 146 $\\mu^+$ events corresponding to the core-passing neutrinos and\nantineutrinos, respectively, in 10 years. We demonstrate for the first time\nthat ICAL would be able to validate the presence of Earth's core by ruling out\na two-layered profile consisting of only mantle and crust in fit with respect\nto the PREM profile in data with a median $\\Delta \\chi^2$ of 7.45 for normal\nmass ordering (NO) and 4.83 for inverted mass ordering (IO) using 500\nkt$\\cdot$yr exposure. If we do not use the charge identification capability of\nICAL, these sensitivities deteriorate to a $\\Delta\\chi^2$ of 3.76 for NO and\n1.59 for IO.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:41:19 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08334","submitter":"Aditya Dhumuntarao","authors":"Aditya Dhumuntarao and Rafid Mahbub","title":"Gravitational Instabilities of Uniform Black Strings in AdS","comments":"v1: 6 Pages; 2 Figures; Comments are welcome; v2: Corrected typos.\n  Added references. Added a note. Submitted to PRL; v3: Added a figure","journal-ref":null,"doi":"10.1103/PhysRevD.105.L041501","report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Locally AdS$_{d-1}\\times\\mathbb{R}$ uniform black strings (UBS) in the\npresence of a massless scalar field are believed to avoid the onset of the\nGregory-Laflamme (GL) instability in $d\\ge4$ as no tachyonic modes exist in the\nspectrum of the Laplace-Beltrami operator. We present analytic and numerical\nevidence of GL modes in the Lichnerowicz spectrum indicating that AdS$_{d-1}$\nUBSs are classically and thermodynamically unstable at the linear level in\n$d>4$. In $d=4$, we confirm that uniform BTZ$_3$ strings are indeed stable as\npreviously suggested. We propose that linear instabilities of black strings are\ntriggered if and only if a tachyonic mode exists in the Lichnerowicz spectrum.\nAt the end state of the instability, AdS$_{d-1}$ UBSs of finite length may\ntunnel to a SAdS$_d$ black hole or converge onto a novel non-uniform AdS$_d$\nblack string. We conjecture that weak cosmic censorship is violated if the\nnon-uniform solution is an exact AdS$_d$ black funnel and compute entropy\nestimates in $d>4$ as evidence.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:43:07 GMT"},{"version":"v2","created":"Fri, 22 Oct 2021 19:24:47 GMT"},{"version":"v3","created":"Tue, 26 Oct 2021 17:57:34 GMT"}],"update_date":"2022-02-08"}
{"id":"2110.08335","submitter":"Xiaoling Hu Mr","authors":"Xiaoling Hu, Xiao Lin, Michael Cogswell, Yi Yao, Susmit Jha, Chao Chen","title":"Trigger Hunting with a Topological Prior for Trojan Detection","comments":"17 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Despite their success and popularity, deep neural networks (DNNs) are\nvulnerable when facing backdoor attacks. This impedes their wider adoption,\nespecially in mission critical applications. This paper tackles the problem of\nTrojan detection, namely, identifying Trojaned models -- models trained with\npoisoned data. One popular approach is reverse engineering, i.e., recovering\nthe triggers on a clean image by manipulating the model's prediction. One major\nchallenge of reverse engineering approach is the enormous search space of\ntriggers. To this end, we propose innovative priors such as diversity and\ntopological simplicity to not only increase the chances of finding the\nappropriate triggers but also improve the quality of the found triggers.\nMoreover, by encouraging a diverse set of trigger candidates, our method can\nperform effectively in cases with unknown target labels. We demonstrate that\nthese priors can significantly improve the quality of the recovered triggers,\nresulting in substantially improved Trojan detection accuracy as validated on\nboth synthetic and publicly available TrojAI benchmarks.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:47:00 GMT"},{"version":"v2","created":"Sat, 2 Apr 2022 04:36:03 GMT"}],"update_date":"2022-04-05"}
{"id":"2110.08336","submitter":"Koen Schouten","authors":"K.J.M. Schouten, V. Cheianov","title":"Rapid-cycle Thouless pumping in a one-dimensional optical lattice","comments":"10 pages, 9 figures","journal-ref":null,"doi":"10.1103/PhysRevA.104.063315","report-no":null,"categories":"cond-mat.quant-gas","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An adiabatic cycle around a degeneracy point in the parameter space of a\none-dimensional band insulator is known to result in an integer valued\nnoiseless particle transport in the thermodynamic limit. Recently, it was shown\nthat in the case of an infinite bipartite lattice the adiabatic Thouless\nprotocol can be continuously deformed into a fine tuned finite-frequency cycle\npreserving the properties of noiseless quantized transport. In this paper, we\nnumerically investigate the implementation of such an ideal rapid-cycle\nThouless pumping protocol in a one-dimensional optical lattice. It is shown\nthat the rapidity will cause first order corrections due to\nnext-to-nearest-neighbour hopping and second order corrections due to the\naddition of a harmonic potential. Lastly, the quantization of the change in\ncenter of mass of the particle distribution is investigated, and shown to have\ncorrections in the first order of the potential curvature.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:49:48 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 17:05:37 GMT"}],"update_date":"2021-12-22"}
{"id":"2110.08337","submitter":"Pedro Felix Silva J\\'unior","authors":"Pedro F. da Silva J\\'unior","title":"On the Integrability of Pfaffian Forms on ${\\mathbb R}^{n}$","comments":"16 pages. Submitted","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper details the lesser known conditions on ${\\mathbb {R}}^{n}$ for the\nintegrability of pfaffian forms, or 1-forms. Emphasis is given to locality of\nthese conditions, and proofs in some additional detail are provided for\ntheorems due to Clairaut and Carath\\'eodory. Considering the importance of the\nintegrability of pfaffian forms, in particular in mathematical-physics, this\npaper shows that: there is a hidden content in Carath\\'eodory's theorem in the\ndirection of a global integrability.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:50:19 GMT"},{"version":"v2","created":"Thu, 11 Nov 2021 01:21:13 GMT"},{"version":"v3","created":"Sun, 30 Jan 2022 15:30:31 GMT"}],"update_date":"2022-02-01"}
{"id":"2110.08338","submitter":"Mengjiao Han","authors":"Mengjiao Han, Sudhanshu Sane, Chris R. Johnson","title":"Exploratory Lagrangian-Based Particle Tracing Using Deep Learning","comments":"The paper has been accepted to publish by Journal of Flow\n  Visualization and Image Processing","journal-ref":null,"doi":"10.1615/JFlowVisImageProc.2022041197","report-no":null,"categories":"cs.LG physics.flu-dyn","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Time-varying vector fields produced by computational fluid dynamics\nsimulations are often prohibitively large and pose challenges for accurate\ninteractive analysis and exploration. To address these challenges, reduced\nLagrangian representations have been increasingly researched as a means to\nimprove scientific time-varying vector field exploration capabilities. This\npaper presents a novel deep neural network-based particle tracing method to\nexplore time-varying vector fields represented by Lagrangian flow maps. In our\nworkflow, in situ processing is first utilized to extract Lagrangian flow maps,\nand deep neural networks then use the extracted data to learn flow field\nbehavior. Using a trained model to predict new particle trajectories offers a\nfixed small memory footprint and fast inference. To demonstrate and evaluate\nthe proposed method, we perform an in-depth study of performance using a\nwell-known analytical data set, the Double Gyre. Our study considers two flow\nmap extraction strategies as well as the impact of the number of training\nsamples and integration durations on efficacy, evaluates multiple sampling\noptions for training and testing and informs hyperparameter settings. Overall,\nwe find our method requires a fixed memory footprint of 10.5 MB to encode a\nLagrangian representation of a time-varying vector field while maintaining\naccuracy. For post hoc analysis, loading the trained model costs only two\nseconds, significantly reducing the burden of I/O when reading data for\nvisualization. Moreover, our parallel implementation can infer one hundred\nlocations for each of two thousand new pathlines across the entire temporal\nresolution in 1.3 seconds using one NVIDIA Titan RTX GPU.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:54:32 GMT"},{"version":"v2","created":"Thu, 6 Jan 2022 23:15:22 GMT"}],"update_date":"2022-04-11"}
{"id":"2110.08339","submitter":"Pavle Subotic","authors":"Pavle Suboti\\'c, Lazar Miliki\\'c, Milan Stoji\\'c","title":"A Static Analysis Framework for Data Science Notebooks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Notebooks provide an interactive environment for programmers to develop code,\nanalyse data and inject interleaved visualizations in a single environment.\nDespite their flexibility, a major pitfall that data scientists encounter is\nunexpected behaviour caused by the unique out-of-order execution model of\nnotebooks. As a result, data scientists face various challenges ranging from\nnotebook correctness, reproducibility and cleaning. In this paper, we propose a\nframework that performs static analysis on notebooks, incorporating their\nunique execution semantics. Our framework is general in the sense that it\naccommodate for a wide range of analyses, useful for various notebook use\ncases. We have instantiated our framework on a diverse set of analyses and have\nevaluated them on 2211 real world notebooks. Our evaluation demonstrates that\nthe vast majority (98.7%) of notebooks can be analysed in less than a second,\nwell within the time frame required by interactive notebook clients\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:57:24 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 19:55:27 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08340","submitter":"Samin Aref","authors":"Xinyi Zhao, Samin Aref, Emilio Zagheni, and Guy Stecklov","title":"Return migration of German-affiliated researchers: Analyzing departure\n  and return by gender, cohort, and discipline using Scopus bibliometric data\n  1996-2020","comments":"27 pages, 6 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.CY cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The international migration of researchers is an important dimension of\nscientific mobility, and has been the subject of considerable policy debate.\nHowever, tracking the migration life courses of researchers is challenging due\nto data limitations. In this study, we use Scopus bibliometric data on eight\nmillion publications from 1.1 million researchers who have published at least\nonce with an affiliation address from Germany in 1996-2020. We construct the\npartial life histories of published researchers in this period and explore both\ntheir out-migration and the subsequent return of a subset of this group: the\nreturnees. Our analyses shed light on the career stages and gender disparities\nbetween researchers who remain in Germany, those who emigrate, and those who\neventually return. We find that the return migration streams are even more\ngender imbalanced, which points to the need for additional efforts to encourage\nfemale researchers to come back to Germany. We document a slightly declining\ntrend in return migration among more recent cohorts of researchers who left\nGermany, which, for most disciplines, was associated with a decrease in the\nGerman collaborative ties of these researchers. Moreover, we find that the\ngender disparities for the most gender imbalanced disciplines are unlikely to\nbe mitigated by return migration given the gender compositions of the cohorts\nof researchers who have left Germany and of those who have returned. This\nanalysis uncovers new dimensions of migration among scholars by investigating\nthe return migration of published researchers, which is critical for the\ndevelopment of science policy.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:59:21 GMT"},{"version":"v2","created":"Tue, 1 Feb 2022 13:47:27 GMT"}],"update_date":"2022-02-02"}
{"id":"2110.08341","submitter":"Leonardo Felipe Toso","authors":"Leonardo F. Toso, Ross Drummond and Stephen R. Duncan","title":"Regional Stability Analysis of Transitional Fluid Flows","comments":"The paper is composed of 6 pages with 4 figures. It will be submitted\n  to the IEEE Control Systems Letters (L-CSS)","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A method to bound the maximum energy perturbation for which regional\nstability of transitional fluid flow models can be guaranteed is introduced.\nThe proposed method exploits the fact that the fluid model's nonlinearities are\nboth lossless and locally bounded and uses the axes lengths of the ellipsoids\nfor the trajectory set containment as variables in the stability conditions.\nCompared to existing approaches, the proposed method leads to an average\nincrease in the maximum allowable energy perturbation of 29% for the\nWaleffe-KimHamilton (WKH) shear flow model and of 38% for the 9-state reduced\nmodel of Couette flow.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:00:56 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08342","submitter":"Abdel Kader Geraldo","authors":"Matthew Dobson and Abdel Kader Geraldo","title":"Simple Periodic Boundary Conditions for Molecular Simulation of Uniaxial\n  Flow","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present rotating periodic boundary conditions (PBCs) for the simulation of\nnonequilibrium molecular dynamics (NEMD) under uniaxial stretching flow (USF)\nor biaxial stretching flow (BSF). Such nonequilibrium flows need specialized\nPBCs since the simulation box deforms with the background flow. The technique\nbuilds on previous models using one or lattice remappings, and is simpler than\nthe PBCs developed for the general three dimensional flow. For general three\ndimensional flows, Dobson \\cite{Dobson} and Hunt \\cite{Hunt} proposed schemes\nwhich are not time-periodic since they use more than one automorphism\nremapping. This paper presents a single automorphism remapping PBCs for USF and\nBSF which is time periodic up to a rotation matrix and has a better minimum\nlattice spacing properties.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:02:34 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08343","submitter":"Evgeny Osipov","authors":"Evgeny Osipov, Sachin Kahawala, Dilantha Haputhanthri, Thimal\n  Kempitiya, Daswin De Silva, Damminda Alahakoon, Denis Kleyko","title":"Hyperseed: Unsupervised Learning with Vector Symbolic Architectures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivated by recent innovations in biologically-inspired neuromorphic\nhardware, this article presents a novel unsupervised machine learning algorithm\nnamed Hyperseed that draws on the principles of Vector Symbolic Architectures\n(VSA) for fast learning of a topology preserving feature map of unlabelled\ndata. It relies on two major operations of VSA, binding and bundling. The\nalgorithmic part of Hyperseed is expressed within Fourier Holographic Reduced\nRepresentations model, which is specifically suited for implementation on\nspiking neuromorphic hardware. The two primary contributions of the Hyperseed\nalgorithm are, few-shot learning and a learning rule based on single vector\noperation. These properties are empirically evaluated on synthetic datasets as\nwell as on illustrative benchmark use-cases, IRIS classification, and a\nlanguage identification task using n-gram statistics. The results of these\nexperiments confirm the capabilities of Hyperseed and its applications in\nneuromorphic hardware.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:05:43 GMT"},{"version":"v2","created":"Thu, 29 Sep 2022 09:55:31 GMT"}],"update_date":"2022-09-30"}
{"id":"2110.08344","submitter":"Mark Suffak","authors":"M. Suffak, C.E. Jones, A.C. Carciofi","title":"Growth and Dissipation of Be Star Discs in Misaligned Binary Systems","comments":"14 pages, 14 figures","journal-ref":null,"doi":"10.1093/mnras/stab3024","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use a three-dimensional smoothed particle hydrodynamics code to simulate\ngrowth and dissipation of Be star discs in systems where the binary orbit is\nmisaligned with respect to the spin axis of the primary star. We investigate\nsix different scenarios of varying orbital period and misalignment angle,\nfeeding the disc at a constant rate for 100 orbital periods, and then letting\nthe disc dissipate for 100 orbital periods. During the disc growth phase, we\nfind that the binary companion tilts the disc away from its initial plane at\nthe equator of the primary star before settling to a constant orientation after\n40 to 50 orbital periods. While the mass-injection into the disc is ongoing,\nthe tilting of the disc can cause material to reaccrete onto the primary star\nprematurely. Once disc dissipation begins, usually the disc precesses about the\nbinary companion's orbital axis with precession periods ranging from 20 to 50\norbital periods. In special cases we detect phenomena of disc tearing, as well\nas Kozai-Lidov oscillations of the disc. These oscillations reach a maximum\neccentricity of about 0.6, and a minimum inclination of about \\ang{20} with\nrespect to the binary's orbit. We also find the disc material to have highly\neccentric orbits beyond the transition radius, where the disc changes from\nbeing dominated by viscous forces, to heavily controlled by the companion star,\nin contrast to its nearly circular motion inward of the transition radius.\nFinally, we offer predictions to how these changes will affect Be star\nobservables.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:10:50 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08345","submitter":"Lingbo Mo","authors":"Lingbo Mo, Ashley Lewis, Huan Sun, Michael White","title":"Towards Transparent Interactive Semantic Parsing via Step-by-Step\n  Correction","comments":"Accepted by Findings of ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Existing studies on semantic parsing focus primarily on mapping a\nnatural-language utterance to a corresponding logical form in one turn.\nHowever, because natural language can contain a great deal of ambiguity and\nvariability, this is a difficult challenge. In this work, we investigate an\ninteractive semantic parsing framework that explains the predicted logical form\nstep by step in natural language and enables the user to make corrections\nthrough natural-language feedback for individual steps. We focus on question\nanswering over knowledge bases (KBQA) as an instantiation of our framework,\naiming to increase the transparency of the parsing process and help the user\nappropriately trust the final answer. To do so, we construct INSPIRED, a\ncrowdsourced dialogue dataset derived from the ComplexWebQuestions dataset. Our\nexperiments show that the interactive framework with human feedback has the\npotential to greatly improve overall parse accuracy. Furthermore, we develop a\npipeline for dialogue simulation to evaluate our framework w.r.t. a variety of\nstate-of-the-art KBQA models without involving further crowdsourcing effort.\nThe results demonstrate that our interactive semantic parsing framework\npromises to be effective across such models.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:11:22 GMT"},{"version":"v2","created":"Mon, 28 Mar 2022 00:26:08 GMT"}],"update_date":"2022-03-29"}
{"id":"2110.08346","submitter":"Timothy McCormick","authors":"Timothy M. McCormick, Bryan R. Osborn, R. Blair Angle, Roy L. Streit","title":"Implementation of a Multiple Target Tracking Filter on an Adiabatic\n  Quantum Computer","comments":"14 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent work at Fraunhofer FKIE shows that Morefield's method for multiple\ntarget data association can in theory be solved on an adiabatic quantum\ncomputer. The present paper validates the theory and examines the significant\nlimitations of currently available adiabatic quantum computers for solving the\ndata association problem. The limitations of such architectures are both\ntheoretical and practical in nature, and both are discussed. The data\nassociation problem is formulated as a quadratic unconstrained binary\noptimization (QUBO) problem; consequently, much of the discussion is relevant\nto other applications which are, or can be, posed as QUBO problems.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:11:24 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08347","submitter":"Alan John Mitchell","authors":"V. S. Prasher, A. J. Mitchell, C. J. Lister, P. Chowdhury, L.\n  Afanasieva, M. Albers, C. J. Chiara, M. P. Carpenter, D. Cline, N. D'Olympia,\n  C. J. Guess, A. B. Hayes, C. R. Hoffman, R. V. F. Janssens, B. P. Kay, T. L.\n  Khoo, A. Korichi, T. Lauritsen, E. Merchan, Y. Qiu, D. Seweryniak, R.\n  Shearman, S. K. Tandel, A. Verras, C. Y. Wu, and S. Zhu","title":"Shapes, Softness and Non-Yrast Collectivity in 186W","comments":"14 pages, 16 figures","journal-ref":"Phys. Rev. C 104, 044318 (2021)","doi":"10.1103/PhysRevC.104.044318","report-no":null,"categories":"nucl-ex nucl-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Non-yrast, excited states in neutron-rich $^{186}$W were populated via\ninelastic-scattering reactions using beams of $^{136}$Xe nuclei accelerated to\n725 and 800 MeV. Levels populated in the reactions were investigated via\nparticle-$ \\gamma $ coincidence techniques using the Gammasphere array of\nHigh-Purity Germanium detectors and the compact heavy-ion counter, CHICO2. The\n$ K^{\\pi} = 2 ^{+} $ ($\\gamma$), $ K^{\\pi} = 0^{+}$ and $ K^{\\pi} = 2^{-} $\n(octupole) rotational side bands were extended to spins $ 14\\hbar $, $ 12\\hbar\n$, and $ 13\\hbar $, respectively. A staggering pattern observed in the energies\nof levels in the $ K^{\\pi} = 2^{+} $ band was found to be consistent with a\npotential that gets softer to vibration in the $ \\gamma $ degree of freedom\nwith increasing spin. The odd-even staggering of states in the $ K^{\\pi} =\n2^{-}$ band was found to exhibit a phase opposite to that seen in the $ \\gamma\n$ band; an effect most probably associated with Coriolis coupling to other,\nunobserved octupole vibrational bands in $^{186}$W.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:18:42 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08348","submitter":"Peter Pfaffelhuber","authors":"Peter Pfaffelhuber, Angelika Rohde","title":"A central limit theorem concerning uncertainty in estimates of\n  individual admixture","comments":"25 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.PE math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The concept of individual admixture (IA) assumes that the genome of\nindividuals is composed of alleles inherited from $K$ ancestral populations.\nEach copy of each allele has the same chance $q_k$ to originate from population\n$k$, and together with the allele frequencies $p$ in all populations at all $M$\nmarkers, comprises the admixture model. Here, we assume a supervised scheme,\ni.e.\\ allele frequencies $p$ are given through a reference database of size\n$N$, and $q$ is estimated via maximum likelihood for a single sample. We study\nlaws of large numbers and central limit theorems describing effects of\nfiniteness of both, $M$ and $N$, on the estimate of $q$. We recall results for\nthe effect of finite $M$, and provide a central limit theorem for the effect of\nfinite $N$, introduce a new way to express the uncertainty in estimates in\nstandard barplots, give simulation results, and discuss applications in\nforensic genetics.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:21:15 GMT"},{"version":"v2","created":"Fri, 29 Jul 2022 09:43:01 GMT"}],"update_date":"2022-08-01"}
{"id":"2110.08349","submitter":"Julian Barragan Amado","authors":"Juli\\'an Barrag\\'an Amado, Bruno Carneiro da Cunha and Elisabetta\n  Pallante","title":"QNMs of scalar fields on small Reissner-Nordstr\\\"{o}m-AdS$\\mathbf{_5}$\n  black holes","comments":"16 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the quasinormal modes (QNMs) of a charged scalar field on a\nReissner-Nordstr\\\"{o}m-anti-de Sitter (RN-AdS$_{5}$) black hole in the small\nradius limit by using the isomonodromic method. We also derive the\nlow-temperature expansion of the fundamental QNM frequency. Finally, we provide\nnumerical evidence that instabilities appear in the small radius limit for\nlarge values of the charge of the scalar field.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:25:00 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08350","submitter":"Edgar Liberis","authors":"Edgar Liberis, Nicholas D. Lane","title":"Differentiable Network Pruning for Microcontrollers","comments":null,"journal-ref":null,"doi":"10.1145/3569468","report-no":null,"categories":"cs.LG cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Embedded and personal IoT devices are powered by microcontroller units\n(MCUs), whose extreme resource scarcity is a major obstacle for applications\nrelying on on-device deep learning inference. Orders of magnitude less storage,\nmemory and computational capacity, compared to what is typically required to\nexecute neural networks, impose strict structural constraints on the network\narchitecture and call for specialist model compression methodology. In this\nwork, we present a differentiable structured network pruning method for\nconvolutional neural networks, which integrates a model's MCU-specific resource\nusage and parameter importance feedback to obtain highly compressed yet\naccurate classification models. Our methodology (a) improves key resource usage\nof models up to 80x; (b) prunes iteratively while a model is trained, resulting\nin little to no overhead or even improved training time; (c) produces\ncompressed models with matching or improved resource usage up to 1.4x in less\ntime compared to prior MCU-specific methods. Compressed models are available\nfor download.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:26:15 GMT"},{"version":"v2","created":"Wed, 15 Dec 2021 11:22:26 GMT"},{"version":"v3","created":"Thu, 8 Dec 2022 13:39:45 GMT"}],"update_date":"2022-12-09"}
{"id":"2110.08351","submitter":"Edson Vernek","authors":"E. Vernek","title":"Robustness of Stark many-body localization in the $J_1$-$J_2$ Heisenberg\n  model","comments":"8 pages, 8 figures","journal-ref":"Phys. Rev. B 105, 075124 (2022)","doi":"10.1103/PhysRevB.105.075124","report-no":null,"categories":"cond-mat.dis-nn cond-mat.soft cond-mat.stat-mech cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stark many-body localization (SMBL) is a phenomenon observed in interacting\nsystems with a nearly uniform spatial gradient applied field. Contrasting to\nthe traditional many-body localization phenomenon, SMBL does not require\ndisorder. Here we investigate SMBL in a spin-$1/2$ described by a Heisenberg\nmodel including a next-nearest-neighbor exchange coupling. By employing an\nexact diagonalization approach and time evolution calculation we analyze both\nlevel spacing ratio (LSR) statistics of the Hamiltonian model as well as the\ndynamics of the system from a given initial state. Our results reveals that for\nzero field in our finite system, LSR statistics suggest localization while the\ndynamics shows thermalization, which has been attributed to a finite-size\neffect. Slightly nonuniform field gradient, LSR statistic predictions agree\nvery well with the dynamics of the physical quantities indicating\ndelocalization and localization for small and large field gradient,\nrespectively. More interestingly, we find that localization is robust in the\npresence of next-nearest-neighbor coupling in the Hamiltonian. Moreover, this\ncoupling can be tuned to enhance SMBL in the system, meaning that localized\nregimes can be obtained for smaller field gradient as compared to the\ntraditional nearest-neighbor isotropic Heisenberg model.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:27:54 GMT"},{"version":"v2","created":"Fri, 11 Feb 2022 18:31:23 GMT"}],"update_date":"2022-02-14"}
{"id":"2110.08352","submitter":"Haichuan Yang","authors":"Haichuan Yang, Yuan Shangguan, Dilin Wang, Meng Li, Pierce Chuang,\n  Xiaohui Zhang, Ganesh Venkatesh, Ozlem Kalinli, Vikas Chandra","title":"Omni-sparsity DNN: Fast Sparsity Optimization for On-Device Streaming\n  E2E ASR via Supernet","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  From wearables to powerful smart devices, modern automatic speech recognition\n(ASR) models run on a variety of edge devices with different computational\nbudgets. To navigate the Pareto front of model accuracy vs model size,\nresearchers are trapped in a dilemma of optimizing model accuracy by training\nand fine-tuning models for each individual edge device while keeping the\ntraining GPU-hours tractable. In this paper, we propose Omni-sparsity DNN,\nwhere a single neural network can be pruned to generate optimized model for a\nlarge range of model sizes. We develop training strategies for Omni-sparsity\nDNN that allows it to find models along the Pareto front of word-error-rate\n(WER) vs model size while keeping the training GPU-hours to no more than that\nof training one singular model. We demonstrate the Omni-sparsity DNN with\nstreaming E2E ASR models. Our results show great saving on training time and\nresources with similar or better accuracy on LibriSpeech compared to\nindividually pruned sparse models: 2%-6.6% better WER on Test-other.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:28:27 GMT"},{"version":"v2","created":"Wed, 20 Jul 2022 05:14:37 GMT"}],"update_date":"2022-07-21"}
{"id":"2110.08353","submitter":"Bhaskar Mitra","authors":"Nicola Neophytou, Bhaskar Mitra and Catherine Stinson","title":"Revisiting Popularity and Demographic Biases in Recommender Evaluation\n  and Effectiveness","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recommendation algorithms are susceptible to popularity bias: a tendency to\nrecommend popular items even when they fail to meet user needs. A related issue\nis that the recommendation quality can vary by demographic groups. Marginalized\ngroups or groups that are under-represented in the training data may receive\nless relevant recommendations from these algorithms compared to others. In a\nrecent study, Ekstrand et al. investigate how recommender performance varies\naccording to popularity and demographics, and find statistically significant\ndifferences in recommendation utility between binary genders on two datasets,\nand significant effects based on age on one dataset. Here we reproduce those\nresults and extend them with additional analyses. We find statistically\nsignificant differences in recommender performance by both age and gender. We\nobserve that recommendation utility steadily degrades for older users, and is\nlower for women than men. We also find that the utility is higher for users\nfrom countries with more representation in the dataset. In addition, we find\nthat total usage and the popularity of consumed content are strong predictors\nof recommender performance and also vary significantly across demographic\ngroups.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:30:51 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08354","submitter":"Vincent Neiger","authors":"Vincent Neiger, Bruno Salvy, \\'Eric Schost, Gilles Villard","title":"Faster Modular Composition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SC cs.CC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A new Las Vegas algorithm is presented for the composition of two polynomials\nmodulo a third one, over an arbitrary field. When the degrees of these\npolynomials are bounded by $n$, the algorithm uses $O(n^{1.43})$ field\noperations, breaking through the $3/2$ barrier in the exponent for the first\ntime. The previous fastest algebraic algorithms, due to Brent and Kung in 1978,\nrequire $O(n^{1.63})$ field operations in general, and ${n^{3/2+o(1)}}$ field\noperations in the particular case of power series over a field of large enough\ncharacteristic. If using cubic-time matrix multiplication, the new algorithm\nruns in ${n^{5/3+o(1)}}$ operations, while previous ones run in $O(n^2)$\noperations.\n  Our approach relies on the computation of a matrix of algebraic relations\nthat is typically of small size. Randomization is used to reduce arbitrary\ninput to this favorable situation.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:33:37 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08355","submitter":"Derek Chen","authors":"Derek Chen, Zhou Yu, and Samuel R. Bowman","title":"Clean or Annotate: How to Spend a Limited Data Collection Budget","comments":"17 pages, 3 figures, 6 tables. Accepted to NAACL 2022 workshop","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Crowdsourcing platforms are often used to collect datasets for training\nmachine learning models, despite higher levels of inaccurate labeling compared\nto expert labeling. There are two common strategies to manage the impact of\nsuch noise. The first involves aggregating redundant annotations, but comes at\nthe expense of labeling substantially fewer examples. Secondly, prior works\nhave also considered using the entire annotation budget to label as many\nexamples as possible and subsequently apply denoising algorithms to implicitly\nclean the dataset. We find a middle ground and propose an approach which\nreserves a fraction of annotations to explicitly clean up highly probable error\nsamples to optimize the annotation process. In particular, we allocate a large\nportion of the labeling budget to form an initial dataset used to train a\nmodel. This model is then used to identify specific examples that appear most\nlikely to be incorrect, which we spend the remaining budget to relabel.\nExperiments across three model variations and four natural language processing\ntasks show our approach outperforms or matches both label aggregation and\nadvanced denoising methods designed to handle noisy labels when allocated the\nsame finite annotation budget.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:37:29 GMT"},{"version":"v2","created":"Sun, 12 Jun 2022 16:57:41 GMT"}],"update_date":"2022-06-14"}
{"id":"2110.08356","submitter":"Bret Underwood","authors":"S. Shajidul Haque, Chandan Jana, Bret Underwood","title":"Operator Complexity for Quantum Scalar Fields and Cosmological\n  Perturbations","comments":"30 pages, 5 figures. v2: References added. v3: New section and\n  figures added","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We calculate the operator complexity for the displacement, squeeze and\nrotation operators of a quantum harmonic oscillator. The complexity of the\ntime-dependent displacement operator is constant, equal to the magnitude of the\ncoherent state parameter, while the complexity of unitary evolution by a\ngeneric quadratic Hamiltonian is proportional to the amount of squeezing and is\nsensitive to the time-dependent phase of the unitary operator. We apply these\nresults to study the complexity of a free massive scalar field, finding that\nthe complexity has a period of rapid linear growth followed by a saturation\ndetermined by the UV cutoff and the number of spatial dimensions. We also study\nthe complexity of the unitary evolution of quantum cosmological perturbations\nin de Sitter space, which can be written as time-dependent squeezing and\nrotation operators on individual Fourier mode pairs. The complexity of a single\nmode pair at late times grows linearly with the number of e-folds, while the\ncomplexity at early times oscillates rapidly due to the sensitivity of operator\ncomplexity to the phase of unitary time evolution. Integrating over all modes,\nthe total complexity of cosmological perturbations scales as the square root of\nthe (exponentially) growing volume of de Sitter space, suggesting that\ninflation leads to an explosive growth in complexity of the Universe.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:37:36 GMT"},{"version":"v2","created":"Thu, 28 Oct 2021 17:45:24 GMT"},{"version":"v3","created":"Mon, 11 Jul 2022 17:20:33 GMT"}],"update_date":"2022-07-12"}
{"id":"2110.08357","submitter":"Daiane Dolci Dolci","authors":"Daiane I. Dolci and Bruno S. Carmo","title":"Sensitivity of the least stable modes to passive control for a flow\n  around an elastically-mounted circular cylinder","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn math.OC","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper, a methodology to calculate the sensitivity of the least stable\nmodes of fluid-structure interaction systems with respect to local forces is\npresented. We make use of the adjoint equations of the flow-structure coupled\nsystem to calculate the gradients, and the algorithms were implemented using\nthe spectral/\\emph{hp} element method for the spatial discretization. The\nmethodology was applied to two-dimensional incompressible laminar steady flows\naround an elastically-mounted circular cylinder, and we obtained the gradients\nof the real and imaginary parts of the least stable eigenvalues with respect to\nforces located at arbitrary points in the flow domain. Selected values of mass\nratio and reduced velocity were considered in the simulations, and the results\nwere compared to those obtained for a fixed cylinder at the same Reynolds\nnumber. We noticed that the sensitivity fields of the fluid-structure\ninteraction system can be very different from its fixed structure counterpart,\nand amongst the cases, with an elastic structure, the fields vary greatly\naccording to the reduced velocity. Finally, the sensitivity results were\nverified against linear and nonlinear simulations of flows with small control\ncylinders placed at locations selected according to the sensitivity fields. The\nagreement between the predictions made with the sensitivity analyses and the\nlinear and nonlinear results of the forced flows was excellent. In some cases,\nit was possible to completely suppress the cylinder vibration.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:38:32 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08358","submitter":"Ewan O'Sullivan","authors":"Ewan O'Sullivan, Magdalena Kunert-Bajraszewska, Aneta Siemiginowska,\n  D.J. Burke, Francoise Combes, Philippe Salome, Simona Giacintucci","title":"1321+045: a Compact Steep Spectrum radio source in a cool-core galaxy\n  cluster","comments":"4 pages, accepted for publication on Astronomische Nachrichten, as\n  part of the proceedings of the 6th Workshop on Compact Steep-Spectrum and\n  GHz-Peaked Spectrum radio sources","journal-ref":null,"doi":"10.1002/asna.20210035","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Cluster-central gigahertz peak and compact steep spectrum (CSS) sources offer\nan opportunity to study the earliest phases of AGN feedback, but few have yet\nbeen examined in detail. We present results from radio and X-ray observations\nof 1321+045, a CSS source in a 4.4 keV cluster at z=0.263. The cluster has a\nstrongly cooling core, and disturbances from a minor cluster merger may have\ntriggered a period of jet activity which formed the 16 kpc radio lobes 2.0\n[+0.3,-0.2] Myr ago. However, new VLBA imaging shows a ~20 pc jet on a\ndifferent projected axis, which is probably only a few hundred years old. We\nconsider possible histories for the system, with either one or two periods of\njet activity. While this single system is informative, a broader study of the\nyoungest cluster-central radio sources is desirable.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:39:16 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08359","submitter":"Elizabeth Wong","authors":"Michael W. Ferry, Philip E. Gill, Elizabeth Wong, Minxin Zhang","title":"Projected-Search Methods for Bound-Constrained Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":"CCoM 21-01","categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Projected-search methods for bound-constrained optimization are based on\nperforming a search along a piecewise-linear continuous path obtained by\nprojecting a search direction onto the feasible region. A benefit of these\nmethods is that many changes to the active set can be made at the cost of\ncomputing a single search direction. As the objective function is not\ndifferentiable along the search path, it is not possible to use a\nprojected-search method with a step that satisfies the Wolfe conditions, which\nrequire the directional derivative of the objective function at a point on the\npath. Thus, methods based on a simple backtracking procedure must be used to\ngive a step that satisfies an \"Armijo-like\" sufficient decrease condition. As a\nconsequence, conventional projected-search methods are unable to exploit\nsophisticated safeguarded polynomial interpolation techniques that have been\nshown to be effective for the unconstrained case.\n  This paper concerns the formulation and analysis of projected-search methods\nbased on a new quasi-Wolfe line search that is appropriate for piecewise\ndifferentiable functions. The behavior of the line search is similar to\nconventional Wolfe line search, except that a step is accepted under a wider\nrange of conditions. These conditions take into consideration steps at which\nthe restriction of the objective function on the search path is not\ndifferentiable. Two new classes of method are proposed that may be broadly\ncategorized as active-set and interior-point methods. Computational results are\ngiven for two specific methods from these general classes: a projected-search\nactive-set method that uses a limited-memory quasi-Newton approximation of the\nHessian; and a projected-search primal-dual interior-point method. The results\nshow that in these contexts, a quasi-Wolfe line search is substantially more\nefficient and reliable than an Armijo line search.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:42:40 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08360","submitter":"Stephen Reynolds","authors":"Alice G. Stone, Heather T. Johnson, John M. Blondin, Richard A.\n  Watson, Kazimierz J. Borkowski, Carla Frohlich, Ivo R. Seitenzahl, and\n  Stephen P. Reynolds","title":"Type Ia Supernova Models: Asymmetric Remnants and Supernova Remnant\n  G1.9+0.3","comments":"30 pages, 23 figures. Accepted for publication in ApJS. Animations\n  will be available in online published version","journal-ref":null,"doi":"10.3847/1538-4357/ac300f","report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The youngest Galactic supernova remnant G1.9+0.3, probably the result of a\nType Ia supernova, shows surprising anomalies in the distribution of its ejecta\nin space and velocity. In particular, high-velocity shocked iron is seen in\nseveral locations far from the remnant center, in some cases beyond prominent\nsilicon and sulfur emission. These asymmetries strongly suggest a highly\nasymmetric explosion. We present high-resolution hydrodynamic simulations in\ntwo and three dimensions of the evolution from ages of 100 seconds to hundreds\nof years of two asymmetric Type Ia models, expanding into a uniform medium. At\nthe age of G1.9+0.3 (about 100 years), our 2D model shows almost no iron\nshocked to become visible in X-rays. Only in a much higher-density environment\ncould significant iron be shocked, at which time the model's expansion speed is\ncompletely inconsistent with the observations of G1.9+0.3. Our 3D model,\nevolving the most asymmetric of a suite of Type Ia SN models from Seitenzahl et\nal.~(2013), shows some features resembling G1.9+0.3. We characterize its\nevolution with images of composition in three classes: C and O,\nintermediate-mass elements (IMEs), and iron-group elements (IGEs). From ages of\n13 to 1800 years, we follow the evolution of the highly asymmetric initial\nremnant as the explosion asymmetries decrease in relative strength to be\nreplaced by asymmetries due to evolutionary hydrodynamic instabilities. At an\nage of about 100 years, our 3D model has comparable shocked masses of C+O,\nIMEs, and IGEs, with about 0.03 $M_\\odot$ each. Evolutionary changes appear to\nbe rapid enough that continued monitoring with the Chandra X-ray Observatory\nmay show significant variations.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:43:05 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08361","submitter":"Anton Andreev","authors":"A. V. Andreev","title":"Electronic pumping of heat without charge transfer","comments":"5 pages, no figures","journal-ref":null,"doi":"10.1103/PhysRevB.105.L081410","report-no":null,"categories":"cond-mat.mes-hall cond-mat.other","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A mechanism of electron-mediated pumping of heat in the absence of net charge\ntransfer is proposed. It may be realized in charge-neutral electron systems,\nsuch as graphene, coupled to an external electric potential. The flow of heat\nin this pumping cycle is not accompanied by a buildup of voltage along the\nsystem, which offers advantages over traditional thermoelectric cooling setups.\nEfficiency of heat pumping and magnitude of heat flux are studied in the\nhydrodynamic regime for weak disorder. In a pristine system, even for an\ninfinitesimal pumping potential the heat flux remains finite. In particular,\nfor a potential in the form of a traveling wave moving with velocity $c$ the\npumping is perfect; the entire heat content of the electron liquid is advected\nwith velocity $c$. For a general pumping cycle the heat flux is determined by\nthe cycle geometry and disorder strength.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:44:41 GMT"}],"update_date":"2022-03-14"}
{"id":"2110.08362","submitter":"Wolfgang Grieskamp","authors":"David Dill, Wolfgang Grieskamp, Junkil Park, Shaz Qadeer, Meng Xu,\n  Emma Zhong","title":"Fast and Reliable Formal Verification of Smart Contracts with the Move\n  Prover","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.SC cs.SE","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The Move Prover (MVP) is a formal verifier for smart contracts written in the\nMove programming language. MVP has an expressive specification language, and is\nfast and reliable enough that it can be run routinely by developers and in\nintegration testing in a few minutes. Besides the simplicity of smart contracts\nand the Move language, three transformations are responsible for the\npracticality of MVP: (1) an alias-free memory model, (2) fine-grained invariant\nchecking, and (3) monomorphization. The entirety of the Move code for the Diem\nblockchain has been extensively specified and can be completely verified by MVP\nin a few minutes. Changes in the Diem framework must be successfully verified\nbefore being integrated into the open source repository on GitHub.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:49:30 GMT"},{"version":"v2","created":"Wed, 26 Jan 2022 15:57:48 GMT"},{"version":"v3","created":"Sun, 13 Feb 2022 02:56:40 GMT"}],"update_date":"2022-02-15"}
{"id":"2110.08363","submitter":"Lekha Patel","authors":"Lekha Patel, Lyndsay Shand, J. Derek Tucker, Gabriel Huerta","title":"Spatio-temporal extreme event modeling of terror insurgencies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Extreme events with potential deadly outcomes, such as those organized by\nterror groups, are highly unpredictable in nature and an imminent threat to\nsociety. In particular, quantifying the likelihood of a terror attack occurring\nin an arbitrary space-time region and its relative societal risk, would\nfacilitate informed measures that would strengthen national security. This\npaper introduces a novel self-exciting marked spatio-temporal model for attacks\nwhose inhomogeneous baseline intensity is written as a function of covariates.\nIts triggering intensity is succinctly modeled with a Gaussian Process prior\ndistribution to flexibly capture intricate spatio-temporal dependencies between\nan arbitrary attack and previous terror events. By inferring the parameters of\nthis model, we highlight specific space-time areas in which attacks are likely\nto occur. Furthermore, by measuring the outcome of an attack in terms of the\nnumber of casualties it produces, we introduce a novel mixture distribution for\nthe number of casualties. This distribution flexibly handles low and high\nnumber of casualties and the discrete nature of the data through a {\\it\nGeneralized ZipF} distribution. We rely on a customized Markov chain Monte\nCarlo (MCMC) method to estimate the model parameters. We illustrate the\nmethodology with data from the open source Global Terrorism Database (GTD) that\ncorrespond to attacks in Afghanistan from 2013-2018. We show that our model is\nable to predict the intensity of future attacks for 2019-2021 while considering\nvarious covariates of interest such as population density, number of regional\nlanguages spoken, and the density of population supporting the opposing\ngovernment.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:50:24 GMT"},{"version":"v2","created":"Fri, 29 Oct 2021 21:48:46 GMT"}],"update_date":"2021-11-02"}
{"id":"2110.08364","submitter":"Antonio Ortega","authors":"Julia Barrufet, Antonio Ortega","title":"Orthogonal Transforms for Signals on Directed Graphs","comments":"5 pages, submitted to ICASSP 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we consider the problem of defining transforms for signals on\ndirected graphs, with a specific focus on defective graphs where the\ncorresponding graph operator cannot be diagonalized. Our proposed method is\nbased on the Schur decomposition and leads to a series of embedded invariant\nsubspaces for which orthogonal basis are available. As compared to diffusion\nwavelets, our method is more flexible in the generation of subspaces, but these\nsubspaces can only be approximately orthogonal.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:52:11 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08365","submitter":"Mengyi Tang","authors":"Mengyi Tang (1), Maryam Yashtini (2), and Sung Ha Kang (1) ((1)\n  Georgia Institute of Technology, (2) Georgetown University )","title":"Counting Objects by Diffused Index: geometry-free and training-free\n  approach","comments":null,"journal-ref":null,"doi":"10.1016/j.jvcir.2022.103527","report-no":null,"categories":"cs.CV cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Counting objects is a fundamental but challenging problem. In this paper, we\npropose diffusion-based, geometry-free, and learning-free methodologies to\ncount the number of objects in images. The main idea is to represent each\nobject by a unique index value regardless of its intensity or size, and to\nsimply count the number of index values. First, we place different vectors,\nrefer to as seed vectors, uniformly throughout the mask image. The mask image\nhas boundary information of the objects to be counted. Secondly, the seeds are\ndiffused using an edge-weighted harmonic variational optimization model within\neach object. We propose an efficient algorithm based on an operator splitting\napproach and alternating direction minimization method, and theoretical\nanalysis of this algorithm is given. An optimal solution of the model is\nobtained when the distributed seeds are completely diffused such that there is\na unique intensity within each object, which we refer to as an index. For\ncomputational efficiency, we stop the diffusion process before a full\nconvergence, and propose to cluster these diffused index values. We refer to\nthis approach as Counting Objects by Diffused Index (CODI). We explore scalar\nand multi-dimensional seed vectors. For Scalar seeds, we use Gaussian fitting\nin histogram to count, while for vector seeds, we exploit a high-dimensional\nclustering method for the final step of counting via clustering. The proposed\nmethod is flexible even if the boundary of the object is not clear nor fully\nenclosed. We present counting results in various applications such as\nbiological cells, agriculture, concert crowd, and transportation. Some\ncomparisons with existing methods are presented.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:53:37 GMT"}],"update_date":"2022-11-08"}
{"id":"2110.08366","submitter":"David Northeast Dr.","authors":"Patrick Laferri\\`ere, Edith Yeung, Isabelle Miron, David B. Northeast,\n  Sofiane Haffouz, Jean Lapointe, Marek Korkusinski, Philip J. Poole, Robin L.\n  Williams, Dan Dalacu","title":"Unity yield of deterministically positioned quantum dot single photon\n  sources","comments":"9 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mes-hall physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We report on a platform for the production of single photon devices with a\nfabrication yield of 100%. The sources are based on InAsP quantum dots embedded\nwithin position-controlled bottom-up InP nanowires. Using optimized growth\nconditions, we produce large arrays of structures having highly uniform\ngeometries. Collection efficiencies are as high as 83% and multiphoton emission\nprobabilities as low as 0.6% with the distribution away from optimal values\nassociated with the excitation of other charge complexes and re-excitation\nprocesses, respectively, inherent to the above-band excitation employed.\nImportantly, emission peak lineshapes have Lorentzian profiles indicating that\nlinewidths are not limited by inhomogeneous broadening but rather pure\ndephasing, likely elastic carrier-phonon scattering due to a high phonon\noccupation. This work establishes nanowire-based devices as a viable route for\nthe scalable fabrication of efficient single photon sources and provides a\nvaluable resource for hybrid on-chip platforms currently being developed.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:55:50 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08367","submitter":"Ananthan Nambiar","authors":"Ananthan Nambiar, Tobias Rubel, James McCaull, Jon deVries and Mark\n  Bedau","title":"Dropping diversity of products of large US firms: Models and measures","comments":null,"journal-ref":null,"doi":"10.1371/journal.pone.0264330","report-no":null,"categories":"q-fin.ST cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It is widely assumed that in our lifetimes the products available in the\nglobal economy have become more diverse. This assumption is difficult to\ninvestigate directly, however, because it is difficult to collect the necessary\ndata about every product in an economy each year. We solve this problem by\nmining publicly available textual descriptions of the products of every large\nUS firms each year from 1997 to 2017. Although many aspects of economic\nproductivity have been steadily rising during this period, our text-based\nmeasurements show that the diversity of the products of at least large US firms\nhas steadily declined. This downward trend is visible using a variety of\nproduct diversity metrics, including some that depend on a measurement of the\nsimilarity of the products of every single pair of firms. The current state of\nthe art in comprehensive and detailed firm-similarity measurements is a Boolean\nword vector model due to Hoberg and Phillips. We measure diversity using\nfirm-similarities from this Boolean model and two more sophisticated variants,\nand we consistently observe a significant dropping trend in product diversity.\nThese results make it possible to frame and start to test specific hypotheses\nfor explaining the dropping product diversity trend.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:07:50 GMT"}],"update_date":"2022-03-18"}
{"id":"2110.08368","submitter":"Giselle Sosa Jones","authors":"Giselle Sosa Jones, Beatrice Riviere, Loic Cappanera","title":"Existence and convergence of a discontinuous Galerkin method for the\n  incompressible three-phase flow problem in porous media","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents and analyzes a discontinuous Galerkin method for the\nincompressible three-phase flow problem in porous media. We use a first order\ntime extrapolation which allows us to solve the equations implicitly and\nsequentially. We show that the discrete problem is well-posed, and obtain a\npriori error estimates. Our numerical results validate the theoretical results,\ni.e. the algorithm converges with first order.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:10:03 GMT"},{"version":"v2","created":"Mon, 10 Jan 2022 20:11:00 GMT"}],"update_date":"2022-01-12"}
{"id":"2110.08369","submitter":"Omar Jes\\'us Franca Santiago","authors":"O. J. Franca and Stefan Yoshi Buhmann","title":"Modification of transition radiation by three-dimensional topological\n  insulators","comments":"18 pages, 10 figures, Published final version","journal-ref":"Phys. Rev. B 105, 155120 (2022)","doi":"10.1103/PhysRevB.105.155120","report-no":null,"categories":"cond-mat.mes-hall hep-ph hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study how transition radiation is modified by the presence of a generic\nmagnetoelectric medium with a special focus on topological insulators. To this\nend, we use the Green's function for the electromagnetic field in presence of a\nplane interface between two topological insulators with different topological\nparameters, permittivities and permeabilities. We employ the far-field\napproximation together with the steepest descent method to obtain approximate\nanalytical expressions for the electromagnetic field. Through this method we\nfind that the electric field is a superposition of spherical waves and lateral\nwaves. Contributions of both kind can be attributed to a purely topological\norigin. After computing the angular distribution of the radiation, we find that\nin a region far from the interface the main contribution to the radiation comes\nfrom the spherical waves. We present typical radiation patterns for the\ntopological insulator TlBiSe$_2$ and the magnetoelectric TbPO$_4$. In the\nultra-relativistic case, the additional contributions from the magnetoelectric\ncoupling appreciably enhance the global maximum of the angular distribution. We\nalso present an analytic expression for the frequency distribution of the\nradiation for this case. We find that in the limit where the permittivities are\nequal there still exists transition radiation of the order of the square of the\ntopological parameter with a pure topological origin.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:13:11 GMT"},{"version":"v2","created":"Wed, 10 Nov 2021 20:07:50 GMT"},{"version":"v3","created":"Tue, 19 Apr 2022 20:02:24 GMT"}],"update_date":"2022-04-25"}
{"id":"2110.08370","submitter":"Tanya Goyal","authors":"Tanya Goyal, Jiacheng Xu, Junyi Jessy Li, Greg Durrett","title":"Training Dynamics for Text Summarization Models","comments":"ACL 2022 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained language models (e.g. BART) have shown impressive results when\nfine-tuned on large summarization datasets. However, little is understood about\nthis fine-tuning process, including what knowledge is retained from\npre-training time or how content selection and generation strategies are learnt\nacross iterations. In this work, we analyze the training dynamics for\ngeneration models, focusing on summarization. Across different datasets\n(CNN/DM, XSum, MediaSum) and summary properties, such as abstractiveness and\nhallucination, we study what the model learns at different stages of its\nfine-tuning process. We find that a propensity to copy the input is learned\nearly in the training process consistently across all datasets studied. On the\nother hand, factual errors, such as hallucination of unsupported facts, are\nlearnt in the later stages, though this behavior is more varied across domains.\nBased on these observations, we explore complementary approaches for modifying\ntraining: first, disregarding high-loss tokens that are challenging to learn\nand second, disregarding low-loss tokens that are learnt very quickly in the\nlatter stages of the training process. We show that these simple training\nmodifications allow us to configure our model to achieve different goals, such\nas improving factuality or improving abstractiveness.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:13:41 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 07:14:20 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08371","submitter":"Colin Pirillo","authors":"Tyler Minnick, Colin Pirillo, Sarah Racile, Yueqi Wang","title":"Hurwitz equivalence of reflection factorizations in $G_7$","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that two reflection factorizations of a given element in an\nexceptional rank-2 complex reflection group of tetrahedral type are\nHurwitz-equivalent if and only if they generate the same subgroup and have the\nsame multiset of conjugacy classes.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:15:45 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08372","submitter":"Tim Van Hoose","authors":"Jason Murphy, Tim Van Hoose","title":"Well-posedness and blowup for the dispersion-managed nonlinear\n  Schr\\\"odinger equation","comments":"13 pages, 1 figure","journal-ref":"Proc. Amer. Math. Soc. 151 (2023), no. 5, 2489--2502","doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the nonlinear Schr\\\"odinger equation with periodic dispersion\nmanagement. We first establish global-in-time Strichartz estimates for the\nunderlying linear equation with suitable dispersion maps. As an application, we\nestablish a small-data scattering result for the $3d$ cubic equation. Finally,\nwe use a virial argument to demonstrate the existence of blowup solutions for\nthe $3d$ cubic equation with piecewise constant dispersion map.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:19:45 GMT"}],"update_date":"2023-05-11"}
{"id":"2110.08373","submitter":"Gilbert Holder","authors":"Gilbert Holder, Jens Chluba","title":"The radio SZ effect as a probe of the cosmological radio background","comments":"submitted to AAS Journals","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  If there is a substantial cosmological radio background, there should be a\nradio Sunyaev-Zeldovich (SZ) effect that goes along with it. The radio\nbackground Comptonization leads to a slight photon excess at all wavelengths,\nwhile Comptonization of the CMB at low frequencies leads to a decrement. For\nlevels of the radio background consistent with observations, these effects\ncancel each other around $\\nu\\simeq 735~$MHz, with an excess at lower\nfrequencies and a decrement at higher frequencies. Assuming a purely\ncosmological origin of the observed ARCADE radio excess, at $\\nu \\lesssim\n20\\,{\\rm GHz}$ the signal scales as $\\Delta T / T_{\\rm CMB}\\simeq 2\\,y\\left[\n(\\nu/735\\,{\\rm MHz})^{-2.59}-1\\right]$ with frequency and the Compton-$y$\nparameter of the cluster. For a typical cluster, the total radio SZ signal is\nat the level of $\\Delta T\\simeq 1\\,{\\rm mK}$ around the null, with a steep\nscaling towards radio frequencies. This is above current raw sensitivity limits\nfor many radio facilities at these wavelengths, providing a unique way to\nconfirm the cosmological origin of the ARCADE excess and probe its properties\n(e.g., redshift dependence and isotropy). We also give an expression to compute\nthe radio-analogue of the kinematic SZ effect, highlighting that this might\nprovide a new tool to probe large-scale velocity fields and the cosmic\nevolution of the radio background.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:23:27 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08374","submitter":"Mingyang Zhang","authors":"Mingyang Zhang (1), Jianan Zhang (2), Rui Wang (2), Ramesh Govindan\n  (1), Jeffrey C. Mogul (2), Amin Vahdat (2) ((1) University of Southern\n  California, (2) Google)","title":"Gemini: Practical Reconfigurable Datacenter Networks with Topology and\n  Traffic Engineering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To reduce cost, datacenter network operators are exploring blocking network\ndesigns. An example of such a design is a \"spine-free\" form of a Fat-Tree, in\nwhich pods directly connect to each other, rather than via spine blocks. To\nmaintain application-perceived performance in the face of dynamic workloads,\nthese new designs must be able to reconfigure routing and the inter-pod\ntopology. Gemini is a system designed to achieve these goals on commodity\nhardware while reconfiguring the network infrequently, rendering these blocking\ndesigns practical enough for deployment in the near future. The key to Gemini\nis the joint optimization of topology and routing, using as input a robust\nestimation of future traffic derived from multiple historical traffic matrices.\nGemini \"hedges\" against unpredicted bursts, by spreading these bursts across\nmultiple paths, to minimize packet loss in exchange for a small increase in\npath lengths. It incorporates a robust decision algorithm to determine when to\nreconfigure, and whether to use hedging. Data from tens of production fabrics\nallows us to categorize these as either low-or high-volatility; these\ncategories seem stable. For the former, Gemini finds topologies and routing\nwith near-optimal performance and cost. For the latter, Gemini's use of\nmulti-traffic-matrix optimization and hedging avoids the need for frequent\ntopology reconfiguration, with only marginal increases in path length. As a\nresult, Gemini can support existing workloads on these production fabrics using\na spine-free topology that is half the cost of the existing topology on these\nfabrics.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:23:28 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08375","submitter":"Jan Verschelde","authors":"Jan Verschelde","title":"Least Squares on GPUs in Multiple Double Precision","comments":"24 pages, 11 tables, 5 figures, added plot of the roofline model.\n  Accepted for publication in the 2022 IEEE International Parallel and\n  Distributed Processing Symposium Workshops (IPDPSW)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MS cs.DC cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper describes the application of the code generated by the CAMPARY\nsoftware to accelerate the solving of linear systems in the least squares sense\non Graphics Processing Units (GPUs), in double double, quad double, and octo\ndouble precision. The goal is to use accelerators to offset the cost overhead\ncaused by multiple double precision arithmetic. For the blocked Householder QR\nand the back substitution, of interest are those dimensions at which teraflop\nperformance is attained. The other interesting question is the cost overhead\nfactor that appears each time the precision is doubled.\n  Experimental results are reported on five different NVIDIA GPUs, with a\nparticular focus on the P100 and the V100, both capable of teraflop\nperformance. Thanks to the high Compute to Global Memory Access (CGMA) ratios\nof multiple double arithmetic, teraflop performance is already attained running\nthe double double QR on 1,024-by-1,024 matrices, both on the P100 and the V100.\nFor the back substitution, the dimension of the upper triangular system must be\nas high as 17,920 to reach one teraflops on the V100, in quad double precision,\nand then taking only the times spent by the kernels into account. The lower\nperformance of the back substitution in small dimensions does not prevent\nteraflop performance of the solver at dimension 1,024, as the time for the QR\ndecomposition dominates.\n  In doubling the precision from double double to quad double and from quad\ndouble to octo double, the observed cost overhead factors are lower than the\nfactors predicted by the arithmetical operation counts. This observation\ncorrelates with the increased performance for increased precision, which can\nagain be explained by the high CGMA ratios.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:25:14 GMT"},{"version":"v2","created":"Sun, 20 Mar 2022 23:53:20 GMT"}],"update_date":"2022-03-22"}
{"id":"2110.08376","submitter":"Raul Arenal","authors":"Avraham Bar-Hen, Ronen Bar Ziv, Tsion Ohaion-Raz, Amir Mizrahi, Simon\n  Hettler, Raul Arenal and Maya Bar Sadan","title":"Shelling with MoS$_2$ Functional CuS@MoS2 Hybrids as Electrocatalysts\n  for the Oxygen Reduction and Hydrogen Evolution Reactions","comments":"26 pages","journal-ref":"Chemical Engineering Journal, 420, 129771 (2021)","doi":"10.1016/j.cej.2021.129771","report-no":null,"categories":"physics.app-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The development of noble-metal free electrocatalysts is of high importance\nfor clean energy conversion applications. MoS$_2$ has been considered as a\npromising low cost catalyst for the hydrogen evolution reaction (HER), however\nits activity is limited by poor conductivity and low abundance of active sites.\nMoreover, its suitability as an effective catalyst for other reactions, in\nparticluar the oxygen reduction reaction (ORR), was hardly explored to date.\nHerein, we show hybrid nanostructures of shelled CuS particles with MoS$_2$\nlayers, which produces several outcomes: The MoS$_2$ shell is strained and\ndefective, and charge transfer from the core to MoS$_2$ occurs, enabling\nactivation of the basal plane of MoS$_2$. Changing the feed ratio of the\nprecursors led to control over morphology, such that the wrapping of the cores\nwith the shell was continuously varied and characterized. We found an optimal\nhybrid structure, which provided high electrochemical active surface area and\nfast charge transfer kinetics, leading to improved activity not only towards\nHER (overpotential of 225 mV at 10 mA cm$^{-1}$), but also for the sluggish ORR\n(onset potential 0.87 V vs RHE).\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:27:54 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08377","submitter":"Ivan Khokhlov","authors":"Egor Davydenko, Ivan Khokhlov, Vladimir Litvinenko, Ilya Ryakin, Ilya\n  Osokin, and Azer Babaev","title":"Starkit: RoboCup Humanoid KidSize 2021 Worldwide Champion Team Paper","comments":"15 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This article is devoted to the features that were under development between\nRoboCup 2019 Sydney and RoboCup 2021 Worldwide. These features include\nvision-related matters, such as detection and localization, mechanical and\nalgorithmic novelties. Since the competition was held virtually, the\nsimulation-specific features are also considered in the article. We give an\noverview of the approaches that were tried out along with the analysis of their\npreconditions, perspectives and the evaluation of their performance.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:34:03 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08378","submitter":"Jun Luo","authors":"Jun Luo, Shandong Wu","title":"FedSLD: Federated Learning with Shared Label Distribution for Medical\n  Image Classification","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning in medical research, by nature, needs careful attention on\nobeying the regulations of data privacy, making it difficult to train a machine\nlearning model over gathered data from different medical centers. Failure of\nleveraging data of the same kind may result in poor generalizability for the\ntrained model. Federated learning (FL) enables collaboratively training a joint\nmodel while keeping the data decentralized for multiple medical centers.\nHowever, federated optimizations often suffer from the heterogeneity of the\ndata distribution across medical centers. In this work, we propose Federated\nLearning with Shared Label Distribution (FedSLD) for classification tasks, a\nmethod that assumes knowledge of the label distributions for all the\nparticipating clients in the federation. FedSLD adjusts the contribution of\neach data sample to the local objective during optimization given knowledge of\nthe distribution, mitigating the instability brought by data heterogeneity\nacross all clients. We conduct extensive experiments on four publicly available\nimage datasets with different types of non-IID data distributions. Our results\nshow that FedSLD achieves better convergence performance than the compared\nleading FL optimization algorithms, increasing the test accuracy by up to 5.50\npercentage points.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:38:25 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08379","submitter":"Roberto Casadio","authors":"Anna D'Addio, Roberto Casadio, Andrea Giusti, Mariafelicia De\n  Laurentis","title":"Orbits in bootstrapped Newtonian gravity","comments":"REVTeX 4, 11 pages, 5 figures, 5 tables. Version to appear in PRD","journal-ref":null,"doi":"10.1103/PhysRevD.105.104010","report-no":null,"categories":"gr-qc astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bootstrapped Newtonian gravity is a non-linear version of Newton's law which\ncan be lifted to a fully geometric theory of gravity starting from a modified\npotential. Here, we study geodesics in the bootstrapped Newtonian effective\nmetric in vacuum and obtain bounds on a free parameter from Solar System data\nand S-star orbits near our Galaxy centre. These bounds make vacuum bootstrapped\nNewtonian gravity experimentally indistinguishable from General Relativity.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:38:41 GMT"},{"version":"v2","created":"Sat, 23 Apr 2022 15:40:40 GMT"}],"update_date":"2022-05-18"}
{"id":"2110.08380","submitter":"Stuart Masson","authors":"Eric Sierra, Stuart J. Masson and Ana Asenjo-Garcia","title":"Dicke superradiance in ordered lattices: dimensionality matters","comments":"13 pages, 6 figures. This version is in line with the published\n  version","journal-ref":null,"doi":"10.1103/PhysRevResearch.4.023207","report-no":null,"categories":"quant-ph physics.atom-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dicke superradiance in ordered atomic arrays is a phenomenon where atomic\nsynchronization gives rise to a burst in photon emission. This superradiant\nburst only occurs if there is one -- or just a few -- dominant decay channels.\nFor a fixed atom number, this happens only below a critical interatomic\ndistance. Here we show that array dimensionality is the determinant factor that\ndrives superradiance. In 2D and 3D arrays, superradiance occurs due to\nconstructive interference, which grows stronger with atom number. This leads to\na critical distance that scales sublogarithmically with atom number in 2D, and\nas a power law in 3D. In 1D arrays, superradiance occurs due to destructive\ninterference that effectively switches off certain decay channels, yielding a\ncritical distance that saturates with atom number. Our results provide a guide\nto explore many-body decay in state-of-the art experimental setups.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:40:40 GMT"},{"version":"v2","created":"Fri, 22 Oct 2021 22:10:50 GMT"},{"version":"v3","created":"Mon, 14 Mar 2022 16:49:48 GMT"},{"version":"v4","created":"Thu, 21 Jul 2022 02:32:04 GMT"}],"update_date":"2022-07-22"}
{"id":"2110.08381","submitter":"Pengcheng Yin","authors":"Pengcheng Yin, John Wieting, Avirup Sil, Graham Neubig","title":"On The Ingredients of an Effective Zero-shot Semantic Parser","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Semantic parsers map natural language utterances into meaning representations\n(e.g., programs). Such models are typically bottlenecked by the paucity of\ntraining data due to the required laborious annotation efforts. Recent studies\nhave performed zero-shot learning by synthesizing training examples of\ncanonical utterances and programs from a grammar, and further paraphrasing\nthese utterances to improve linguistic diversity. However, such synthetic\nexamples cannot fully capture patterns in real data. In this paper we analyze\nzero-shot parsers through the lenses of the language and logical gaps (Herzig\nand Berant, 2019), which quantify the discrepancy of language and programmatic\npatterns between the canonical examples and real-world user-issued ones. We\npropose bridging these gaps using improved grammars, stronger paraphrasers, and\nefficient learning methods using canonical examples that most likely reflect\nreal user intents. Our model achieves strong performance on two semantic\nparsing benchmarks (Scholar, Geo) with zero labeled data.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:41:16 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08382","submitter":"Elisa Negrini","authors":"Elisa Negrini, Giovanna Citti, Luca Capogna","title":"A Neural Network Ensemble Approach to System Identification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.NA math.DS math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a new algorithm for learning unknown governing equations from\ntrajectory data, using and ensemble of neural networks. Given samples of\nsolutions $x(t)$ to an unknown dynamical system $\\dot{x}(t)=f(t,x(t))$, we\napproximate the function $f$ using an ensemble of neural networks. We express\nthe equation in integral form and use Euler method to predict the solution at\nevery successive time step using at each iteration a different neural network\nas a prior for $f$. This procedure yields M-1 time-independent networks, where\nM is the number of time steps at which $x(t)$ is observed. Finally, we obtain a\nsingle function $f(t,x(t))$ by neural network interpolation. Unlike our earlier\nwork, where we numerically computed the derivatives of data, and used them as\ntarget in a Lipschitz regularized neural network to approximate $f$, our new\nmethod avoids numerical differentiations, which are unstable in presence of\nnoise. We test the new algorithm on multiple examples both with and without\nnoise in the data. We empirically show that generalization and recovery of the\ngoverning equation improve by adding a Lipschitz regularization term in our\nloss function and that this method improves our previous one especially in\npresence of noise, when numerical differentiation provides low quality target\ndata. Finally, we compare our results with the method proposed by Raissi, et\nal. arXiv:1801.01236 (2018) and with SINDy.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:45:48 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08383","submitter":"Alexandros Papangelis","authors":"Yen-Ting Lin, Alexandros Papangelis, Seokhwan Kim, Dilek Hakkani-Tur","title":"Training Conversational Agents with Generative Conversational Networks","comments":"Accepted at WeCNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rich, open-domain textual data available on the web resulted in great\nadvancements for language processing. However, while that data may be suitable\nfor language processing tasks, they are mostly non-conversational, lacking many\nphenomena that appear in human interactions and this is one of the reasons why\nwe still have many unsolved challenges in conversational AI. In this work, we\nattempt to address this by using Generative Conversational Networks to\nautomatically generate data and train social conversational agents. We evaluate\nour approach on TopicalChat with automatic metrics and human evaluators,\nshowing that with 10% of seed data it performs close to the baseline that uses\n100% of the data.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:46:39 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08384","submitter":"Julien Deparday","authors":"Julien Deparday, Xiaowei He, Jeff D. Eldredge, Karen Mulleners, and\n  David R. Williams","title":"Experimental quantification of unsteady leading-edge flow separation","comments":"21 pages, 9 figures, first revision submitted to Journal of Fluid\n  Mechanics on 11th February 2022","journal-ref":"Journal of Fluid Mechanics 941 (2022) A60","doi":"10.1017/jfm.2022.319","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose here a method to experimentally quantify unsteady leading-edge\nflow separation on aerofoils with finite thickness. The methodology relies on\nthe computation of a leading-edge suction parameter based on measured values of\nthe partial circulation around the leading-edge and the stagnation point\nlocation. We validate the computation of the leading-edge suction parameter for\nboth numerical and experimental data under steady and unsteady flow conditions.\nThe leading-order approximation of the definition of the leading-edge suction\nparameter is proven to be sufficiently accurate for the application to thin\naerofoils such as the NACA0009 without a-priori knowledge of the stagnation\npoint location. The higher-order terms including the stagnation point location\nare required to reliably compute the leading-edge suction parameter on thicker\naerofoils such as the NACA0015. The computation of the leading-edge suction\nparameter from inviscid flow theory does not assume the Kutta condition to be\nvalid at the trailing edge which allows us to compute its value for separated\nflows. The relation between the leading-edge suction parameter and the\nevolution of the shear layer height is studied in two different unsteady flow\nconditions, a fixed aerofoil in a fluctuating free-stream velocity and a\npitching aerofoil in a steady free-stream. We demonstrate here that the\ninstantaneous value of the leading-edge suction parameter based on the partial\ncirculation around the leading edge is unambiguously defined for a given flow\nfield and can serve as a directly quantitative measure of the degree of\nunsteady flow separation at the leading edge.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:46:53 GMT"},{"version":"v2","created":"Tue, 22 Feb 2022 21:55:32 GMT"}],"update_date":"2022-05-16"}
{"id":"2110.08385","submitter":"Jimit Majmudar","authors":"Jimit Majmudar, Stephen Vavasis","title":"Robust Correlation Clustering with Asymmetric Noise","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.LG math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph clustering problems typically aim to partition the graph nodes such\nthat two nodes belong to the same partition set if and only if they are\nsimilar. Correlation Clustering is a graph clustering formulation which: (1)\ntakes as input a signed graph with edge weights representing a\nsimilarity/dissimilarity measure between the nodes, and (2) requires no prior\nestimate of the number of clusters in the input graph. However, the\ncombinatorial optimization problem underlying Correlation Clustering is\nNP-hard. In this work, we propose a novel graph generative model, called the\nNode Factors Model (NFM), which is based on generating feature\nvectors/embeddings for the graph nodes. The graphs generated by the NFM contain\nasymmetric noise in the sense that there may exist pairs of nodes in the same\ncluster which are negatively correlated. We propose a novel Correlation\nClustering algorithm, called \\anormd, using techniques from semidefinite\nprogramming. Using a combination of theoretical and computational results, we\ndemonstrate that $\\texttt{$\\ell_2$-norm-diag}$ recovers nodes with sufficiently\nstrong cluster membership in graph instances generated by the NFM, thereby\nmaking progress towards establishing the provable robustness of our proposed\nalgorithm.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:47:27 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08386","submitter":"Enrico Prati","authors":"Marco Lazzarin, Davide Emilio Galli, and Enrico Prati","title":"Multi-class quantum classifiers with tensor network circuits for quantum\n  phase recognition","comments":null,"journal-ref":null,"doi":"10.1016/j.physleta.2022.128056","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hybrid quantum-classical algorithms based on variational circuits are a\npromising approach to quantum machine learning problems for near-term devices,\nbut the selection of the variational ansatz is an open issue. Recently, tensor\nnetwork-inspired circuits have been proposed as a natural choice for such\nansatz. Their employment on binary classification tasks provided encouraging\nresults. However, their effectiveness on more difficult tasks is still unknown.\nHere, we present numerical experiments on multi-class classifiers based on tree\ntensor network and multiscale entanglement renormalization ansatz circuits. We\nconducted experiments on image classification with the MNIST dataset and on\nquantum phase recognition with the XXZ model by Cirq and TensorFlow Quantum. In\nthe former case, we reduced the number of classes to four to match the aimed\noutput based on 2 qubits. The quantum data of the XXZ model consist of three\nclasses of ground states prepared by a checkerboard circuit used for the ansatz\nof the variational quantum eigensolver, corresponding to three distinct quantum\nphases. Test accuracy turned out to be 59%-93% and 82%-96% respectively,\ndepending on the model architecture and on the type of preprocessing.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:55:13 GMT"}],"update_date":"2022-03-23"}
{"id":"2110.08387","submitter":"Jiacheng Liu","authors":"Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le\n  Bras, Yejin Choi, Hannaneh Hajishirzi","title":"Generated Knowledge Prompting for Commonsense Reasoning","comments":"ACL 2022 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It remains an open question whether incorporating external knowledge benefits\ncommonsense reasoning while maintaining the flexibility of pretrained sequence\nmodels. To investigate this question, we develop generated knowledge prompting,\nwhich consists of generating knowledge from a language model, then providing\nthe knowledge as additional input when answering a question. Our method does\nnot require task-specific supervision for knowledge integration, or access to a\nstructured knowledge base, yet it improves performance of large-scale,\nstate-of-the-art models on four commonsense reasoning tasks, achieving\nstate-of-the-art results on numerical commonsense (NumerSense), general\ncommonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks.\nGenerated knowledge prompting highlights large-scale language models as\nflexible sources of external knowledge for improving commonsense reasoning. Our\ncode is available at https://github.com/liujch1998/GKP\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:58:03 GMT"},{"version":"v2","created":"Thu, 17 Mar 2022 00:04:59 GMT"},{"version":"v3","created":"Wed, 28 Sep 2022 19:24:24 GMT"}],"update_date":"2022-09-30"}
{"id":"2110.08388","submitter":"Lucas Torroba Hennigen","authors":"Alexander Immer, Lucas Torroba Hennigen, Vincent Fortuin, Ryan\n  Cotterell","title":"Probing as Quantifying Inductive Bias","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Pre-trained contextual representations have led to dramatic performance\nimprovements on a range of downstream tasks. Such performance improvements have\nmotivated researchers to quantify and understand the linguistic information\nencoded in these representations. In general, researchers quantify the amount\nof linguistic information through probing, an endeavor which consists of\ntraining a supervised model to predict a linguistic property directly from the\ncontextual representations. Unfortunately, this definition of probing has been\nsubject to extensive criticism in the literature, and has been observed to lead\nto paradoxical and counter-intuitive results. In the theoretical portion of\nthis paper, we take the position that the goal of probing ought to be measuring\nthe amount of inductive bias that the representations encode on a specific\ntask. We further describe a Bayesian framework that operationalizes this goal\nand allows us to quantify the representations' inductive bias. In the empirical\nportion of the paper, we apply our framework to a variety of NLP tasks. Our\nresults suggest that our proposed framework alleviates many previous problems\nfound in probing. Moreover, we are able to offer concrete evidence that -- for\nsome tasks -- fastText can offer a better inductive bias than BERT.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:01:16 GMT"},{"version":"v2","created":"Thu, 24 Mar 2022 23:12:27 GMT"}],"update_date":"2022-03-28"}
{"id":"2110.08389","submitter":"Ali Mashayek","authors":"Thomas Bewley, Ali Mashayek, Daniele Cavaglieri, Paolo Luchini","title":"Tweed and wireframe: accelerated relaxation algorithms for multigrid\n  solution of elliptic PDEs on stretched structured grids","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two new relaxation schemes are proposed for the smoothing step in the\ngeometric multigrid solution of PDEs on 2D and 3D stretched structured grids.\nThe new schemes are characterized by efficient line relaxation on branched sets\nof lines of alternating colour, where the lines are constructed to be\neverywhere orthogonal to the local direction of maximum grid clustering. Tweed\nrelaxation is best suited for grid clustering near the boundaries of the\ncomputational domain, whereas wireframe relaxation is best suited for grid\nclustering near the centre of the computational domain. On strongly stretched\ngrids of these types, multigrid leveraging these new smoothing schemes\nsignificantly outperforms multigrid based on other leading relaxation schemes,\nsuch as checkerboard and alternating-direction zebra relaxation, for the\nnumerical solution of large linear systems arising from the discretization of\nelliptic PDEs.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:06:57 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08390","submitter":"Pedram Ghavidel","authors":"Armin Abadifard, Pedram Ghavidel, Seyed Hossein Hosseini, Masoud\n  Farhadi","title":"Non-Isolated Single-Switch Zeta Based High-Step up DC-DC Converter with\n  Coupled Inductor","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  In this paper, a non-isolated high step-up DC-DC converter has been proposed\nfor renewable energy applications. The proposed structure converter has been\nderived from the fundamental Zeta converter, in both of which only a single\nswitch is employed. The voltage gain ratio has considerably enhanced in this\nconverter with the absence of using switched capacity. To magnify voltage gain\nof the converter, a coupled-inductor has adopted. Increase and decrease of gain\nby changing the ratio of coupled-inductor assist the duty cycle. The number of\ncomponents is low in this structure. The operating principle and evaluation of\nthe proposed converter, considering designing approaches for elements, are\ndiscussed in detail. To verify the feasibility of the proposed converter,\nsimulation results have been provided and evaluated.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:09:25 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08391","submitter":"Ingrid Lan","authors":"Ingrid S. Lan (1), Ju Liu (2), Weiguang Yang (1), Alison L. Marsden\n  (1) ((1) Stanford University, Stanford, USA, (2) Southern University of\n  Science and Technology, Shenzhen, P.R. China)","title":"A reduced unified continuum formulation for vascular fluid-structure\n  interaction","comments":null,"journal-ref":null,"doi":"10.1016/j.cma.2022.114852","report-no":null,"categories":"physics.comp-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We recently derived the unified continuum and variational multiscale\nformulation for fluid-structure interaction (FSI) using the Gibbs free energy.\nRestricting our attention to vascular FSI, we now reduce this arbitrary\nLagrangian-Eulerian (ALE) formulation by adopting three assumptions for the\nvascular wall. The resulting reduced unified continuum formulation achieves\nmonolithic FSI coupling in the Eulerian frame through a simple modification of\nthe fluid boundary integral. While ostensibly similar to the semi-discrete\nformulation of the coupled momentum method, its underlying derivation does not\nrely on an assumption of a fictitious body force in the elastodynamics\nsub-problem and therefore represents a direct simplification of the ALE method.\nUniform temporal discretization is performed via the generalized-$\\alpha$\nscheme. In contrast to the predominant approach yielding only first-order\naccuracy for pressure, we collocate both pressure and velocity at the\nintermediate time step to achieve uniform second-order temporal accuracy. In\nconjunction with quadratic tetrahedral elements, our methodology offers\nhigher-order temporal and spatial accuracy for quantities of clinical interest.\nFurthermore, without loss of consistency, a segregated predictor\nmulti-corrector algorithm is developed to preserve the same block structure as\nfor the incompressible Navier-Stokes equations in the implicit solver's\nassociated linear system. Block preconditioning of a monolithically coupled FSI\nsystem is therefore made possible for the first time. Compared to alternative\npreconditioners, our three-level nested block preconditioner, which improves\nrepresentation of the Schur complement, demonstrates robust performance over a\nwide range of physical parameters. We present verification against Womersley's\ndeformable wall theory and additionally develop practical modeling techniques\nfor clinical applications.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:10:43 GMT"}],"update_date":"2022-04-06"}
{"id":"2110.08392","submitter":"Igor Nikonov","authors":"Igor Nikonov","title":"Intersection formulas for parities on virtual knots","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove that parities on virtual knots come from invariant 1-cycles on the\narcs of knot diagrams. In turn, the invariant cycles are determined by\nquasi-indices on the crossings of the diagrams. The found connection between\nthe parities and the (quasi)-indices allows to define a new series of parities\non virtual knots.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:11:05 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08393","submitter":"Hong Guan","authors":"Hong Guan and Chitta Baral","title":"A Bayesian Approach for Medical Inquiry and Disease Inference in\n  Automated Differential Diagnosis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a Bayesian approach for both medical inquiry and disease\ninference, the two major phases in differential diagnosis. Unlike previous work\nthat simulates data from given probabilities and uses ML algorithms on them, we\ndirectly use the Quick Medical Reference (QMR) belief network, and apply\nBayesian inference in the inference phase and Bayesian experimental design in\nthe inquiry phase. Moreover, we improve the inquiry phase by extending the\nBayesian experimental design framework from one-step search to multi-step\nsearch. Our approach has some practical advantages as it is interpretable, free\nof costly training, and able to adapt to new changes without any additional\neffort. Our experiments show that our approach achieves new state-of-the-art\nresults on two simulated datasets, SymCAT and HPO, and competitive results on\ntwo diagnosis dialogue datasets, Muzhi and Dxy.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:16:05 GMT"},{"version":"v2","created":"Sat, 23 Oct 2021 03:39:16 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.08394","submitter":"Jun Luo","authors":"Jun Luo, Shandong Wu","title":"Adapt to Adaptation: Learning Personalization for Cross-Silo Federated\n  Learning","comments":"Accepted by IJCAI 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conventional federated learning (FL) trains one global model for a federation\nof clients with decentralized data, reducing the privacy risk of centralized\ntraining. However, the distribution shift across non-IID datasets, often poses\na challenge to this one-model-fits-all solution. Personalized FL aims to\nmitigate this issue systematically. In this work, we propose APPLE, a\npersonalized cross-silo FL framework that adaptively learns how much each\nclient can benefit from other clients' models. We also introduce a method to\nflexibly control the focus of training APPLE between global and local\nobjectives. We empirically evaluate our method's convergence and generalization\nbehaviors, and perform extensive experiments on two benchmark datasets and two\nmedical imaging datasets under two non-IID settings. The results show that the\nproposed personalized FL framework, APPLE, achieves state-of-the-art\nperformance compared to several other personalized FL approaches in the\nliterature. The code is publicly available at\nhttps://github.com/ljaiverson/pFL-APPLE.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:23:14 GMT"},{"version":"v2","created":"Mon, 2 May 2022 22:09:10 GMT"},{"version":"v3","created":"Mon, 6 Jun 2022 16:52:43 GMT"}],"update_date":"2022-06-07"}
{"id":"2110.08395","submitter":"Chia-Chien Hung","authors":"Chia-Chien Hung, Anne Lauscher, Simone Paolo Ponzetto, Goran\n  Glava\\v{s}","title":"DS-TOD: Efficient Domain Specialization for Task Oriented Dialog","comments":"Findings of ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Recent work has shown that self-supervised dialog-specific pretraining on\nlarge conversational datasets yields substantial gains over traditional\nlanguage modeling (LM) pretraining in downstream task-oriented dialog (TOD).\nThese approaches, however, exploit general dialogic corpora (e.g., Reddit) and\nthus presumably fail to reliably embed domain-specific knowledge useful for\nconcrete downstream TOD domains. In this work, we investigate the effects of\ndomain specialization of pretrained language models (PLMs) for TOD. Within our\nDS-TOD framework, we first automatically extract salient domain-specific terms,\nand then use them to construct DomainCC and DomainReddit -- resources that we\nleverage for domain-specific pretraining, based on (i) masked language modeling\n(MLM) and (ii) response selection (RS) objectives, respectively. We further\npropose a resource-efficient and modular domain specialization by means of\ndomain adapters -- additional parameter-light layers in which we encode the\ndomain knowledge. Our experiments with prominent TOD tasks -- dialog state\ntracking (DST) and response retrieval (RR) -- encompassing five domains from\nthe MultiWOZ benchmark demonstrate the effectiveness of DS-TOD. Moreover, we\nshow that the light-weight adapter-based specialization (1) performs comparably\nto full fine-tuning in single domain setups and (2) is particularly suitable\nfor multi-domain specialization, where besides advantageous computational\nfootprint, it can offer better TOD performance.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:25:51 GMT"},{"version":"v2","created":"Fri, 20 May 2022 18:17:57 GMT"}],"update_date":"2022-05-24"}
{"id":"2110.08396","submitter":"Samuel Dooley","authors":"Samuel Dooley, Ryan Downing, George Wei, Nathan Shankar, Bradon\n  Thymes, Gudrun Thorkelsdottir, Tiye Kurtz-Miott, Rachel Mattson, Olufemi\n  Obiwumi, Valeriia Cherepanova, Micah Goldblum, John P Dickerson, Tom\n  Goldstein","title":"Comparing Human and Machine Bias in Face Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CY cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Much recent research has uncovered and discussed serious concerns of bias in\nfacial analysis technologies, finding performance disparities between groups of\npeople based on perceived gender, skin type, lighting condition, etc. These\naudits are immensely important and successful at measuring algorithmic bias but\nhave two major challenges: the audits (1) use facial recognition datasets which\nlack quality metadata, like LFW and CelebA, and (2) do not compare their\nobserved algorithmic bias to the biases of their human alternatives. In this\npaper, we release improvements to the LFW and CelebA datasets which will enable\nfuture researchers to obtain measurements of algorithmic bias that are not\ntainted by major flaws in the dataset (e.g. identical images appearing in both\nthe gallery and test set). We also use these new data to develop a series of\nchallenging facial identification and verification questions that we\nadministered to various algorithms and a large, balanced sample of human\nreviewers. We find that both computer models and human survey participants\nperform significantly better at the verification task, generally obtain lower\naccuracy rates on dark-skinned or female subjects for both tasks, and obtain\nhigher accuracy rates when their demographics match that of the question.\nComputer models are observed to achieve a higher level of accuracy than the\nsurvey participants on both tasks and exhibit bias to similar degrees as the\nhuman survey participants.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:26:20 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 15:30:11 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.08397","submitter":"Guchuan Li","authors":"Guchuan Li","title":"Invertible spectra of finite type","comments":"19 pages. Comments welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe the necessary and sufficient numerical condition when an element\n$X$ in the Picard group of $K(2)$-local category at prime $p \\geqslant 5$ is of\nfinite type, i.e., $\\pi_kX$ is finitely generated as a $\\mathbb{Z}_p$-module\nfor all $k \\in \\mathbb{Z}$.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:26:59 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08398","submitter":"Peihao Zhu","authors":"Peihao Zhu, Rameen Abdal, John Femiani, Peter Wonka","title":"Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for\n  Generative Adversarial Networks","comments":"Video: https://youtu.be/RLBJ-mem9gM","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a new method for one shot domain adaptation. The input to our\nmethod is trained GAN that can produce images in domain A and a single\nreference image I_B from domain B. The proposed algorithm can translate any\noutput of the trained GAN from domain A to domain B. There are two main\nadvantages of our method compared to the current state of the art: First, our\nsolution achieves higher visual quality, e.g. by noticeably reducing\noverfitting. Second, our solution allows for more degrees of freedom to control\nthe domain gap, i.e. what aspects of image I_B are used to define the domain B.\nTechnically, we realize the new method by building on a pre-trained StyleGAN\ngenerator as GAN and a pre-trained CLIP model for representing the domain gap.\nWe propose several new regularizers for controlling the domain gap to optimize\nthe weights of the pre-trained StyleGAN generator to output images in domain B\ninstead of domain A. The regularizers prevent the optimization from taking on\ntoo many attributes of the single reference image. Our results show significant\nvisual improvements over the state of the art as well as multiple applications\nthat highlight improved control.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:32:12 GMT"},{"version":"v2","created":"Sun, 28 Nov 2021 23:47:36 GMT"}],"update_date":"2021-11-30"}
{"id":"2110.08399","submitter":"John Arrington","authors":"J. Arrington, J. Bane, A. Daniel, N. Fomin, D. Gaskell, J. Seely, R.\n  Asaturyan, F. Benmokhtar, W. Boeglin, P. Bosted, M.H.S. Bukhari, M.E.\n  Christy, S. Connell, M.M. Dalton, D. Day, J. Dunne, D. Dutta, L. El Fassi, R.\n  Ent, H. Fenker, H. Gao, R.J. Holt, T. Horn, E. Hungerford, M.K. Jones, J.\n  Jourdan, N. Kalantarians, C.E. Keppel, D. Kiselev, A.F. Lung, S. Malace, D.G.\n  Meekins, T. Mertens, H. Mkrtchyan, G. Niculescu, I. Niculescu, D.H.\n  Potterveld, C. Perdrisat, V. Punjabi, X. Qian, P.E. Reimer, J. Roche, V.M.\n  Rodriguez, O. Rondon, E. Schulte, K. Slifer, G.R. Smith, P. Solvignon, V.\n  Tadevosyan, L. Tang, G. Testa, R. Trojer, V. Tvaskis, F.R. Wesselmann, S.A.\n  Wood, L. Yuan, X. Zheng","title":"Measurement of the EMC effect in light and heavy nuclei","comments":"28 pages, 23 figures, archival paper for Jefferson Lab experiment\n  E03-103","journal-ref":null,"doi":"10.1103/PhysRevC.104.065203","report-no":null,"categories":"nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inclusive electron scattering from nuclear targets has been measured to\nextract the nuclear dependence of the inelastic cross section in Hall C at the\nThomas Jefferson National Accelerator facility. Results are presented for 2H,\n3He, 4He, 9B, 12C, 63Cu and 197Au at an incident electron beam energy of 5.77\nGeV for a range of momentum transfer from Q^2 = 2 to 7 (GeV/c)^2. These data\nimprove the precision of the existing measurements of the EMC effect in the\nnuclear targets at large x, and allow for more detailed examinations of the A\ndependence of the EMC effect.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:35:15 GMT"},{"version":"v2","created":"Tue, 7 Dec 2021 03:52:44 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08400","submitter":"Christene Lynch","authors":"C. R. Lynch, T. J. Galvin, J. L. B. Line, C. H. Jordan, C. M. Trott,\n  J. K. Chege, B. McKinley, M. Johnston-Hollitt, S. J. Tingay","title":"The MWA Long Baseline Epoch of Reionisation Survey: I. Improved Source\n  Catalogue for the EoR 0 field","comments":"25 pages, 14 figures, Accepted for publication in PASA","journal-ref":null,"doi":"10.1017/pasa.2021.50","report-no":null,"categories":"astro-ph.CO astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One of the principal systematic constraints on the Epoch of Reionisation\n(EoR) experiment is the accuracy of the foreground calibration model. Recent\nresults have shown that highly accurate models of extended foreground sources,\nand including models for sources in both the primary beam and its sidelobes,\nare necessary for reducing foreground power. To improve the accuracy of the\nsource models for the EoR fields observed by the Murchison Widefield Array\n(MWA), we conducted the MWA Long Baseline Epoch of Reionisation Survey (LoBES).\nThis survey consists of multi-frequency observations of the main MWA EoR fields\nand their eight neighbouring fields using the MWA Phase II extended array. We\npresent the results of the first half of this survey centred on the MWA EoR0\nobserving field (centred at RA(J2000) 0 h, Dec(J2000) -27 deg). This half of\nthe survey covers an area of 3069 degrees$^2$, with an average rms of 2.1 mJy\nbeam$^{-1}$. The resulting catalogue contains a total of 80824 sources, with 16\nseparate spectral measurements between 100 and 230 MHz, and spectral modelling\nfor 78$\\%$ of these sources. Over this region we estimate that the catalogue is\n90$\\%$ complete at 32 mJy, and 70$\\%$ complete at 10.5~mJy. The overall\nnormalised source counts are found to be in good agreement with previous\nlow-frequency surveys at similar sensitivities. Testing the performance of the\nnew source models we measure lower residual rms values for peeled sources,\nparticularly for extended sources, in a set of MWA Phase I data. The\n2-dimensional power spectrum of these data residuals also show improvement on\nsmall angular scales -- consistent with the better angular resolution of the\nLoBES catalogue. It is clear that the LoBES sky models improve upon the current\nsky model used by the Australian MWA EoR group for the EoR0 field.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:35:59 GMT"}],"update_date":"2021-12-08"}
{"id":"2110.08401","submitter":"Zhaoyi Xu","authors":"Zhaoyi Xu, Cong Shi, Tianfang Zhang, Shuping Li, Yichao Yuan,\n  Chung-Tse Michael Wu, Yingying Chen, Athina Petropulu","title":"Simultaneous Monitoring of Multiple People's Vital Sign Leveraging a\n  Single Phased-MIMO Radar","comments":null,"journal-ref":null,"doi":"10.1109/JERM.2022.3143431.","report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vital sign monitoring plays a critical role in tracking the physiological\nstate of people and enabling various health-related applications (e.g.,\nrecommending a change of lifestyle, examining the risk of diseases).\nTraditional approaches rely on hospitalization or body-attached instruments,\nwhich are costly and intrusive. Therefore, researchers have been exploring\ncontact-less vital sign monitoring with radio frequency signals in recent\nyears. Early studies with continuous wave radars/WiFi devices work on detecting\nvital signs of a single individual, but it still remains challenging to\nsimultaneously monitor vital signs of multiple subjects, especially those who\nlocate in proximity. In this paper, we design and implement a time-division\nmultiplexing (TDM) phased-MIMO radar sensing scheme for high-precision vital\nsign monitoring of multiple people. Our phased-MIMO radar can steer the mmWave\nbeam towards different directions with a micro-second delay, which enables\ncapturing the vital signs of multiple individuals at the same radial distance\nto the radar. Furthermore, we develop a TDM-MIMO technique to fully utilize all\ntransmitting antenna (TX)-receiving antenna (RX) pairs, thereby significantly\nboosting the signal-to-noise ratio. Based on the designed TDM phased-MIMO\nradar, we develop a system to automatically localize multiple human subjects\nand estimate their vital signs. Extensive evaluations show that under\ntwo-subject scenarios, our system can achieve an error of less than 1 beat per\nminute (BPM) and 3 BPM for breathing rate (BR) and heartbeat rate (HR)\nestimations, respectively, at a subject-to-radar distance of $1.6~m$. The\nminimal subject-to-subject angle separation is $40{\\deg}$, corresponding to a\nclose distance of $0.5~m$ between two subjects, which outperforms the\nstate-of-the-art.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:38:29 GMT"}],"update_date":"2022-04-11"}
{"id":"2110.08402","submitter":"Tin Lai","authors":"Tin Lai","title":"sbp-env: Sampling-based Motion Planners' Testing Environment","comments":null,"journal-ref":"Journal of Open Source Software, 6(66), 3782 (2021)","doi":"10.21105/joss.03782","report-no":null,"categories":"cs.RO cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sampling-based motion planners' testing environment (sbp-env) is a full\nfeature framework to quickly test different sampling-based algorithms for\nmotion planning. sbp-env focuses on the flexibility of tinkering with different\naspects of the framework, and had divided the main planning components into two\ncategories (i) samplers and (ii) planners.\n  The focus of motion planning research had been mainly on (i) improving the\nsampling efficiency (with methods such as heuristic or learned distribution)\nand (ii) the algorithmic aspect of the planner using different routines to\nbuild a connected graph. Therefore, by separating the two components one can\nquickly swap out different components to test novel ideas.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:39:44 GMT"},{"version":"v2","created":"Thu, 28 Oct 2021 03:26:10 GMT"}],"update_date":"2021-10-29"}
{"id":"2110.08403","submitter":"Chandra Maddila","authors":"Chandra Maddila, Suhas Shanbhogue, Apoorva Agrawal, Thomas Zimmermann,\n  Chetan Bansal, Nicole Forsgren, Divyanshu Agrawal, Kim Herzig, Arie van\n  Deursen","title":"Nalanda: A Socio-Technical Graph for Building Software Analytics Tools\n  at Enterprise Scale","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Software development is information-dense knowledge work that requires\ncollaboration with other developers and awareness of artifacts such as work\nitems, pull requests, and files. With the speed of development increasing,\ninformation overload is a challenge for people developing and maintaining these\nsystems. Finding information and people is difficult for software engineers,\nespecially when they work in large software systems or have just recently\njoined a project. In this paper, we build a large scale data platform named\nNalanda platform, which contains two subsystems: 1. A large scale\nsocio-technical graph system, named Nalanda graph system 2. A large scale\nrecommendation system, named Nalanda index system that aims at satisfying the\ninformation needs of software developers. The Nalanda graph is an enterprise\nscale graph with data from 6,500 repositories, with 37,410,706 nodes and\n128,745,590 edges. On top of the Nalanda graph system, we built software\nanalytics applications including a newsfeed named MyNalanda, and based on\norganic growth alone, it has Daily Active Users (DAU) of 290 and Monthly Active\nUsers (MAU) of 590. A preliminary user study shows that 74% of developers and\nengineering managers surveyed are favorable toward continued use of the\nplatform for information discovery. The Nalanda index system constitutes two\nindices: artifact index and expert index. It uses the socio-technical graph\n(Nalanda graph system) to rank the results and provide better recommendations\nto software developers. A large scale quantitative evaluation shows that the\nNalanda index system provides recommendations with an accuracy of 78% for the\ntop three recommendations.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:55:23 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 22:22:42 GMT"},{"version":"v3","created":"Sat, 5 Mar 2022 18:20:22 GMT"},{"version":"v4","created":"Mon, 19 Sep 2022 21:01:20 GMT"}],"update_date":"2022-09-21"}
{"id":"2110.08404","submitter":"Clara Bradley","authors":"Clara Bradley and James Owen Weatherall","title":"Mathematical Responses to the Hole Argument: Then and Now","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.hist-ph gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We argue that several apparently distinct responses to the hole argument, all\ninvoking formal or mathematical considerations, should be viewed as a unified\n\"mathematical response\". We then consider and rebut two prominent critiques of\nthe mathematical response before reflecting on what is ultimately at issue in\nthis literature.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 22:58:29 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08405","submitter":"Jayasinghage Ruchira Nirmali Perera","authors":"Robert Lipton and Ruchira Perera","title":"Bloch Spectra for High Contrast Elastic Media","comments":"37 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:1512.06062","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Analytic representation formulas and power series are developed to describe\nthe band structure inside periodic elastic crystals made from high contrast\ninclusions. We use source free modes associated with structural spectra to\nrepresent the solution operator of the Lam\\'e system inside phononic crystals.\nConvergent power series for the Bloch wave spectrum are obtained using the\nrepresentation formulas. An explicit bound on the convergence radius is given\nthrough the structural spectra of the inclusion array and the Dirichlet spectra\nof the inclusions. Sufficient conditions for the separation of spectral\nbranches of the dispersion relation for any fixed quasi-momentum are\nidentified.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:06:39 GMT"},{"version":"v2","created":"Sun, 23 Jan 2022 17:49:05 GMT"}],"update_date":"2022-01-25"}
{"id":"2110.08406","submitter":"Charlotte Loh","authors":"Charlotte Loh, Thomas Christensen, Rumen Dangovski, Samuel Kim and\n  Marin Soljacic","title":"Surrogate- and invariance-boosted contrastive learning for data-scarce\n  applications in science","comments":"21 pages, 10 figures","journal-ref":null,"doi":"10.1038/s41467-022-31915-y","report-no":null,"categories":"cs.LG cond-mat.mtrl-sci physics.app-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deep learning techniques have been increasingly applied to the natural\nsciences, e.g., for property prediction and optimization or material discovery.\nA fundamental ingredient of such approaches is the vast quantity of labelled\ndata needed to train the model; this poses severe challenges in data-scarce\nsettings where obtaining labels requires substantial computational or labor\nresources. Here, we introduce surrogate- and invariance-boosted contrastive\nlearning (SIB-CL), a deep learning framework which incorporates three\n``inexpensive'' and easily obtainable auxiliary information sources to overcome\ndata scarcity. Specifically, these are: 1)~abundant unlabeled data, 2)~prior\nknowledge of symmetries or invariances and 3)~surrogate data obtained at\nnear-zero cost. We demonstrate SIB-CL's effectiveness and generality on various\nscientific problems, e.g., predicting the density-of-states of 2D photonic\ncrystals and solving the 3D time-independent Schrodinger equation. SIB-CL\nconsistently results in orders of magnitude reduction in the number of labels\nneeded to achieve the same network accuracies.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:08:24 GMT"}],"update_date":"2022-08-24"}
{"id":"2110.08407","submitter":"Pauliina Paavilainen","authors":"Pauliina Paavilainen, Saad Ullah Akram, Juho Kannala","title":"Bridging the gap between paired and unpaired medical image translation","comments":"Deep Generative Models for MICCAI (DGM4MICCAI) workshop 2021","journal-ref":null,"doi":"10.1007/978-3-030-88210-5_4","report-no":null,"categories":"eess.IV cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Medical image translation has the potential to reduce the imaging workload,\nby removing the need to capture some sequences, and to reduce the annotation\nburden for developing machine learning methods. GANs have been used\nsuccessfully to translate images from one domain to another, such as MR to CT.\nAt present, paired data (registered MR and CT images) or extra supervision\n(e.g. segmentation masks) is needed to learn good translation models.\nRegistering multiple modalities or annotating structures within each of them is\na tedious and laborious task. Thus, there is a need to develop improved\ntranslation methods for unpaired data. Here, we introduce modified pix2pix\nmodels for tasks CT$\\rightarrow$MR and MR$\\rightarrow$CT, trained with unpaired\nCT and MR data, and MRCAT pairs generated from the MR scans. The proposed\nmodifications utilize the paired MR and MRCAT images to ensure good alignment\nbetween input and translated images, and unpaired CT images ensure the\nMR$\\rightarrow$CT model produces realistic-looking CT and CT$\\rightarrow$MR\nmodel works well with real CT as input. The proposed pix2pix variants\noutperform baseline pix2pix, pix2pixHD and CycleGAN in terms of FID and KID,\nand generate more realistic looking CT and MR translations.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:15:12 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08408","submitter":"Benjamin Lynch","authors":"Nariaki V. Nitta, Tamitha Mulligan, Emilia K. J. Kilpua, Benjamin J.\n  Lynch, Marilena Mierla, Jennifer O'Kane, Paolo Pagano, Erika Palmerio, Jens\n  Pomoell, Ian G. Richardson, Luciano Rodriguez, Alexis P. Rouillard, Suvadip\n  Sinha, Nandita Srivastava, Dana-Camelia Talpeanu, Stephanie L. Yardley,\n  Andrei N. Zhukov","title":"Understanding the Origins of Problem Geomagnetic Storms Associated With\n  \"Stealth\" Coronal Mass Ejections","comments":"60 pages, 25 figures, 5 tables. Accepted for publication in Space\n  Science Reviews","journal-ref":"Space Sci Rev 217, 82 (2021)","doi":"10.1007/s11214-021-00857-0","report-no":null,"categories":"astro-ph.SR physics.space-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Geomagnetic storms are an important aspect of space weather and can result in\nsignificant impacts on space- and ground-based assets. The majority of strong\nstorms are associated with the passage of interplanetary coronal mass ejections\n(ICMEs) in the near-Earth environment. In many cases, these ICMEs can be traced\nback unambiguously to a specific coronal mass ejection (CME) and solar activity\non the frontside of the Sun. Hence, predicting the arrival of ICMEs at Earth\nfrom routine observations of CMEs and solar activity currently makes a major\ncontribution to the forecasting of geomagnetic storms. However, it is clear\nthat some ICMEs, which may also cause enhanced geomagnetic activity, cannot be\ntraced back to an observed CME, or, if the CME is identified, its origin may be\nelusive or ambiguous in coronal images. Such CMEs have been termed \"stealth\nCMEs.\" In this review, we focus on these \"problem\" geomagnetic storms in the\nsense that the solar/CME precursors are enigmatic and stealthy. We start by\nreviewing evidence for stealth CMEs discussed in past studies. We then identify\nseveral moderate to strong geomagnetic storms (minimum Dst < -50 nT) in solar\ncycle 24 for which the related solar sources and/or CMEs are unclear and\napparently stealthy. We discuss the solar and in situ circumstances of these\nevents and identify several scenarios that may account for their elusive solar\nsignatures. These range from observational limitations (e.g., a coronagraph\nnear Earth may not detect an incoming CME if it is diffuse and not wide enough)\nto the possibility that there is a class of mass ejections from the Sun that\nhave only weak or hard-to-observe coronal signatures. In particular, some of\nthese sources are only clearly revealed by considering the evolution of coronal\nstructures over longer time intervals than is usually considered. We also\nreview a variety of numerical modelling approaches...\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:16:56 GMT"}],"update_date":"2021-11-05"}
{"id":"2110.08409","submitter":"Andrew Zucker","authors":"Martin Balko, David Chodounsk\\'y, Natasha Dobrinen, Jan Hubi\\v{c}ka,\n  Mat\\v{e}j Kon\\v{e}cn\\'y, Lluis Vena, and Andy Zucker","title":"Exact big Ramsey degrees via coding trees","comments":"Submitted version","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We characterize the big Ramsey degrees of free amalgamation classes in finite\nbinary languages defined by finitely many forbidden irreducible substructures,\nthus refining the recent upper bounds given by Zucker. Using this\ncharacterization, we show that the Fra\\\"iss\\'e limit of each such class admits\na big Ramsey structure. Consequently, the automorphism group of each such\nFra\\\"iss\\'e limit has a metrizable universal completion flow.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:17:31 GMT"},{"version":"v2","created":"Sat, 25 Dec 2021 14:04:34 GMT"}],"update_date":"2021-12-28"}
{"id":"2110.08410","submitter":"Matias Cattaneo","authors":"Matias D. Cattaneo, Luke Keele, Rocio Titiunik","title":"Covariate Adjustment in Regression Discontinuity Designs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME econ.EM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Regression Discontinuity (RD) design is a widely used non-experimental\nmethod for causal inference and program evaluation. While its canonical\nformulation only requires a score and an outcome variable, it is common in\nempirical work to encounter RD analyses where additional variables are used for\nadjustment. This practice has led to misconceptions about the role of covariate\nadjustment in RD analysis, from both methodological and empirical perspectives.\nIn this chapter, we review the different roles of covariate adjustment in RD\ndesigns, and offer methodological guidance for its correct use.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:41:19 GMT"},{"version":"v2","created":"Wed, 24 Aug 2022 12:36:23 GMT"}],"update_date":"2022-08-25"}
{"id":"2110.08411","submitter":"Didong Li","authors":"Didong Li, Andrew Jones, Sudipto Banerjee, Barbara E. Engelhardt","title":"Multi-group Gaussian Processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Gaussian processes (GPs) are pervasive in functional data analysis, machine\nlearning, and spatial statistics for modeling complex dependencies. Modern\nscientific data sets are typically heterogeneous and often contain multiple\nknown discrete subgroups of samples. For example, in genomics applications\nsamples may be grouped according to tissue type or drug exposure. In the\nmodeling process it is desirable to leverage the similarity among groups while\naccounting for differences between them. While a substantial literature exists\nfor GPs over Euclidean domains $\\mathbb{R}^p$, GPs on domains suitable for\nmulti-group data remain less explored. Here, we develop a multi-group Gaussian\nprocess (MGGP), which we define on $\\mathbb{R}^p\\times \\mathscr{C}$, where\n$\\mathscr{C}$ is a finite set representing the group label. We provide general\nmethods to construct valid (positive definite) covariance functions on this\ndomain, and we describe algorithms for inference, estimation, and prediction.\nWe perform simulation experiments and apply MGGP to gene expression data to\nillustrate the behavior and advantages of the MGGP in the joint modeling of\ncontinuous and categorical variables.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:48:04 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08412","submitter":"Andreas Madsen","authors":"Andreas Madsen, Nicholas Meade, Vaibhav Adlakha, Siva Reddy","title":"Evaluating the Faithfulness of Importance Measures in NLP by Recursively\n  Masking Allegedly Important Tokens and Retraining","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  To explain NLP models a popular approach is to use importance measures, such\nas attention, which inform input tokens are important for making a prediction.\nHowever, an open question is how well these explanations accurately reflect a\nmodel's logic, a property called faithfulness.\n  To answer this question, we propose Recursive ROAR, a new faithfulness\nmetric. This works by recursively masking allegedly important tokens and then\nretraining the model. The principle is that this should result in worse model\nperformance compared to masking random tokens. The result is a performance\ncurve given a masking-ratio. Furthermore, we propose a summarizing metric using\nrelative area-between-curves (RACU), which allows for easy comparison across\npapers, models, and tasks.\n  We evaluate 4 different importance measures on 8 different datasets, using\nboth LSTM-attention models and RoBERTa models. We find that the faithfulness of\nimportance measures is both model-dependent and task-dependent. This conclusion\ncontradicts previous evaluations in both computer vision and faithfulness of\nattention literature.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 23:59:42 GMT"},{"version":"v2","created":"Thu, 19 May 2022 21:02:08 GMT"},{"version":"v3","created":"Mon, 31 Oct 2022 18:09:19 GMT"}],"update_date":"2022-11-02"}
{"id":"2110.08413","submitter":"Maxime Peyrard","authors":"Maxime Peyrard, Sarvjeet Singh Ghotra, Martin Josifoski, Vidhan\n  Agarwal, Barun Patra, Dean Carignan, Emre Kiciman, Robert West","title":"Invariant Language Modeling","comments":"Published at EMNLP 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large pretrained language models are critical components of modern NLP\npipelines. Yet, they suffer from spurious correlations, poor out-of-domain\ngeneralization, and biases. Inspired by recent progress in causal machine\nlearning, in particular the invariant risk minimization (IRM) paradigm, we\npropose invariant language modeling, a framework for learning invariant\nrepresentations that generalize better across multiple environments. In\nparticular, we adapt a game-theoretic formulation of IRM (IRM-games) to\nlanguage models, where the invariance emerges from a specific training schedule\nin which all the environments compete to optimize their own\nenvironment-specific loss by updating subsets of the model in a round-robin\nfashion. We focus on controlled experiments to precisely demonstrate the\nability of our method to (i) remove structured noise, (ii) ignore specific\nspurious correlations without affecting global performance, and (iii) achieve\nbetter out-of-domain generalization. These benefits come with a negligible\ncomputational overhead compared to standard training, do not require changing\nthe local loss, and can be applied to any language model. We believe this\nframework is promising to help mitigate spurious correlations and biases in\nlanguage models.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:03:19 GMT"},{"version":"v2","created":"Mon, 14 Nov 2022 22:11:19 GMT"}],"update_date":"2022-11-16"}
{"id":"2110.08414","submitter":"Robert Vandermolen","authors":"Robert Vandermolen, Duncan Wright","title":"Graph-Theoretic Approach to Quantum Error Correction","comments":"11 pages","journal-ref":null,"doi":"10.1103/PhysRevA.105.032450","report-no":null,"categories":"quant-ph cs.IT math-ph math.IT math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate a novel class of quantum error correcting codes to correct\nerrors on both qubits and higher-state quantum systems represented as qudits.\nThese codes arise from an original graph-theoretic representation of sets of\nquantum errors. In this new framework, we represent the algebraic conditions\nfor error correction in terms of edge avoidance between graphs providing a\nvisual representation of the interplay between errors and error correcting\ncodes. Most importantly, this framework supports the development of quantum\ncodes that correct against a predetermined set of errors, in contrast to\ncurrent methods. A heuristic algorithm is presented, providing steps to develop\ncodes that correct against an arbitrary noisy channel. We benchmark the\ncorrection capability of reflexive stabilizer codes for the case of single\nqubit errors by comparison to existing stabilizer codes that are widely used.\nIn addition, we present two instances of optimal encodings: an optimal encoding\nfor fully correlated noise which achieves a higher encoding rate than\npreviously known, and a minimal encoding for single qudit errors on a\nfour-state system.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:04:24 GMT"},{"version":"v2","created":"Mon, 14 Mar 2022 23:08:43 GMT"}],"update_date":"2022-04-13"}
{"id":"2110.08415","submitter":"C.M. Downey","authors":"C.M. Downey, Shannon Drizin, Levon Haroutunian, Shivin Thukral","title":"Multilingual unsupervised sequence segmentation transfers to extremely\n  low-resource languages","comments":"ACL 2022 camera-ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that unsupervised sequence-segmentation performance can be\ntransferred to extremely low-resource languages by pre-training a Masked\nSegmental Language Model (Downey et al., 2021) multilingually. Further, we show\nthat this transfer can be achieved by training over a collection of\nlow-resource languages that are typologically similar (but phylogenetically\nunrelated) to the target language. In our experiments, we transfer from a\ncollection of 10 Indigenous American languages (AmericasNLP, Mager et al.,\n2021) to K'iche', a Mayan language. We compare our multilingual model to a\nmonolingual (from-scratch) baseline, as well as a model pre-trained on Quechua\nonly. We show that the multilingual pre-trained approach yields consistent\nsegmentation quality across target dataset sizes, exceeding the monolingual\nbaseline in 6/10 experimental settings. Our model yields especially strong\nresults at small target sizes, including a zero-shot performance of 20.6 F1.\nThese results have promising implications for low-resource NLP pipelines\ninvolving human-like linguistic units, such as the sparse transcription\nframework proposed by Bird (2020).\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:08:28 GMT"},{"version":"v2","created":"Mon, 14 Mar 2022 19:31:39 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08416","submitter":"Michael Booty","authors":"Manman Ma, Michael R. Booty, and Michael Siegel","title":"A model for the electric field-driven deformation of a drop or vesicle\n  in strong electrolyte solutions","comments":"35 pages including 2 figures and references","journal-ref":null,"doi":"10.1017/jfm.2022.469","report-no":null,"categories":"physics.flu-dyn","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  A model is constructed to describe the arbitrary deformation of a drop or\nvesicle that contains and is embedded in an electrolyte solution, where the\ndeformation is caused by an applied electric field. The applied field produces\nan electrokinetic flow or induced charge electro-osmosis. The model is based on\nthe coupled Poisson-Nernst-Planck and Stokes equations. These are reduced or\nsimplified by forming the limit of strong electrolytes, for which ion densities\nare relatively large, together with the limit of thin Debye layers. Debye\nlayers of opposite polarity form on either side of the drop interface or\nvesicle membrane, together forming an electrical double layer.\n  Two formulations of the model are given. One utilizes an integral equation\nfor the velocity field on the interface or membrane surface together with a\npair of integral equations for the electrostatic potential on the outer faces\nof the double layer. The other utilizes a form of the stress-balance boundary\ncondition that incorporates the double layer structure into relations between\nthe dependent variables on the layer's outer faces. This constitutes an\ninterfacial boundary condition that drives an otherwise unforced Stokes flow\noutside the double layer. For both formulations relations derived from the\ntransport of ions in each Debye layer give additional boundary conditions for\nthe potential and ion concentrations outside the double layer.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:10:36 GMT"}],"update_date":"2022-07-13"}
{"id":"2110.08417","submitter":"Hao Cheng","authors":"Kaixin Ma, Hao Cheng, Xiaodong Liu, Eric Nyberg, Jianfeng Gao","title":"Open Domain Question Answering with A Unified Knowledge Interface","comments":"ACL 2022 camera ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The retriever-reader framework is popular for open-domain question answering\n(ODQA) due to its ability to use explicit knowledge. Although prior work has\nsought to increase the knowledge coverage by incorporating structured knowledge\nbeyond text, accessing heterogeneous knowledge sources through a unified\ninterface remains an open question. While data-to-text generation has the\npotential to serve as a universal interface for data and text, its feasibility\nfor downstream tasks remains largely unknown. In this work, we bridge this gap\nand use the data-to-text method as a means for encoding structured knowledge\nfor ODQA. Specifically, we propose a verbalizer-retriever-reader framework for\nODQA over data and text where verbalized tables from Wikipedia and graphs from\nWikidata are used as augmented knowledge sources. We show that our Unified Data\nand Text QA, UDT-QA, can effectively benefit from the expanded knowledge index,\nleading to large gains over text-only baselines. Notably, our approach sets the\nsingle-model state-of-the-art on Natural Questions. Furthermore, our analyses\nindicate that verbalized knowledge is preferred for answer reasoning for both\nadapted and hot-swap settings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:11:21 GMT"},{"version":"v2","created":"Sat, 19 Mar 2022 04:06:37 GMT"}],"update_date":"2022-03-22"}
{"id":"2110.08418","submitter":"Yunfan Zhao","authors":"Samory Kpotufe, Gan Yuan, Yunfan Zhao","title":"Nuances in Margin Conditions Determine Gains in Active Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider nonparametric classification with smooth regression functions,\nwhere it is well known that notions of margin in $E[Y|X]$ determine fast or\nslow rates in both active and passive learning. Here we elucidate a striking\ndistinction between the two settings. Namely, we show that some seemingly\nbenign nuances in notions of margin -- involving the uniqueness of the Bayes\nclassifier, and which have no apparent effect on rates in passive learning --\ndetermine whether or not any active learner can outperform passive learning\nrates. In particular, for Audibert-Tsybakov's margin condition (allowing\ngeneral situations with non-unique Bayes classifiers), no active learner can\ngain over passive learning in commonly studied settings where the marginal on\n$X$ is near uniform. Our results thus negate the usual intuition from past\nliterature that active rates should improve over passive rates in nonparametric\nsettings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:17:39 GMT"},{"version":"v2","created":"Fri, 25 Feb 2022 21:15:37 GMT"}],"update_date":"2022-03-01"}
{"id":"2110.08419","submitter":"Mengnan Du","authors":"Mengnan Du, Subhabrata Mukherjee, Yu Cheng, Milad Shokouhi, Xia Hu,\n  Ahmed Hassan Awadallah","title":"Robustness Challenges in Model Distillation and Pruning for Natural\n  Language Understanding","comments":"Accepted by EACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent work has focused on compressing pre-trained language models (PLMs)\nlike BERT where the major focus has been to improve the in-distribution\nperformance for downstream tasks. However, very few of these studies have\nanalyzed the impact of compression on the generalizability and robustness of\ncompressed models for out-of-distribution (OOD) data. Towards this end, we\nstudy two popular model compression techniques including knowledge distillation\nand pruning and show that the compressed models are significantly less robust\nthan their PLM counterparts on OOD test sets although they obtain similar\nperformance on in-distribution development sets for a task. Further analysis\nindicates that the compressed models overfit on the shortcut samples and\ngeneralize poorly on the hard ones. We further leverage this observation to\ndevelop a regularization strategy for robust model compression based on sample\nuncertainty. Experimental results on several natural language understanding\ntasks demonstrate that our bias mitigation framework improves the OOD\ngeneralization of the compressed models, while not sacrificing the\nin-distribution task performance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:20:04 GMT"},{"version":"v2","created":"Mon, 27 Feb 2023 03:14:07 GMT"}],"update_date":"2023-02-28"}
{"id":"2110.08420","submitter":"Kawin Ethayarajh","authors":"Kawin Ethayarajh, Yejin Choi, Swabha Swayamdipta","title":"Understanding Dataset Difficulty with $\\mathcal{V}$-Usable Information","comments":"ICML 2022 (long talk)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Estimating the difficulty of a dataset typically involves comparing\nstate-of-the-art models to humans; the bigger the performance gap, the harder\nthe dataset is said to be. However, this comparison provides little\nunderstanding of how difficult each instance in a given distribution is, or\nwhat attributes make the dataset difficult for a given model. To address these\nquestions, we frame dataset difficulty -- w.r.t. a model $\\mathcal{V}$ -- as\nthe lack of $\\mathcal{V}$-$\\textit{usable information}$ (Xu et al., 2019),\nwhere a lower value indicates a more difficult dataset for $\\mathcal{V}$. We\nfurther introduce $\\textit{pointwise $\\mathcal{V}$-information}$ (PVI) for\nmeasuring the difficulty of individual instances w.r.t. a given distribution.\nWhile standard evaluation metrics typically only compare different models for\nthe same dataset, $\\mathcal{V}$-$\\textit{usable information}$ and PVI also\npermit the converse: for a given model $\\mathcal{V}$, we can compare different\ndatasets, as well as different instances/slices of the same dataset.\nFurthermore, our framework allows for the interpretability of different input\nattributes via transformations of the input, which we use to discover\nannotation artefacts in widely-used NLP benchmarks.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:21:42 GMT"},{"version":"v2","created":"Wed, 15 Jun 2022 00:47:15 GMT"}],"update_date":"2022-06-16"}
{"id":"2110.08421","submitter":"Habib Slim","authors":"Habib Slim, Eden Belouadah, Adrian Popescu and Darian Onchis","title":"Dataset Knowledge Transfer for Class-Incremental Learning without Memory","comments":"Accepted to WACV 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Incremental learning enables artificial agents to learn from sequential data.\nWhile important progress was made by exploiting deep neural networks,\nincremental learning remains very challenging. This is particularly the case\nwhen no memory of past data is allowed and catastrophic forgetting has a strong\nnegative effect. We tackle class-incremental learning without memory by\nadapting prediction bias correction, a method which makes predictions of past\nand new classes more comparable. It was proposed when a memory is allowed and\ncannot be directly used without memory, since samples of past classes are\nrequired. We introduce a two-step learning process which allows the transfer of\nbias correction parameters between reference and target datasets. Bias\ncorrection is first optimized offline on reference datasets which have an\nassociated validation memory. The obtained correction parameters are then\ntransferred to target datasets, for which no memory is available. The second\ncontribution is to introduce a finer modeling of bias correction by learning\nits parameters per incremental state instead of the usual past vs. new class\nmodeling. The proposed dataset knowledge transfer is applicable to any\nincremental method which works without memory. We test its effectiveness by\napplying it to four existing methods. Evaluation with four target datasets and\ndifferent configurations shows consistent improvement, with practically no\ncomputational and memory overhead.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:33:33 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08422","submitter":"Bogdan Carbunar","authors":"Ruben Recabarren and Bogdan Carbunar","title":"Toward Uncensorable, Anonymous and Private Access Over Satoshi\n  Blockchains","comments":null,"journal-ref":"Proceedings of the Privacy Enhancing Technologies Symposium\n  (PoPETS), volume 2022, issue 1","doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Providing unrestricted access to sensitive content such as news and software\nis difficult in the presence of adaptive and resourceful surveillance and\ncensoring adversaries. In this paper we leverage the distributed and resilient\nnature of commercial Satoshi blockchains to develop the first provably secure,\ncensorship resistant, cost-efficient storage system with anonymous and private\naccess, built on top of commercial cryptocurrency transactions. We introduce\nmax-rate transactions, a practical construct to persist data of arbitrary size\nentirely in a Satoshi blockchain. We leverage max-rate transactions to develop\nUWeb, a blockchain-based storage system that charges publishers to self-sustain\nits decentralized infrastructure. UWeb organizes blockchainstored content for\neasy retrieval, and enables clients to store and access content with provable\nanonymity, privacy and censorship resistance properties.\n  We present results from UWeb experiments with writing 268.21 MB of data into\nthe live Litecoin blockchain, including 4.5 months of live-feed BBC articles,\nand 41 censorship resistant tools. The max-rate writing throughput (183 KB/s)\nand blockchain utilization (88%) exceed those of state-of-the-art solutions by\n2-3 orders of magnitude and broke Litecoin's record of the daily average block\nsize. Our simulations with up to 3,000 concurrent UWeb writers confirm that\nUWeb does not impact the confirmation delays of financial transactions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:36:25 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08423","submitter":"Elias Khalil","authors":"Elias B. Khalil, Pashootan Vaezipoor, Bistra Dilkina","title":"Finding Backdoors to Integer Programs: A Monte Carlo Tree Search\n  Framework","comments":"Published in the Proceedings of AAAI 2022","journal-ref":"Proceedings of the AAAI Conference on Artificial Intelligence.\n  Vol. 36. No. 4. 2022","doi":"10.1609/aaai.v36i4.20293","report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In Mixed Integer Linear Programming (MIP), a (strong) backdoor is a \"small\"\nsubset of an instance's integer variables with the following property: in a\nbranch-and-bound procedure, the instance can be solved to global optimality by\nbranching only on the variables in the backdoor. Constructing datasets of\npre-computed backdoors for widely used MIP benchmark sets or particular problem\nfamilies can enable new questions around novel structural properties of a MIP,\nor explain why a problem that is hard in theory can be solved efficiently in\npractice. Existing algorithms for finding backdoors rely on sampling candidate\nvariable subsets in various ways, an approach which has demonstrated the\nexistence of backdoors for some instances from MIPLIB2003 and MIPLIB2010.\nHowever, these algorithms fall short of consistently succeeding at the task due\nto an imbalance between exploration and exploitation. We propose BaMCTS, a\nMonte Carlo Tree Search framework for finding backdoors to MIPs. Extensive\nalgorithmic engineering, hybridization with traditional MIP concepts, and close\nintegration with the CPLEX solver have enabled our method to outperform\nbaselines on MIPLIB2017 instances, finding backdoors more frequently and more\nefficiently.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:36:53 GMT"},{"version":"v2","created":"Thu, 7 Jul 2022 19:23:40 GMT"}],"update_date":"2022-07-11"}
{"id":"2110.08424","submitter":"Zezhong Ye","authors":"Zezhong Ye, Jack M. Qian, Ahmed Hosny, Roman Zeleznik, Deborah Plana,\n  Jirapat Likitlersuang, Zhongyi Zhang, Raymond H. Mak, Hugo J. W. L. Aerts,\n  Benjamin H. Kann","title":"Deep learning-based detection of intravenous contrast in computed\n  tomography scans","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Purpose: Identifying intravenous (IV) contrast use within CT scans is a key\ncomponent of data curation for model development and testing. Currently, IV\ncontrast is poorly documented in imaging metadata and necessitates manual\ncorrection and annotation by clinician experts, presenting a major barrier to\nimaging analyses and algorithm deployment. We sought to develop and validate a\nconvolutional neural network (CNN)-based deep learning (DL) platform to\nidentify IV contrast within CT scans. Methods: For model development and\nevaluation, we used independent datasets of CT scans of head, neck (HN) and\nlung cancer patients, totaling 133,480 axial 2D scan slices from 1,979 CT scans\nmanually annotated for contrast presence by clinical experts. Five different DL\nmodels were adopted and trained in HN training datasets for slice-level\ncontrast detection. Model performances were evaluated on a hold-out set and on\nan independent validation set from another institution. DL models was then\nfine-tuned on chest CT data and externally validated on a separate chest CT\ndataset. Results: Initial DICOM metadata tags for IV contrast were missing or\nerroneous in 1,496 scans (75.6%). The EfficientNetB4-based model showed the\nbest overall detection performance. For HN scans, AUC was 0.996 in the internal\nvalidation set (n = 216) and 1.0 in the external validation set (n = 595). The\nfine-tuned model on chest CTs yielded an AUC: 1.0 for the internal validation\nset (n = 53), and AUC: 0.980 for the external validation set (n = 402).\nConclusion: The DL model could accurately detect IV contrast in both HN and\nchest CT scans with near-perfect performance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:46:45 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 23:43:41 GMT"}],"update_date":"2021-10-22"}
{"id":"2110.08425","submitter":"Haoge Chang","authors":"Haoge Chang and Joel Middleton and P.M. Aronow","title":"Exact Bias Correction for Linear Adjustment of Randomized Controlled\n  Trials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME econ.EM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In an influential critique of empirical practice, Freedman (2008) showed that\nthe linear regression estimator was biased for the analysis of randomized\ncontrolled trials under the randomization model. Under Freedman's assumptions,\nwe derive exact closed-form bias corrections for the linear regression\nestimator with and without treatment-by-covariate interactions. We show that\nthe limiting distribution of the bias corrected estimator is identical to the\nuncorrected estimator, implying that the asymptotic gains from adjustment can\nbe attained without introducing any risk of bias. Taken together with results\nfrom Lin (2013), our results show that Freedman's theoretical arguments against\nthe use of regression adjustment can be completely resolved with minor\nmodifications to practice.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:48:20 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 04:09:56 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.08426","submitter":"Frederick Liu","authors":"Frederick Liu, Terry Huang, Shihang Lyu, Siamak Shakeri, Hongkun Yu,\n  Jing Li","title":"EncT5: A Framework for Fine-tuning T5 as Non-autoregressive Models","comments":"Update multi-label and structured prediction results","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Pre-trained encoder-decoder transformer architectures have become\nincreasingly popular recently with the advent of T5 models. T5 has also become\nmore favorable over other architectures like BERT due to the amount of data\nthat it is pre-trained on, increased scale of model parameter sizes and easy\napplicability to a diverse set of tasks due to the generative nature of the\nmodel. While being able to generalize to a wide variety of tasks, it is not\nclear that encoder-decoder architectures are the most efficient for fine-tuning\ntasks that don't require auto-regressive decoding. In this work, we study\nfine-tuning pre-trained encoder-decoder models for tasks such as\nclassification, multi-label classification, and structured prediction. We\npropose \\textbf{EncT5}, a framework for these problems, and illustrate\ninstantiations for these tasks. Our experiment results show that EncT5 has\nadvantages over T5 such as efficiency and usability out performs BERT when\nevaluated on publicly available pre-trained checkpoints.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:50:08 GMT"},{"version":"v2","created":"Sun, 23 Oct 2022 04:55:52 GMT"}],"update_date":"2022-10-25"}
{"id":"2110.08427","submitter":"Juntao Jiang","authors":"Juntao Jiang and Shuyi Lin","title":"COVID-19 Detection in Chest X-ray Images Using Swin-Transformer and\n  Transformer in Transformer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The Coronavirus Disease 2019 (COVID-19) has spread globally and caused\nserious damage. Chest X-ray images are widely used for COVID-19 diagnosis and\nthe Artificial Intelligence method can increase efficiency and accuracy. In the\nChallenge of Chest XR COVID-19 detection in Ethics and Explainability for\nResponsible Data Science (EE-RDS) conference 2021, we proposed a method that\ncombined Swin Transformer and Transformer in Transformer to classify chest\nX-ray images as three classes: COVID-19, Pneumonia, and Normal (healthy) and\nachieved 0.9475 accuracies on the test set.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:53:21 GMT"},{"version":"v2","created":"Sat, 31 Dec 2022 18:28:20 GMT"}],"update_date":"2023-01-03"}
{"id":"2110.08428","submitter":"Adela Zhang","authors":"Adela YiYu Zhang","title":"Quillen homology of spectral Lie algebras with application to mod $p$\n  homology of labeled configuration spaces","comments":"Revised following referee reports","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We provide a general method computing the mod $p$ Quillen homology of\nalgebras over a monad that parametrizes the structure of mod $p$ homology of\nspectral Lie algebras. This is the $E^2$-page of the bar spectral sequence\nconverging to the mod $p$ topological Quillen homology of spectral Lie\nalgebras. The computation of the Quillen homology of the trivial algebra allows\nus to deduce that the $\\mathbb F_p$-linear spectral Lie operad is not formal.\nAs an application, we study the mod $p$ homology of the labeled configuration\nspace $B_k(M;X)$ in a manifold $M$ with labels in a spectrum $X$, which is the\nmod $p$ topological Quillen homology of a certain spectral Lie algebra by a\nresult of Knudsen. We obtain general upper bounds for the mod $p$ homology of\n$B_k(M;X)$, as well as explicit computations for small $k$. When $p$ is odd, we\nobserve that the mod $p$ homology of $B_k(M^n;S^r)$ for small $k$ depends on\nand only on the cohomology ring of the one-point compactification of $M$ when\n$n+r$ is even. This supplements and contrasts with the result of\nB\\\"{o}digheimer-Cohen-Taylor when $n+r$ is odd.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:56:43 GMT"},{"version":"v2","created":"Thu, 18 Aug 2022 16:44:12 GMT"}],"update_date":"2022-08-19"}
{"id":"2110.08429","submitter":"Soumick Chatterjee","authors":"Soumick Chatterjee, Arnab Das, Chirag Mandal, Budhaditya Mukhopadhyay,\n  Manish Vipinraj, Aniruddh Shukla, Rajatha Nagaraja Rao, Chompunuch Sarasaen,\n  Oliver Speck and Andreas N\\\"urnberger","title":"TorchEsegeta: Framework for Interpretability and Explainability of\n  Image-based Deep Learning Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Clinicians are often very sceptical about applying automatic image processing\napproaches, especially deep learning based methods, in practice. One main\nreason for this is the black-box nature of these approaches and the inherent\nproblem of missing insights of the automatically derived decisions. In order to\nincrease trust in these methods, this paper presents approaches that help to\ninterpret and explain the results of deep learning algorithms by depicting the\nanatomical areas which influence the decision of the algorithm most. Moreover,\nthis research presents a unified framework, TorchEsegeta, for applying various\ninterpretability and explainability techniques for deep learning models and\ngenerate visual interpretations and explanations for clinicians to corroborate\ntheir clinical findings. In addition, this will aid in gaining confidence in\nsuch methods. The framework builds on existing interpretability and\nexplainability techniques that are currently focusing on classification models,\nextending them to segmentation tasks. In addition, these methods have been\nadapted to 3D models for volumetric analysis. The proposed framework provides\nmethods to quantitatively compare visual explanations using infidelity and\nsensitivity metrics. This framework can be used by data scientists to perform\npost-hoc interpretations and explanations of their models, develop more\nexplainable tools and present the findings to clinicians to increase their\nfaith in such models. The proposed framework was evaluated based on a use case\nscenario of vessel segmentation models trained on Time-of-fight (TOF) Magnetic\nResonance Angiogram (MRA) images of the human brain. Quantitative and\nqualitative results of a comparative study of different models and\ninterpretability methods are presented. Furthermore, this paper provides an\nextensive overview of several existing interpretability and explainability\nmethods.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:00:15 GMT"},{"version":"v2","created":"Mon, 7 Feb 2022 10:22:32 GMT"}],"update_date":"2022-02-08"}
{"id":"2110.08430","submitter":"Simran Arora","authors":"Simran Arora, Sen Wu, Enci Liu, Christopher Re","title":"Metadata Shaping: Natural Language Annotations for the Tail","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language models (LMs) have made remarkable progress, but still struggle to\ngeneralize beyond the training data to rare linguistic patterns. Since rare\nentities and facts are prevalent in the queries users submit to popular\napplications such as search and personal assistant systems, improving the\nability of LMs to reliably capture knowledge over rare entities is a pressing\nchallenge studied in significant prior work. Noticing that existing approaches\nprimarily modify the LM architecture or introduce auxiliary objectives to\ninject useful entity knowledge, we ask to what extent we could match the\nquality of these architectures using a base LM architecture, and only changing\nthe data? We propose metadata shaping, a method in which readily available\nmetadata, such as entity descriptions and categorical tags, are appended to\nexamples based on information theoretic metrics. Intuitively, if metadata\ncorresponding to popular entities overlap with metadata for rare entities, the\nLM may be able to better reason about the rare entities using patterns learned\nfrom similar popular entities. On standard entity-rich tasks (TACRED, FewRel,\nOpenEntity), with no changes to the LM whatsoever, metadata shaping exceeds the\nBERT-baseline by up to 5.3 F1 points, and achieves or competes with\nstate-of-the-art results. We further show the improvements are up to 10x larger\non examples containing tail versus popular entities.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:00:47 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08431","submitter":"Sandeep Kumar","authors":"Anand Katailiha, Paul C. Lou, Ravindra G. Bhardwaj, Ward Beyermann,\n  and Sandeep Kumar","title":"Topological phonons in an inhomogeneously strained silicon-6: Possible\n  evidence of the high temperature spin superfluidity and the second sound of\n  topological phonons","comments":"Draft. Theoretical/modeling help welcome. Basic Si devices can be\n  shared for replication/spectroscopic/ or any other complimentary experimental\n  work","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The superposition of topological phonons and flexoelectronic charge\nseparation in an inhomogeneously strain Si give rise to topological electronic\nmagnetism of phonons. The topological electronic magnetism of phonons is also\nexpected to give rise to stationary spin current or spin superfluidity. In this\nexperimental study, we present possible evidence of spin superfluidity in an\ninhomogeneously strained p-Si thin films samples. The spin superfluidity is\nuncovered using non-local resistance measurement. A resonance behavior is\nobserved in a non-local resistance measurement at 10 kHz and between 270 K and\n281.55 K, which is attributed to the second sound. The observation of second\nsound and spatially varying non-local resistance phase are the evidences for\nspin superfluidity. The spatially varying non-local resistance with opposite\nphase are also observed in Pt/MgO/p-Si sample. The overall non-local responses\ncan be treated as a standing waveform from temporal magnetic moments of the\ntopological phonons.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:12:02 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08432","submitter":"Shibo Li","authors":"Shibo Li, Zheng Wang, Akil Narayan, Robert Kirby, Shandian Zhe","title":"Meta-Learning with Adjoint Methods","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Model Agnostic Meta Learning (MAML) is widely used to find a good\ninitialization for a family of tasks. Despite its success, a critical challenge\nin MAML is to calculate the gradient w.r.t. the initialization of a long\ntraining trajectory for the sampled tasks, because the computation graph can\nrapidly explode and the computational cost is very expensive. To address this\nproblem, we propose Adjoint MAML (A-MAML). We view gradient descent in the\ninner optimization as the evolution of an Ordinary Differential Equation (ODE).\nTo efficiently compute the gradient of the validation loss w.r.t. the\ninitialization, we use the adjoint method to construct a companion, backward\nODE. To obtain the gradient w.r.t. the initialization, we only need to run the\nstandard ODE solver twice -- one is forward in time that evolves a long\ntrajectory of gradient flow for the sampled task; the other is backward and\nsolves the adjoint ODE. We need not create or expand any intermediate\ncomputational graphs, adopt aggressive approximations, or impose proximal\nregularizers in the training loss. Our approach is cheap, accurate, and\nadaptable to different trajectory lengths. We demonstrate the advantage of our\napproach in both synthetic and real-world meta-learning tasks.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:18:50 GMT"},{"version":"v2","created":"Sun, 23 Oct 2022 12:28:14 GMT"},{"version":"v3","created":"Fri, 24 Feb 2023 05:11:24 GMT"}],"update_date":"2023-02-27"}
{"id":"2110.08433","submitter":"Hidetoshi Tahara","authors":"Hidetoshi Tahara","title":"Uniqueness of the solution of some nonlinear singular partial\n  differential equations of the second order","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider a nonlinear Fuchsian type partial differential\nequation of the second order in the complex domain. Under a very weak\nassumption, we show the uniqueness of the solution. The result is applied to\nthe problem of analytic continuation of local holomorphic solutions of this\nequation.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:21:51 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08434","submitter":"Carolyn Chun","authors":"Joseph Bonin, Carolyn Chun, and Tara Fife","title":"The excluded minors for lattice path polymatroids","comments":"16 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We find the excluded minors for the minor-closed class of lattice path\npolymatroids as a subclass of the minor-closed class of Boolean polymatroids.\nLike lattice path matroids and Boolean polymatroids, there are infinitely many\nexcluded minors, but they fall into a small number of easily-described types.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:25:58 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08435","submitter":"Maxim Lyutikov","authors":"Maxim Lyutikov (Purdue University)","title":"Escape of Fast Radio Bursts from magnetars' magnetospheres","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss dissipative processes occurring during production and escape of\nFast Radio Bursts (FRBs) from magnetars' magnetospheres, the presumed loci of\nFRBs. High magnetic fields are required in the emission region, both to account\nfor the overall energetics of FRBs, and in order to suppress ``normal''\n(non-coherent) radiative losses of radio emitting particles; this limits the\nemission radii to $\\leq {\\rm few} \\times 10 R_{NS}$. Radiative losses by\nparticles in the strong FRB pulse may occur in the outer regions of the\nmagnetosphere for longer rotation periods, $P\\geq 1$ second. These losses are\nsuppressed by several effects: (i) the ponderomotive pre-acceleration of\nbackground plasma along the direction of wave propagation (losses reduced\napproximately as $\\gamma_\\parallel^{3}$: smaller frequency, $ \\propto\n\\gamma_\\parallel^2$ in power, and times scales stretched, $ \\propto\n\\gamma_\\parallel$); this acceleration is non-dissipative and is reversed on the\ndeclining part of the pulse; (ii) Landau-Pomeranchuk-Migdal effects (long\nradiation formation length and ensuing destructive interference of scattered\nwaves). In some cases an FRB pulse may be dissipated on external perturbations\n(e.g., an incoming pulse of Alfven waves): this may produce a pulse of UV/soft\nX-rays, a swan song of an FRB, possibly detectable by Chandra.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:27:52 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08436","submitter":"Ziyi Zhou","authors":"Ziyi Zhou, Dong Jae Lee, Yuki Yoshinaga, Stephen Balakirsky, Dejun\n  Guo, and Ye Zhao","title":"Reactive Task Allocation and Planning for Quadrupedal and Wheeled Robot\n  Teaming","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper takes the first step towards a reactive, hierarchical multi-robot\ntask allocation and planning framework given a global Linear Temporal Logic\nspecification. The capabilities of both quadrupedal and wheeled robots are\nleveraged via a heterogeneous team to accomplish a variety of navigation and\ndelivery tasks. However, when deployed in the real world, all robots can be\nsusceptible to different types of disturbances, including but not limited to\nlocomotion failures, human interventions, and obstructions from the\nenvironment. To address these disturbances, we propose task-level local and\nglobal reallocation strategies to efficiently generate updated action-state\nsequences online while guaranteeing the completion of the original task. These\ntask reallocation approaches eliminate reconstructing the entire plan or\nresynthesizing a new task. To integrate the task planner with low-level inputs,\na Behavior Tree execution layer monitors different types of disturbances and\nemploys the reallocation methods to make corresponding recovery strategies. To\nevaluate this planning framework, dynamic simulations are conducted in a\nrealistic hospital environment with a heterogeneous robot team consisting of\nquadrupeds and wheeled robots for delivery tasks.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:28:52 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 00:53:15 GMT"},{"version":"v3","created":"Mon, 21 Mar 2022 11:36:09 GMT"},{"version":"v4","created":"Tue, 21 Jun 2022 02:16:13 GMT"}],"update_date":"2022-06-22"}
{"id":"2110.08437","submitter":"Ziteng Wang","authors":"Ziteng Wang, Yueyue Na, Biao Tian, Qiang Fu","title":"NN3A: Neural Network supported Acoustic Echo Cancellation, Noise\n  Suppression and Automatic Gain Control for Real-Time Communications","comments":"submitted to ICASSP2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Acoustic echo cancellation (AEC), noise suppression (NS) and automatic gain\ncontrol (AGC) are three often required modules for real-time communications\n(RTC). This paper proposes a neural network supported algorithm for RTC, namely\nNN3A, which incorporates an adaptive filter and a multi-task model for residual\necho suppression, noise reduction and near-end speech activity detection. The\nproposed algorithm is shown to outperform both a method using separate models\nand an end-to-end alternative. It is further shown that there exists a\ntrade-off in the model between residual suppression and near-end speech\ndistortion, which could be balanced by a novel loss weighting function. Several\npractical aspects of training the joint model are also investigated to push its\nperformance to limit.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:38:33 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08438","submitter":"Neeraj Varshney","authors":"Neeraj Varshney, Pratyay Banerjee, Tejas Gokhale, Chitta Baral","title":"Unsupervised Natural Language Inference Using PHL Triplet Generation","comments":"ACL 2022 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Transformer-based models achieve impressive performance on numerous Natural\nLanguage Inference (NLI) benchmarks when trained on respective training\ndatasets. However, in certain cases, training samples may not be available or\ncollecting them could be time-consuming and resource-intensive. In this work,\nwe address the above challenge and present an explorative study on unsupervised\nNLI, a paradigm in which no human-annotated training samples are available. We\ninvestigate it under three settings: PH, P, and NPH that differ in the extent\nof unlabeled data available for learning. As a solution, we propose a\nprocedural data generation approach that leverages a set of sentence\ntransformations to collect PHL (Premise, Hypothesis, Label) triplets for\ntraining NLI models, bypassing the need for human-annotated training data.\nComprehensive experiments with several NLI datasets show that the proposed\napproach results in accuracies of up to 66.75%, 65.9%, 65.39% in PH, P, and NPH\nsettings respectively, outperforming all existing unsupervised baselines.\nFurthermore, fine-tuning our model with as little as ~0.1% of the\nhuman-annotated training dataset (500 instances) leads to 12.2% higher accuracy\nthan the model trained from scratch on the same 500 instances. Supported by\nthis superior performance, we conclude with a recommendation for collecting\nhigh-quality task-specific data.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:40:34 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 15:58:38 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08439","submitter":"Ziteng Wang","authors":"Ziteng Wang, Yueyue Na, Biao Tian, Qiang Fu","title":"Controllable Multichannel Speech Dereverberation based on Deep Neural\n  Networks","comments":"submitted to ICASSP2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Neural network based speech dereverberation has achieved promising results in\nrecent studies. Nevertheless, many are focused on recovery of only the direct\npath sound and early reflections, which could be beneficial to speech\nperception, are discarded. The performance of a model trained to recover clean\nspeech degrades when evaluated on early reverberation targets, and vice versa.\nThis paper proposes a novel deep neural network based multichannel speech\ndereverberation algorithm, in which the dereverberation level is controllable.\nThis is realized by adding a simple floating-point number as target controller\nof the model. Experiments are conducted using spatially distributed\nmicrophones, and the efficacy of the proposed algorithm is confirmed in various\nsimulated conditions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:41:25 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08440","submitter":"Dheeraj Nagaraj","authors":"Naman Agarwal, Syomantak Chaudhuri, Prateek Jain, Dheeraj Nagaraj,\n  Praneeth Netrapalli","title":"Online Target Q-learning with Reverse Experience Replay: Efficiently\n  finding the Optimal Policy for Linear MDPs","comments":"Under Review, V2 has updated acknowledgements","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Q-learning is a popular Reinforcement Learning (RL) algorithm which is widely\nused in practice with function approximation (Mnih et al., 2015). In contrast,\nexisting theoretical results are pessimistic about Q-learning. For example,\n(Baird, 1995) shows that Q-learning does not converge even with linear function\napproximation for linear MDPs. Furthermore, even for tabular MDPs with\nsynchronous updates, Q-learning was shown to have sub-optimal sample complexity\n(Li et al., 2021;Azar et al., 2013). The goal of this work is to bridge the gap\nbetween practical success of Q-learning and the relatively pessimistic\ntheoretical results. The starting point of our work is the observation that in\npractice, Q-learning is used with two important modifications: (i) training\nwith two networks, called online network and target network simultaneously\n(online target learning, or OTL) , and (ii) experience replay (ER) (Mnih et\nal., 2015). While they have been observed to play a significant role in the\npractical success of Q-learning, a thorough theoretical understanding of how\nthese two modifications improve the convergence behavior of Q-learning has been\nmissing in literature. By carefully combining Q-learning with OTL and reverse\nexperience replay (RER) (a form of experience replay), we present novel methods\nQ-Rex and Q-RexDaRe (Q-Rex + data reuse). We show that Q-Rex efficiently finds\nthe optimal policy for linear MDPs (or more generally for MDPs with zero\ninherent Bellman error with linear approximation (ZIBEL)) and provide\nnon-asymptotic bounds on sample complexity -- the first such result for a\nQ-learning method for this class of MDPs under standard assumptions.\nFurthermore, we demonstrate that Q-RexDaRe in fact achieves near optimal sample\ncomplexity in the tabular setting, improving upon the existing results for\nvanilla Q-learning.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:47:41 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 17:35:59 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.08441","submitter":"Jianhui Li","authors":"Jianhui Li and Tongou Yang","title":"Decoupling for smooth surfaces in $\\mathbb{R}^3$","comments":"30 pages and 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For each $d\\geq 0$, we prove decoupling inequalities in $\\mathbb R^3$ for the\ngraphs of all bivariate polynomials of degree at most $d$ with bounded\ncoefficients, with the decoupling constant depending uniformly in $d$ but not\nthe coefficients of each individual polynomial. As a consequence, we prove a\ndecoupling inequality for (a compact piece of) every smooth surface in\n$\\mathbb{R}^3$, which in particular solves a conjecture of Bourgain, Demeter\nand Kemp.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 01:51:10 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08442","submitter":"Zhuoyuan Song","authors":"Gregory Snyder and Zhuoyuan Song","title":"Koopman Operator Theory for Nonlinear Dynamic Modeling using Dynamic\n  Mode Decomposition","comments":"8 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.RO math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Koopman operator is a linear operator that describes the evolution of\nscalar observables (i.e., measurement functions of the states) in an\ninfinitedimensional Hilbert space. This operator theoretic point of view lifts\nthe dynamics of a finite-dimensional nonlinear system to an\ninfinite-dimensional function space where the evolution of the original system\nbecomes linear. In this paper, we provide a brief summary of the Koopman\noperator theorem for nonlinear dynamics modeling and focus on analyzing several\ndata-driven implementations using dynamical mode decomposition (DMD) for\nautonomous and controlled canonical problems. We apply the extended dynamic\nmode decomposition (EDMD) to identify the leading Koopman eigenfunctions and\napproximate a finite-dimensional representation of the discovered linear\ndynamics. This allows us to apply linear control approaches towards nonlinear\nsystems without linearization approximations around fixed points. We can then\nexamine the fidelity of using a linear controller based on a Koopman operator\napproximated system on under-actuated systems with basic maneuvers. We\ndemonstrate the effectiveness of this theory through numerical simulation on\ntwo classic dynamical systems are used to show DMD methods of evaluating and\napproximating the Koopman operator and its effectiveness at linearizing these\nsystems.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:08:42 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08443","submitter":"Wenxuan Zhou","authors":"Wenxuan Zhou, Fangyu Liu, Ivan Vuli\\'c, Nigel Collier, Muhao Chen","title":"Prix-LM: Pretraining for Multilingual Knowledge Base Construction","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge bases (KBs) contain plenty of structured world and commonsense\nknowledge. As such, they often complement distributional text-based information\nand facilitate various downstream tasks. Since their manual construction is\nresource- and time-intensive, recent efforts have tried leveraging large\npretrained language models (PLMs) to generate additional monolingual knowledge\nfacts for KBs. However, such methods have not been attempted for building and\nenriching multilingual KBs. Besides wider application, such multilingual KBs\ncan provide richer combined knowledge than monolingual (e.g., English) KBs.\nKnowledge expressed in different languages may be complementary and unequally\ndistributed: this implies that the knowledge available in high-resource\nlanguages can be transferred to low-resource ones. To achieve this, it is\ncrucial to represent multilingual knowledge in a shared/unified space. To this\nend, we propose a unified representation model, Prix-LM, for multilingual KB\nconstruction and completion. We leverage two types of knowledge, monolingual\ntriples and cross-lingual links, extracted from existing multilingual KBs, and\ntune a multilingual language encoder XLM-R via a causal language modeling\nobjective. Prix-LM integrates useful multilingual and KB-based factual\nknowledge into a single model. Experiments on standard entity-related tasks,\nsuch as link prediction in multiple languages, cross-lingual entity linking and\nbilingual lexicon induction, demonstrate its effectiveness, with gains reported\nover strong task-specialised baselines.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:08:46 GMT"},{"version":"v2","created":"Wed, 9 Mar 2022 18:35:37 GMT"}],"update_date":"2022-03-10"}
{"id":"2110.08444","submitter":"Yongwei Huang","authors":"Yongwei Huang, Wenzheng Yang, Sergiy A. Vorobyov","title":"Robust Adaptive Beamforming Maximizing the Worst-Case SINR over\n  Distributional Uncertainty Sets for Random INC Matrix and Signal Steering\n  Vector","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The robust adaptive beamforming (RAB) problem is considered via the\nworst-case signal-to-interference-plus-noise ratio (SINR) maximization over\ndistributional uncertainty sets for the random interference-plus-noise\ncovariance (INC) matrix and desired signal steering vector. The distributional\nuncertainty set of the INC matrix accounts for the support and the positive\nsemidefinite (PSD) mean of the distribution, and a similarity constraint on the\nmean. The distributional uncertainty set for the steering vector consists of\nthe constraints on the known first- and second-order moments. The RAB problem\nis formulated as a minimization of the worst-case expected value of the SINR\ndenominator achieved by any distribution, subject to the expected value of the\nnumerator being greater than or equal to one for each distribution. Resorting\nto the strong duality of linear conic programming, such a RAB problem is\nrewritten as a quadratic matrix inequality problem. It is then tackled by\niteratively solving a sequence of linear matrix inequality relaxation problems\nwith the penalty term on the rank-one PSD matrix constraint. To validate the\nresults, simulation examples are presented, and they demonstrate the improved\nperformance of the proposed robust beamformer in terms of the array output\nSINR.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:10:06 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08445","submitter":"Ian Stewart","authors":"Ian Stewart, Rada Mihalcea","title":"How Well Do You Know Your Audience? Toward Socially-aware Question\n  Generation","comments":"SIGDIAL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  When writing, a person may need to anticipate questions from their audience,\nbut different social groups may ask very different types of questions. If\nsomeone is writing about a problem they want to resolve, what kind of follow-up\nquestion will a domain expert ask, and could the writer better address the\nexpert's information needs by rewriting their original post? In this paper, we\nexplore the task of socially-aware question generation. We collect a data set\nof questions and posts from social media, including background information\nabout the question-askers' social groups. We find that different social groups,\nsuch as experts and novices, consistently ask different types of questions. We\ntrain several text-generation models that incorporate social information, and\nwe find that a discrete social-representation model outperforms the text-only\nmodel when different social groups ask highly different questions from one\nanother. Our work provides a framework for developing text generation models\nthat can help writers anticipate the information expectations of highly\ndifferent social groups.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:10:16 GMT"},{"version":"v2","created":"Sun, 24 Jul 2022 21:58:35 GMT"}],"update_date":"2022-07-26"}
{"id":"2110.08446","submitter":"Zhangzi Zhu","authors":"Zhangzi Zhu, Tianlei Wang, and Hong Qu","title":"Self-Annotated Training for Controllable Image Captioning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Controllable Image Captioning (CIC) task aims to generate captions\nconditioned on designated control signals. Several structure-related control\nsignals are proposed to control the semantic structure of sentences, such as\nsentence length and Part-of-Speech tag sequences. However, due to the fact that\nthe accuracy-based reward focuses mainly on contents rather than semantic\nstructures, existing reinforcement training methods are not applicable to\nstructure-related CIC models. The lack of reinforcement training leads to\nexposure bias and the inconsistency between the optimizing function and\nevaluation metrics. In this paper, we propose a novel reinforcement training\nmethod for structure-related control signals: Self-Annotated Training (SAT), to\nimprove both the accuracy and controllability of CIC models. In SAT, a\nrecursive annotation mechanism (RAM) is designed to force the input control\nsignal to match the actual output sentence. Moreover, we propose an extra\nalignment reward to finetune the CIC model trained after SAT method, which\nfurther enhances the controllability of models. On the MSCOCO benchmark, we\nconduct extensive experiments on different structure-related control signals\nand on different baseline models, the results of which demonstrate the\neffectiveness and generalizability of our methods.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:10:23 GMT"},{"version":"v2","created":"Sat, 20 Nov 2021 02:54:03 GMT"}],"update_date":"2021-11-23"}
{"id":"2110.08447","submitter":"Chandramouli Amarnath","authors":"Chandramouli Amarnath (Georgia Tech), Aishwarya H. Balwani (Georgia\n  Tech), Kwondo Ma (Georgia Tech), Abhijit Chatterjee (Georgia Tech)","title":"TESDA: Transform Enabled Statistical Detection of Attacks in Deep Neural\n  Networks","comments":"10 pages, 2 reference pages, 2 appendix pages, 14 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Deep neural networks (DNNs) are now the de facto choice for computer vision\ntasks such as image classification. However, their complexity and \"black box\"\nnature often renders the systems they're deployed in vulnerable to a range of\nsecurity threats. Successfully identifying such threats, especially in\nsafety-critical real-world applications is thus of utmost importance, but still\nvery much an open problem. We present TESDA, a low-overhead, flexible, and\nstatistically grounded method for {online detection} of attacks by exploiting\nthe discrepancies they cause in the distributions of intermediate layer\nfeatures of DNNs. Unlike most prior work, we require neither dedicated hardware\nto run in real-time, nor the presence of a Trojan trigger to detect\ndiscrepancies in behavior. We empirically establish our method's usefulness and\npracticality across multiple architectures, datasets and diverse attacks,\nconsistently achieving detection coverages of above 95% with operation count\noverheads as low as 1-2%.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:10:36 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08448","submitter":"Mojtaba Hosseini","authors":"Mojtaba Hosseini, John Turner","title":"Deepest Cuts for Benders Decomposition","comments":"35 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Since its inception, Benders Decomposition (BD) has been successfully applied\nto a wide range of large-scale mixed-integer (linear) problems. The key element\nof BD is the derivation of Benders cuts, which are often not unique. In this\npaper, we introduce a novel unifying Benders cut selection technique based on a\ngeometric interpretation of cut ``depth'', produce deepest Benders cuts based\non $\\ell_p$-norms, and study their properties. Specifically, we show that\ndeepest cuts resolve infeasibility through minimal deviation from the incumbent\npoint, are relatively sparse, and may produce optimality cuts even when\nclassical Benders would require a feasibility cut. Leveraging the duality\nbetween separation and projection, we develop a Guided Projections Algorithm\nfor producing deepest cuts while exploiting the combinatorial structure or\ndecomposablity of problem instances. We then propose a generalization of our\nBenders separation problem that brings several well-known cut selection\nstrategies under one umbrella. In particular, we provide systematic ways of\nselecting the normalization coefficients in the Minimal Infeasible Subsystems\nmethod by establishing its connection to our method. Finally, in our tests on\nfacility location problems, we show deepest cuts often reduce both runtime and\nnumber of Benders iterations, as compared to other cut selection strategies;\nand relative to classical Benders, use $1/3$ the number of cuts and $1/2$ the\nruntime.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:27:09 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08449","submitter":"Eric Han","authors":"Eric Han and Jonathan Scarlett","title":"Adversarial Attacks on Gaussian Process Bandits","comments":"Accepted to ICML 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Gaussian processes (GP) are a widely-adopted tool used to sequentially\noptimize black-box functions, where evaluations are costly and potentially\nnoisy. Recent works on GP bandits have proposed to move beyond random noise and\ndevise algorithms robust to adversarial attacks. This paper studies this\nproblem from the attacker's perspective, proposing various adversarial attack\nmethods with differing assumptions on the attacker's strength and prior\ninformation. Our goal is to understand adversarial attacks on GP bandits from\ntheoretical and practical perspectives. We focus primarily on targeted attacks\non the popular GP-UCB algorithm and a related elimination-based algorithm,\nbased on adversarially perturbing the function $f$ to produce another function\n$\\tilde{f}$ whose optima are in some target region $\\mathcal{R}_{\\rm target}$.\nBased on our theoretical analysis, we devise both white-box attacks (known $f$)\nand black-box attacks (unknown $f$), with the former including a Subtraction\nattack and Clipping attack, and the latter including an Aggressive subtraction\nattack. We demonstrate that adversarial attacks on GP bandits can succeed in\nforcing the algorithm towards $\\mathcal{R}_{\\rm target}$ even with a low attack\nbudget, and we test our attacks' effectiveness on a diverse range of objective\nfunctions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:39:10 GMT"},{"version":"v2","created":"Wed, 1 Jun 2022 17:16:31 GMT"},{"version":"v3","created":"Thu, 16 Jun 2022 11:11:23 GMT"}],"update_date":"2022-06-17"}
{"id":"2110.08450","submitter":"Jie Chen","authors":"Tim Kaler, Nickolas Stathas, Anne Ouyang, Alexandros-Stavros\n  Iliopoulos, Tao B. Schardl, Charles E. Leiserson, Jie Chen","title":"Accelerating Training and Inference of Graph Neural Networks with Fast\n  Sampling and Pipelining","comments":"MLSys 2022. Code is available at\n  https://github.com/MITIBMxGraph/SALIENT","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Improving the training and inference performance of graph neural networks\n(GNNs) is faced with a challenge uncommon in general neural networks: creating\nmini-batches requires a lot of computation and data movement due to the\nexponential growth of multi-hop graph neighborhoods along network layers. Such\na unique challenge gives rise to a diverse set of system design choices. We\nargue in favor of performing mini-batch training with neighborhood sampling in\na distributed multi-GPU environment, under which we identify major performance\nbottlenecks hitherto under-explored by developers: mini-batch preparation and\ntransfer. We present a sequence of improvements to mitigate these bottlenecks,\nincluding a performance-engineered neighborhood sampler, a shared-memory\nparallelization strategy, and the pipelining of batch transfer with GPU\ncomputation. We also conduct an empirical analysis that supports the use of\nsampling for inference, showing that test accuracies are not materially\ncompromised. Such an observation unifies training and inference, simplifying\nmodel implementation. We report comprehensive experimental results with several\nbenchmark data sets and GNN architectures, including a demonstration that, for\nthe ogbn-papers100M data set, our system SALIENT achieves a speedup of 3x over\na standard PyTorch-Geometric implementation with a single GPU and a further 8x\nparallel speedup with 16 GPUs. Therein, training a 3-layer GraphSAGE model with\nsampling fanout (15, 10, 5) takes 2.0 seconds per epoch and inference with\nfanout (20, 20, 20) takes 2.4 seconds, attaining test accuracy 64.58%.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:41:35 GMT"},{"version":"v2","created":"Wed, 16 Mar 2022 21:09:27 GMT"}],"update_date":"2022-03-18"}
{"id":"2110.08451","submitter":"Zo\\\"e Marschner","authors":"Zo\\\"e Marschner, Paul Zhang, David Palmer, Justin Solomon","title":"Sum-of-Squares Geometry Processing","comments":null,"journal-ref":null,"doi":"10.1145/3478513.3480551","report-no":null,"categories":"cs.CG cs.GR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Geometry processing presents a variety of difficult numerical problems, each\nseeming to require its own tailored solution. This breadth is largely due to\nthe expansive list of geometric primitives, e.g., splines, triangles, and\nhexahedra, joined with an ever-expanding variety of objectives one might want\nto achieve with them. With the recent increase in attention toward higher-order\nsurfaces, we can expect a variety of challenges porting existing solutions that\nwork on triangle meshes to work on these more complex geometry types. In this\npaper, we present a framework for solving many core geometry processing\nproblems on higher-order surfaces. We achieve this goal through sum-of-squares\noptimization, which transforms nonlinear polynomial optimization problems into\nsequences of convex problems whose complexity is captured by a single degree\nparameter. This allows us to solve a suite of problems on higher-order\nsurfaces, such as continuous collision detection and closest point queries on\ncurved patches, with only minor changes between formulations and geometries.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 02:52:03 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08452","submitter":"Yuya Murakami","authors":"Yuya Murakami","title":"Extended-cycle integrals of modular functions for badly approximable\n  numbers","comments":"19 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Cycle integrals of modular functions are expected to play a role in real\nquadratic analogue of singular moduli. In this paper, we extend the definition\nof cycle integrals of modular functions from real quadratic numbers to badly\napproximable numbers. We also give explicit representations of values of\nextended-cycle integrals for some cases.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:05:37 GMT"},{"version":"v2","created":"Wed, 2 Nov 2022 05:19:08 GMT"}],"update_date":"2022-11-03"}
{"id":"2110.08453","submitter":"Wesley Holliday","authors":"Wesley H. Holliday, Chase Norman, and Eric Pacuit","title":"Voting Theory in the Lean Theorem Prover","comments":"Postprint of the paper in Proceedings of the Eighth International\n  Conference on Logic, Rationality and Interaction (Springer) with two typos\n  fixed","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is a long tradition of fruitful interaction between logic and social\nchoice theory. In recent years, much of this interaction has focused on\ncomputer-aided methods such as SAT solving and interactive theorem proving. In\nthis paper, we report on the development of a framework for formalizing voting\ntheory in the Lean theorem prover, which we have applied to verify properties\nof a recently studied voting method. While previous applications of interactive\ntheorem proving to social choice (using Isabelle/HOL and Mizar) have focused on\nthe verification of impossibility theorems, we aim to cover a variety of\nresults ranging from impossibility theorems to the verification of properties\nof specific voting methods (e.g., Condorcet consistency, independence of\nclones, etc.). In order to formalize voting theoretic axioms concerning adding\nor removing candidates and voters, we work in a variable-election setting whose\nformalization makes use of dependent types in Lean.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:10:22 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08454","submitter":"Dong-Ho Lee","authors":"Dong-Ho Lee, Akshen Kadakia, Kangmin Tan, Mahak Agarwal, Xinyu Feng,\n  Takashi Shibuya, Ryosuke Mitani, Toshiyuki Sekiya, Jay Pujara and Xiang Ren","title":"Good Examples Make A Faster Learner: Simple Demonstration-based Learning\n  for Low-resource NER","comments":"Accepted to ACL 2022 main conference. 14 pages, 8 figures, 9 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advances in prompt-based learning have shown strong results on\nfew-shot text classification by using cloze-style templates. Similar attempts\nhave been made on named entity recognition (NER) which manually design\ntemplates to predict entity types for every text span in a sentence. However,\nsuch methods may suffer from error propagation induced by entity span\ndetection, high cost due to enumeration of all possible text spans, and\nomission of inter-dependencies among token labels in a sentence. Here we\npresent a simple demonstration-based learning method for NER, which lets the\ninput be prefaced by task demonstrations for in-context learning. We perform a\nsystematic study on demonstration strategy regarding what to include (entity\nexamples, with or without surrounding context), how to select the examples, and\nwhat templates to use. Results on in-domain learning and domain adaptation show\nthat the model's performance in low-resource settings can be largely improved\nwith a suitable demonstration strategy (e.g., a 4-17% improvement on 25 train\ninstances). We also find that good demonstration can save many labeled examples\nand consistency in demonstration contributes to better performance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:24:44 GMT"},{"version":"v2","created":"Mon, 14 Mar 2022 08:06:41 GMT"},{"version":"v3","created":"Thu, 31 Mar 2022 03:22:59 GMT"}],"update_date":"2022-04-01"}
{"id":"2110.08455","submitter":"Xiaokai Wei","authors":"Xiaokai Wei, Shen Wang, Dejiao Zhang, Parminder Bhatia, Andrew Arnold","title":"Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Pretrained Language Models (PLM) have established a new paradigm through\nlearning informative contextualized representations on large-scale text corpus.\nThis new paradigm has revolutionized the entire field of natural language\nprocessing, and set the new state-of-the-art performance for a wide variety of\nNLP tasks. However, though PLMs could store certain knowledge/facts from\ntraining corpus, their knowledge awareness is still far from satisfactory. To\naddress this issue, integrating knowledge into PLMs have recently become a very\nactive research area and a variety of approaches have been developed. In this\npaper, we provide a comprehensive survey of the literature on this emerging and\nfast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs).\nWe introduce three taxonomies to categorize existing work. Besides, we also\nsurvey the various NLU and NLG applications on which KE-PLM has demonstrated\nsuperior performance over vanilla PLMs. Finally, we discuss challenges that\nface KE-PLMs and also promising directions for future research.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:27:56 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08456","submitter":"Brendan White M","authors":"Brendan M. White, Pei Jiang Low, Yvette de Sereville, Matthew L.Day,\n  Noah Greenberg, Richard Rademacher, Crystal Senko","title":"Isotope-Selective Laser Ablation Ion-Trap Loading of\n  $\\mathbf{^{137}\\mathrm{Ba}^+}$ using a $\\mathbf{\\mathrm{BaCl}_2}$ Target","comments":"24 pages, 21 figures","journal-ref":null,"doi":"10.1103/PhysRevA.105.033102","report-no":null,"categories":"physics.atom-ph quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The $^{133}\\mathrm{Ba}^+$ ion is a promising candidate as a high-fidelity\nqubit, and the $^{137}\\mathrm{Ba}^+$ isotope is promising as a high-fidelity\nqudit ($d>2$). Barium metal is very reactive, and $^{133}\\mathrm{Ba}^+$ is\nradioactive and can only be sourced in small quantities, so the most commonly\nused loading method, oven heating, is less suited for barium, and is currently\nnot possible for $^{133}\\mathrm{Ba}^+$.Pulsed laser ablation solves both of\nthese problems by utilizing compound barium sources, while also giving some\ndistinct advantages, such as fast loading, less displaced material, and lower\nheat load near the ion trap. Because of the relatively low abundances of the\nisotopes of interest, a two-step photoionization technique is used, which gives\nus the ability to selectively load isotopes. Characterization of the ablation\nprocess for our $\\mathrm{BaCl}_2$ targets are presented, including observation\nof neutral and ion ablation-fluence regimes, preparation/conditioning and\nlifetimes of ablation spots, and plume velocity distributions.We show that\nusing laser ablation on $\\mathrm{BaCl}_2$ salt targets with a two-step\nphotoionization method, we can produce and trap barium ions reliably. Further,\nwe demonstrate that with our photoionization method, we can trap\n$^{137}\\mathrm{Ba}^+$ with an enhanced selectivity compared to its natural\nabundance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:31:19 GMT"}],"update_date":"2022-03-23"}
{"id":"2110.08457","submitter":"Xiaowen Feng","authors":"Xiaowen Feng, Haoyu Cheng, Daniel Portik, Heng Li","title":"Metagenome assembly of high-fidelity long reads with hifiasm-meta","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.GN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Current metagenome assemblers developed for short sequence reads or noisy\nlong readswere not optimized for accurate long reads. Here we describe\nhifiasm-meta, a new metagenome assembler that exploits the high accuracy of\nrecent data. Evaluated on seven empirical datasets, hifiasm-meta reconstructed\ntens to hundreds of complete circular bacterial genomes per dataset,\nconsistently outperforming other metagenome assemblers.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:32:22 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08458","submitter":"Panupong Pasupat","authors":"Panupong Pasupat and Yuan Zhang and Kelvin Guu","title":"Controllable Semantic Parsing via Retrieval Augmentation","comments":"EMNLP 2021","journal-ref":null,"doi":"10.18653/v1/2021.emnlp-main.607","report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In practical applications of semantic parsing, we often want to rapidly\nchange the behavior of the parser, such as enabling it to handle queries in a\nnew domain, or changing its predictions on certain targeted queries. While we\ncan introduce new training examples exhibiting the target behavior, a mechanism\nfor enacting such behavior changes without expensive model re-training would be\npreferable. To this end, we propose ControllAble Semantic Parser via Exemplar\nRetrieval (CASPER). Given an input query, the parser retrieves related\nexemplars from a retrieval index, augments them to the query, and then applies\na generative seq2seq model to produce an output parse. The exemplars act as a\ncontrol mechanism over the generic generative model: by manipulating the\nretrieval index or how the augmented query is constructed, we can manipulate\nthe behavior of the parser. On the MTOP dataset, in addition to achieving\nstate-of-the-art on the standard setup, we show that CASPER can parse queries\nin a new domain, adapt the prediction toward the specified patterns, or adapt\nto new semantic schemas without having to further re-train the model.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:34:49 GMT"},{"version":"v2","created":"Wed, 23 Feb 2022 18:57:25 GMT"}],"update_date":"2022-02-24"}
{"id":"2110.08459","submitter":"Yilang Liu","authors":"Yilang Liu, Weiwei Zhang, Zhenhua Xia","title":"Analysis on numerical stability and convergence of RANS turbulence\n  models from the perspective of coupling modes","comments":null,"journal-ref":null,"doi":"10.1063/5.0076273","report-no":null,"categories":"physics.flu-dyn physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reynolds-averaged Navier-Stokes simulations are still the main method to\nstudy complex flows in engineering. However, traditional turbulence models\ncannot accurately predict flow fields with separations. In such situation,\nmachine learning methods provide an effective way to build new data-driven\nturbulence closure models. Nevertheless, a bottleneck that the data-driven\nturbulence models encounter is how to ensure the stability and convergence of\nthe RANS equations in posterior iterations. This paper studies the effects of\ndifferent coupling modes on the convergence and stability between the RANS\nequations and turbulence models. Numerical results demonstrate that the frozen\ncoupling mode, commonly used in machine learning turbulence models, may lead to\ndivergence and instability in posterior iterations; while the mutual coupling\nmode can maintain good convergence and stability in the process of iterations.\nThis research can provide a new perspective to the coupling mode for machine\nlearning turbulence models with RANS equations in posterior iterations.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:36:38 GMT"}],"update_date":"2022-02-02"}
{"id":"2110.08460","submitter":"Tianda Li","authors":"Tianda Li, Yassir El Mesbahi, Ivan Kobyzev, Ahmad Rashid, Atif Mahmud,\n  Nithin Anchuri, Habib Hajimolahoseini, Yang Liu, Mehdi Rezagholizadeh","title":"A Short Study on Compressing Decoder-Based Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained Language Models (PLMs) have been successful for a wide range of\nnatural language processing (NLP) tasks. The state-of-the-art of PLMs, however,\nare extremely large to be used on edge devices. As a result, the topic of model\ncompression has attracted increasing attention in the NLP community. Most of\nthe existing works focus on compressing encoder-based models (tiny-BERT,\ndistilBERT, distilRoBERTa, etc), however, to the best of our knowledge, the\ncompression of decoder-based models (such as GPT-2) has not been investigated\nmuch. Our paper aims to fill this gap. Specifically, we explore two directions:\n1) we employ current state-of-the-art knowledge distillation techniques to\nimprove fine-tuning of DistilGPT-2. 2) we pre-train a compressed GPT-2 model\nusing layer truncation and compare it against the distillation-based method\n(DistilGPT2). The training time of our compressed model is significantly less\nthan DistilGPT-2, but it can achieve better performance when fine-tuned on\ndownstream tasks. We also demonstrate the impact of data cleaning on model\nperformance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:37:08 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08461","submitter":"Fei Shi","authors":"Fei Shi, Mao-Sheng Li, Mengyao Hu, Lin Chen, Man-Hong Yung, Yan-Ling\n  Wang and Xiande Zhang","title":"Strong quantum nonlocality from hypercubes","comments":"arXiv admin note: substantial text overlap with arXiv:2101.00735","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A set of multipartite orthogonal product states is strongly nonlocal if it is\nlocally irreducible in every bipartition. Most known constructions of strongly\nnonlocal orthogonal product set (OPS) are limited to tripartite systems, and\nthey are lack of intuitive structures. In this work, based on the decomposition\nfor the outermost layer of an $n$-dimensional hypercube for $n= 3,4,5$, we\nsuccessfully construct strongly nonlocal OPSs in any possible three, four and\nfive-partite systems, which answers an open question given by Halder et al.\n[Phys. Rev. Lett.122, 040403 (2019)] and Yuan et al. [Phys. Rev. A102, 042228\n(2020)] for any possible three, four and five-partite systems. Our results\nbuild the connection between hypercubes and strongly nonlocal OPSs, and exhibit\nthe phenomenon of strong quantum nonlocality without entanglement in\nmultipartite systems.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:44:44 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08462","submitter":"Yuwei Fang","authors":"Yuwei Fang, Shuohang Wang, Yichong Xu, Ruochen Xu, Siqi Sun, Chenguang\n  Zhu, Michael Zeng","title":"Leveraging Knowledge in Multilingual Commonsense Reasoning","comments":"First place in XCSR Leaderboard:\n  https://inklab.usc.edu//XCSR/leaderboard. Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Commonsense reasoning (CSR) requires the model to be equipped with general\nworld knowledge. While CSR is a language-agnostic process, most comprehensive\nknowledge sources are in few popular languages, especially English. Thus, it\nremains unclear how to effectively conduct multilingual commonsense reasoning\n(XCSR) for various languages. In this work, we propose to utilize English\nknowledge sources via a translate-retrieve-translate (TRT) strategy. For\nmultilingual commonsense questions and choices, we collect related knowledge\nvia translation and retrieval from the knowledge sources. The retrieved\nknowledge is then translated into the target language and integrated into a\npre-trained multilingual language model via visible knowledge attention. Then\nwe utilize a diverse of 4 English knowledge sources to provide more\ncomprehensive coverage of knowledge in different formats. Extensive results on\nthe XCSR benchmark demonstrate that TRT with external knowledge can\nsignificantly improve multilingual commonsense reasoning in both zero-shot and\ntranslate-train settings, outperforming 3.3 and 3.6 points over the previous\nstate-of-the-art on XCSR benchmark datasets (X-CSQA and X-CODAH).\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:51:53 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08463","submitter":"Rahul Barthwal","authors":"Rahul Barthwal and T. Raja Sekhar","title":"Existence of solutions to gas expansion problem through a sharp corner\n  for 2-D Euler equations with general equation of state","comments":null,"journal-ref":null,"doi":"10.1111/sapm.12575","report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we study the gas expansion problem by turning a sharp corner\ninto vacuum for the two-dimensional pseudo-steady compressible Euler equations\nwith a convex equation of state. This problem can be considered as interaction\nof a centered simple wave with a planar rarefaction wave. In order to obtain\nthe global existence of solution up to vacuum boundary of the corresponding\ntwo-dimensional Riemann problem, we consider several Goursat type boundary\nvalue problems for 2-D self-similar Euler equations and use the ideas of\ncharacteristic decomposition and bootstrap method. Further, we formulate\ntwo-dimensional modified shallow water equations newly and solve a dam-break\ntype problem for them as an application of this work. Moreover, we also recover\nthe results from the available literature for certain equation of states which\nprovide a check that the results obtained in this article are actually correct.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 03:55:49 GMT"},{"version":"v2","created":"Tue, 21 Feb 2023 06:13:09 GMT"}],"update_date":"2023-03-22"}
{"id":"2110.08464","submitter":"Zhongli Li","authors":"Zhongli Li, Wenxuan Zhang, Chao Yan, Qingyu Zhou, Chao Li, Hongzhi\n  Liu, Yunbo Cao","title":"Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning\n  for Solving Math Word Problems","comments":"Accepted to ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Math Word Problem (MWP) solving needs to discover the quantitative\nrelationships over natural language narratives. Recent work shows that existing\nmodels memorize procedures from context and rely on shallow heuristics to solve\nMWPs. In this paper, we look at this issue and argue that the cause is a lack\nof overall understanding of MWP patterns. We first investigate how a neural\nnetwork understands patterns only from semantics, and observe that, if the\nprototype equations are the same, most problems get closer representations and\nthose representations apart from them or close to other prototypes tend to\nproduce wrong solutions. Inspired by it, we propose a contrastive learning\napproach, where the neural network perceives the divergence of patterns. We\ncollect contrastive examples by converting the prototype equation into a tree\nand seeking similar tree structures. The solving model is trained with an\nauxiliary objective on the collected examples, resulting in the representations\nof problems with similar prototypes being pulled closer. We conduct experiments\non the Chinese dataset Math23k and the English dataset MathQA. Our method\ngreatly improves the performance in monolingual and multilingual settings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:03:47 GMT"},{"version":"v2","created":"Thu, 10 Mar 2022 11:43:23 GMT"}],"update_date":"2022-03-11"}
{"id":"2110.08465","submitter":"Gen Shi","authors":"Gen Shi, Yifan Zhu, Wenjin Liu, Quanming Yao, Xuesong Li","title":"Heterogeneous Graph-Based Multimodal Brain Network Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.NE q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph neural networks (GNNs) provide powerful insights for brain neuroimaging\ntechnology from the view of graphical networks. However, most existing\nGNN-based models assume that the neuroimaging-produced brain connectome network\nis a homogeneous graph with single types of nodes and edges. In fact, emerging\nstudies have reported and emphasized the significance of heterogeneity among\nhuman brain activities, especially between the two cerebral hemispheres. Thus,\nhomogeneous-structured brain network-based graph methods are insufficient for\nmodelling complicated cerebral activity states. To overcome this problem, in\nthis paper, we present a heterogeneous graph neural network (HebrainGNN) for\nmultimodal brain neuroimaging fusion learning. We first model the brain network\nas a heterogeneous graph with multitype nodes (i.e., left and right hemispheric\nnodes) and multitype edges (i.e., intra- and interhemispheric edges). Then, we\npropose a self-supervised pretraining strategy based on a heterogeneous brain\nnetwork to address the potential overfitting problem caused by the conflict\nbetween a large parameter size and a small medical data sample size. Our\nresults show the superiority of the proposed model over other existing methods\nin brain-related disease prediction tasks. Ablation experiments show that our\nheterogeneous graph-based model attaches more importance to hemispheric\nconnections that may be neglected due to their low strength by previous\nhomogeneous graph models. Other experiments also indicate that our proposed\nmodel with a pretraining strategy alleviates the problem of limited labelled\ndata and yields a significant improvement in accuracy.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:15:33 GMT"},{"version":"v2","created":"Fri, 12 Nov 2021 07:05:06 GMT"},{"version":"v3","created":"Thu, 17 Mar 2022 12:20:07 GMT"},{"version":"v4","created":"Wed, 6 Jul 2022 02:53:32 GMT"},{"version":"v5","created":"Wed, 28 Sep 2022 05:44:54 GMT"}],"update_date":"2022-09-30"}
{"id":"2110.08466","submitter":"Hao Sun","authors":"Hao Sun, Guangxuan Xu, Jiawen Deng, Jiale Cheng, Chujie Zheng, Hao\n  Zhou, Nanyun Peng, Xiaoyan Zhu, Minlie Huang","title":"On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark","comments":"Accepted to Findings of ACL 2022 (Long Paper)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dialogue safety problems severely limit the real-world deployment of neural\nconversational models and have attracted great research interests recently.\nHowever, dialogue safety problems remain under-defined and the corresponding\ndataset is scarce. We propose a taxonomy for dialogue safety specifically\ndesigned to capture unsafe behaviors in human-bot dialogue settings, with\nfocuses on context-sensitive unsafety, which is under-explored in prior works.\nTo spur research in this direction, we compile DiaSafety, a dataset with rich\ncontext-sensitive unsafe examples. Experiments show that existing safety\nguarding tools fail severely on our dataset. As a remedy, we train a dialogue\nsafety classifier to provide a strong baseline for context-sensitive dialogue\nunsafety detection. With our classifier, we perform safety evaluations on\npopular conversational models and show that existing dialogue systems still\nexhibit concerning context-sensitive safety problems.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:17:12 GMT"},{"version":"v2","created":"Mon, 4 Apr 2022 06:17:40 GMT"}],"update_date":"2022-04-05"}
{"id":"2110.08467","submitter":"Sanket Vaibhav Mehta","authors":"Sanket Vaibhav Mehta, Jinfeng Rao, Yi Tay, Mihir Kale, Ankur P.\n  Parikh, Emma Strubell","title":"Improving Compositional Generalization with Self-Training for\n  Data-to-Text Generation","comments":"Accepted at ACL 2022 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Data-to-text generation focuses on generating fluent natural language\nresponses from structured meaning representations (MRs). Such representations\nare compositional and it is costly to collect responses for all possible\ncombinations of atomic meaning schemata, thereby necessitating few-shot\ngeneralization to novel MRs. In this work, we systematically study the\ncompositional generalization of the state-of-the-art T5 models in few-shot\ndata-to-text tasks. We show that T5 models fail to generalize to unseen MRs,\nand we propose a template-based input representation that considerably improves\nthe model's generalization capability. To further improve the model's\nperformance, we propose an approach based on self-training using fine-tuned\nBLEURT for pseudo response selection. On the commonly-used SGD and Weather\nbenchmarks, the proposed self-training approach improves tree accuracy by 46%+\nand reduces the slot error rates by 73%+ over the strong T5 baselines in\nfew-shot settings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:26:56 GMT"},{"version":"v2","created":"Mon, 11 Apr 2022 16:24:19 GMT"}],"update_date":"2022-04-12"}
{"id":"2110.08468","submitter":"Matthew Grasinger","authors":"Matthew Grasinger, Kaushik Dayal, Gal deBotton, and Prashant K.\n  Purohit","title":"Statistical mechanics of a dielectric polymer chain in the force\n  ensemble","comments":null,"journal-ref":null,"doi":"10.1016/j.jmps.2021.104658","report-no":null,"categories":"cond-mat.soft cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Constitutive modeling of dielectric elastomers has been of long standing\ninterest in mechanics. Over the last two decades rigorous constitutive models\nhave been developed that couple the electrical response of these polymers with\nlarge deformations characteristic of soft solids. A drawback of these models is\nthat unlike classic models of rubber elasticity they do not consider the\ncoupled electromechanical response of single polymer chains which must be\ntreated using statistical mechanics. The objective of this paper is to compute\nthe stretch and polarization of single polymer chains subject to a fixed force\nand fixed electric field using statistical mechanics. We assume that the\ndipoles induced by the applied electric field at each link do not interact with\neach other and compute the partition function using standard techniques. We\nthen calculate the stretch and polarization by taking appropriate derivatives\nof the partition function and obtain analytical results in various limits. We\nalso perform Markov chain Monte Carlo simulations using the Metropolis and\numbrella sampling methods, as well as develop a new sampling method which\nimproves convergence by exploiting a symmetry inherent in dielectric polymer\nchains. The analytical expressions are shown to agree with the Monte Carlo\nresults over a range of forces and electric fields. Our results complement\nrecent work on the statistical mechanics of electro-responsive chains which\nobtains analytical expressions in a different ensemble.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:34:34 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08469","submitter":"Daniel Mart\\'inez","authors":"Daniel Mart\\'inez-Carbajal, Manuel de la Cruz, Sergio\n  Pati\\~no-L\\'opez, Leonardo D. Herrera-Z\\'u\\~niga","title":"Implications of Seiberg-Witten map on type-I superconductors","comments":"Published version in IJMP-A","journal-ref":"International Journal of Modern Physics A Vol. 37, No. 35, 2250218\n  (2022)","doi":"10.1142/S0217751X22502189","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We incorporate the Seiberg-Witten map of noncommutative theory in the\nclassical London theory of type-I superconductivity when an external magnetic\nfield is applied. After defining the noncommutative Maxwell potentials, we\nderive the London equation for the supercurrent as a function of the\nnoncommutative parameter, up to second order in gauge fields expansion. Keeping\ntrack of the effects of noncommutative gauge fields, we argue that\nnoncommutative magnetic field effects can be cast in the permeability of the\nsuperconductor as an emergent property of the material, measurable in possible\nnot-so-far ultra-high-energy experimental setups. Another consequence of the\nSeiberg-Witten map is the London penetration length that acquires corrections\nin the expansion. Also, we show that the flux quantization remains consistent\nrelative to the commutative case. Our effective magnetic permeability and\nLondon penetration length reduce to the standard ones in the commutative limit.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:45:30 GMT"},{"version":"v2","created":"Sat, 13 Nov 2021 02:51:54 GMT"},{"version":"v3","created":"Sat, 12 Feb 2022 05:08:28 GMT"},{"version":"v4","created":"Mon, 22 Aug 2022 02:52:07 GMT"},{"version":"v5","created":"Thu, 9 Mar 2023 03:03:13 GMT"}],"update_date":"2023-03-10"}
{"id":"2110.08470","submitter":"Mattia Atzeni","authors":"Mattia Atzeni, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya\n  Sachan","title":"Case-based Reasoning for Better Generalization in Textual Reinforcement\n  Learning","comments":"Published as a conference paper at ICLR 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-based games (TBG) have emerged as promising environments for driving\nresearch in grounded language understanding and studying problems like\ngeneralization and sample efficiency. Several deep reinforcement learning (RL)\nmethods with varying architectures and learning schemes have been proposed for\nTBGs. However, these methods fail to generalize efficiently, especially under\ndistributional shifts. In a departure from deep RL approaches, in this paper,\nwe propose a general method inspired by case-based reasoning to train agents\nand generalize out of the training distribution. The case-based reasoner\ncollects instances of positive experiences from the agent's interaction with\nthe world in the past and later reuses the collected experiences to act\nefficiently. The method can be applied in conjunction with any existing\non-policy neural agent in the literature for TBGs. Our experiments show that\nthe proposed approach consistently improves existing methods, obtains good\nout-of-distribution generalization, and achieves new state-of-the-art results\non widely used environments.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:51:34 GMT"},{"version":"v2","created":"Fri, 18 Feb 2022 11:55:08 GMT"},{"version":"v3","created":"Tue, 29 Mar 2022 11:00:03 GMT"}],"update_date":"2022-03-30"}
{"id":"2110.08471","submitter":"Man Shun Ang","authors":"Andersen Ang, Jianzhu Ma, Nianjun Liu, Kun Huang, Yijie Wang","title":"Fast Projection onto the Capped Simplex with Applications to Sparse\n  Regression in Bioinformatics","comments":"12 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG q-bio.GN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the problem of projecting a vector onto the so-called k-capped\nsimplex, which is a hyper-cube cut by a hyperplane. For an n-dimensional input\nvector with bounded elements, we found that a simple algorithm based on\nNewton's method is able to solve the projection problem to high precision with\na complexity roughly about O(n), which has a much lower computational cost\ncompared with the existing sorting-based methods proposed in the literature. We\nprovide a theory for partial explanation and justification of the method.\n  We demonstrate that the proposed algorithm can produce a solution of the\nprojection problem with high precision on large scale datasets, and the\nalgorithm is able to significantly outperform the state-of-the-art methods in\nterms of runtime (about 6-8 times faster than a commercial software with\nrespect to CPU time for input vector with 1 million variables or more).\n  We further illustrate the effectiveness of the proposed algorithm on solving\nsparse regression in a bioinformatics problem. Empirical results on the GWAS\ndataset (with 1,500,000 single-nucleotide polymorphisms) show that, when using\nthe proposed method to accelerate the Projected Quasi-Newton (PQN) method, the\naccelerated PQN algorithm is able to handle huge-scale regression problem and\nit is more efficient (about 3-6 times faster) than the current state-of-the-art\nmethods.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:03:24 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 01:42:06 GMT"},{"version":"v3","created":"Thu, 21 Oct 2021 19:56:47 GMT"},{"version":"v4","created":"Tue, 26 Oct 2021 01:57:58 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08472","submitter":"Xin Yu","authors":"Xin Yu, Jeroen van Baar, Siheng Chen","title":"Joint 3D Human Shape Recovery and Pose Estimation from a Single Image\n  with Bilayer Graph","comments":"3DV'21","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ability to estimate the 3D human shape and pose from images can be useful\nin many contexts. Recent approaches have explored using graph convolutional\nnetworks and achieved promising results. The fact that the 3D shape is\nrepresented by a mesh, an undirected graph, makes graph convolutional networks\na natural fit for this problem. However, graph convolutional networks have\nlimited representation power. Information from nodes in the graph is passed to\nconnected neighbors, and propagation of information requires successive graph\nconvolutions. To overcome this limitation, we propose a dual-scale graph\napproach. We use a coarse graph, derived from a dense graph, to estimate the\nhuman's 3D pose, and the dense graph to estimate the 3D shape. Information in\ncoarse graphs can be propagated over longer distances compared to dense graphs.\nIn addition, information about pose can guide to recover local shape detail and\nvice versa. We recognize that the connection between coarse and dense is itself\na graph, and introduce graph fusion blocks to exchange information between\ngraphs with different scales. We train our model end-to-end and show that we\ncan achieve state-of-the-art results for several evaluation datasets.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:04:02 GMT"},{"version":"v2","created":"Sun, 5 Dec 2021 18:46:36 GMT"}],"update_date":"2021-12-07"}
{"id":"2110.08473","submitter":"Xiaoqian Wang","authors":"Huan Zhao, Xiao-Qian Wang, Chao Gao, Zhuo Yu, Shuang Wang, Li-Dan Gou,\n  and Zhi-Hai Yao","title":"Second-order Cumulants Ghost Imaging","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the conventional ghost imaging (GI), the image is retrieved by correlating\nthe reference intensity fluctuation at a charge-coupled device (CCD) with the\nsignal intensity fluctuation at a bucket detector. In this letter, we present\nthe protocol of GI, it is called Second-order Cumulants ghost imaging (SCGI).\nThe image is retrieved by the fluctuation information of correlating intensity\nfluctuation at two detectors, and the resolution limit can be enhanced than\nconventional GI. The experimental results of SCGI agreement with theoretical\nresults.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:04:04 GMT"},{"version":"v2","created":"Fri, 22 Oct 2021 03:02:03 GMT"}],"update_date":"2021-10-25"}
{"id":"2110.08474","submitter":"Xu Xu","authors":"Xu Xu","title":"A new class of discrete conformal structures on surfaces with boundary","comments":"28 pages, 5 figures, title changed, references are updated","journal-ref":"Calc. Var. Partial Differential Equations 61 (2022), no. 4, Paper\n  No. 141","doi":null,"report-no":null,"categories":"math.GT math.DG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce a new class of discrete conformal structures on surfaces with\nboundary, which have nice interpolations in 3-dimensional hyperbolic geometry.\nThen we prove the global rigidity of the new discrete conformal structures\nusing variational principles, which is a complement of Guo-Luo's rigidity of\nthe discrete conformal structures and Guo's rigidity of vertex scaling on\nsurface with boundary. As a result, new convexities of the volume of\ngeneralized hyperbolic pyramids with right-angled hyperbolic hexagonal bases\nare obtained. Motivated by Chow-Luo's combinatorial Ricci flow and Luo's\ncombinatorial Yamabe flow on closed surfaces, we further introduce\ncombinatorial Ricci flow and combinatorial Calabi flows to deform the new\ndiscrete conformal structures on surfaces with boundary. The basic properties\nof these combinatorial curvature flows are established. These combinatorial\ncurvature flows provide effective algorithms for constructing hyperbolic\nmetrics on surfaces with totally geodesic boundary components of prescribed\nlengths.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:16:26 GMT"},{"version":"v2","created":"Mon, 18 Apr 2022 10:13:39 GMT"}],"update_date":"2022-08-11"}
{"id":"2110.08475","submitter":"Weikui Ye","authors":"Weikui Ye","title":"Global well-posedness, stability and instability for the non-viscous\n  Oldroyd-B model","comments":"Oldroyd-B model; global existence; stability; instability; decay;\n  energy dissipation","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we consider the 3-dimensional incompressible Oldroyd-B model.\nFirst, we establish two results of the global existence for different kinds of\nthe coupling coefficient $k$. Then, we prove that the solutions $(u,\\tau)$ are\nglobally steady when $k^m\\rightarrow k>0$, though $(u,\\tau)$ corresponds to\ndifferent decays for different kinds of $k>0~$. Finally, we show that the\nenergy of $u(t,x)$ will have a jump when $k\\rightarrow 0$ in large time, which\nimplies a non-steady phenomenon. In a word, we find an interesting physical\nphenomenon of \\eqref{1} such that smaller coupling coefficient $k$ will have a\nbetter impact for the energy dissipation of $(u,\\tau)$, but $k$ can't be too\nsmall to zero, or the dissipation will vanish instantly. While the damping term\n$\\tau$ and $\\mathbb{D}u$ always bring the well impact for the energy\ndissipation.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:22:30 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08476","submitter":"Dieu Nguyen","authors":"Dieu D. Nguyen, Martin Bureau, Sabine Thater, Kristina Nyland, Mark\n  den Brok, Michelle Cappellari, Timothy A. Davis, Jenny E. Greene, Nadine\n  Neumayer, Masatoshi Imanishi, Takuma Izumi, Taiki Kawamuro, Shunsuke Baba,\n  Phuong M. Nguyen, Satoru Iguchi, Takafumi Tsukui, Lam N. T., Than Ho","title":"The MBHBM$^{\\star}$ Project -- II. Molecular Gas Kinematics in the\n  Lenticular Galaxy NGC 3593 Reveal a Supermassive Black Hole","comments":"27 pages, 18 Figures, 8 Tables. Accepted to MNRAS","journal-ref":null,"doi":"10.1093/mnras/stab3016","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As part of the Measuring Black Holes in Below Milky Way-mass (M$^\\star$)\ngalaxies (MBHBM$^\\star$) Project, we present a dynamical measurement of the\nsupermassive black hole (SMBH) mass in the nearby lenticular galaxy NGC 3593,\nusing cold molecular gas $^{12}$CO(2-1) emission observed at an angular\nresolution of $\\approx0''.3$ ($\\approx10$ pc) with the Atacama Large\nMillimeter/submillimeter Array (ALMA). Our ALMA observations reveal a\ncircumnuclear molecular gas disc (CND) elongated along the galaxy major axis\nand rotating around the SMBH. Using dynamical modelling, the molecular gas\nkinematics allow us to infer a SMBH mass $M_{\\rm\nBH}=2.40_{-1.05}^{+1.87}\\times10^6$ M$_\\odot$ (only statistical uncertainties\nat the $3\\sigma$ level). We also detect a massive core of cold molecular gas\n(CMC) of mass $M_{\\rm CMC}=(5.4\\pm1.2)\\times10^6$ M$_\\odot$ and effective\n(half-mass) radius $r_{\\rm CMC,e}=11.2\\pm2.8$ pc, co-spatial with a nuclear\nstar cluster (NSC) of mass $M_{\\rm NSC}=(1.67\\pm0.48)\\times10^7$ M$_\\odot$ and\neffective radius $r_{\\rm NSC,e}=5.0\\pm1.0$~pc (or $0''.15\\pm0''.03$). The mass\nprofiles of the CMC and NSC are well described by S\\'{e}rsic functions with\nindices $1-1.4$. Our $M_{\\rm BH}$ and $M_{\\rm NSC}$ estimates for NGC 3593\nagree well with the recently compiled $M_{\\rm BH}$-$M_{\\rm NSC}$ scaling\nrelation. Although the $M_{\\rm NSC}$ uncertainty is twice the inferred $M_{\\rm\nBH}$, the rapid central rise of the rotation velocities of the CND (as the\nradius decreases) clearly suggests a SMBH. Indeed, our dynamical models show\nthat even if $M_{\\rm NSC}$ is at the upper end of its allowed range, the\nevidence for a black hole does not vanish, but remains with a lower limit of\n$M_{\\rm BH}>3\\times10^5$ M$_\\odot$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:28:12 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08477","submitter":"Jian Du","authors":"Yan Shen and Jian Du and Han Zhao and Benyu Zhang and Zhanghexuan Ji\n  and Mingchen Gao","title":"FedMM: Saddle Point Optimization for Federated Adversarial Domain\n  Adaptation","comments":"34 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Federated adversary domain adaptation is a unique distributed minimax\ntraining task due to the prevalence of label imbalance among clients, with each\nclient only seeing a subset of the classes of labels required to train a global\nmodel. To tackle this problem, we propose a distributed minimax optimizer\nreferred to as FedMM, designed specifically for the federated adversary domain\nadaptation problem. It works well even in the extreme case where each client\nhas different label classes and some clients only have unsupervised tasks. We\nprove that FedMM ensures convergence to a stationary point with domain-shifted\nunsupervised data. On a variety of benchmark datasets, extensive experiments\nshow that FedMM consistently achieves either significant communication savings\nor significant accuracy improvements over federated optimizers based on the\ngradient descent ascent (GDA) algorithm. When training from scratch, for\nexample, it outperforms other GDA based federated average methods by around\n$20\\%$ in accuracy over the same communication rounds; and it consistently\noutperforms when training from pre-trained models with an accuracy improvement\nfrom $5.4\\%$ to $9\\%$ for different networks.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:32:03 GMT"},{"version":"v2","created":"Sun, 24 Oct 2021 17:52:37 GMT"},{"version":"v3","created":"Tue, 16 Nov 2021 03:36:08 GMT"}],"update_date":"2021-11-17"}
{"id":"2110.08478","submitter":"Chen Shi","authors":"Chen Shi, Anton Artemyev, Marco Velli, Anna Tenerani","title":"Stability of the magnetotail current sheet with normal magnetic field\n  and field-aligned plasma flows","comments":null,"journal-ref":null,"doi":"10.1029/2021JA029711","report-no":null,"categories":"physics.space-ph physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the most important problems of magnetotail dynamics is the substorm\nonset and the related instability of the magneotail current sheet. Since the\nsimplest 2D current sheet configuration with monotonic $B_z$ was proven to be\nstable to the tearing mode, the focus of the instability investigation moved to\nmore specific configurations, e.g. kinetic current sheets with strong transient\nion currents and current sheets with non-monotonic $B_z$ (local $B_z$ minima\nor/and peaks). Stability of the latter current sheet configuration has been\nstudied both within kinetic and fluid approaches, whereas the investigation of\nthe transient ion effects were limited to kinetic models only. This paper aims\nto provide detailed analysis of stability of a multi-fluid current sheet\nconfiguration that mimics current sheets with transient ions. Using the system\nwith two field-aligned ion flows that mimic the effect of pressure\nnon-gyrotropy, we construct 1D current sheet with a finite $B_z$. This model\ndescribes well recent findings of very thin intense magnetotail current sheets.\nThe stability analysis of this two-ion model confirms the stabilizing effect of\nfinite $B_z$ and shows that the most stable current sheet is the one with\nexactly counter-streaming ion flows and zero net flow. Such field-aligned flows\nmay substitute the contribution of the pressure tensor nongyrotropy to the\nstress balance, but cannot overtake the stabilizing effect of $B_z$. Obtained\nresults are discussed in the context of magnetotail dynamical models and\nspacecraft observations.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:44:16 GMT"}],"update_date":"2021-12-01"}
{"id":"2110.08479","submitter":"Yuki Sato","authors":"Jan Ambj{\\o}rn, Yuki Hiraga, Yoshiyasu Ito and Yuki Sato","title":"Wormhole interaction in 2d Horava-Lifshitz quantum gravity","comments":"11 pages, contribution to the Proceedings of the 16th Marcel\n  Grossmann Meeting (MG16)","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A lattice regularization for the $2$d projectable Horava-Lifshitz (HL)\nquantum gravity is known to be the $2$d causal dynamical triangulations (CDT),\nand the $2$d CDT can be generalized so as to include all possible genus\ncontributions non-perturbatively. We show that in the context of HL gravity,\neffects coming from such a non-perturbative sum over topologies can be\nsuccessfully taken into account, if we quantize the $2$d projectable HL gravity\nwith a simple bi-local wormhole interaction. This conference paper is based on\nthe article, Phys. Lett. B 816 (2021), 136205.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:44:26 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08480","submitter":"Rafid Ameer Mahmud","authors":"Rafid Ameer Mahmud, Fahim Faisal, Saaduddin Mahmud, Md. Mosaddek Khan","title":"Learning Cooperation and Online Planning Through Simulation and Graph\n  Convolutional Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Multi-agent Markov Decision Process (MMDP) has been an effective way of\nmodelling sequential decision making algorithms for multi-agent cooperative\nenvironments. A number of algorithms based on centralized and decentralized\nplanning have been developed in this domain. However, dynamically changing\nenvironment, coupled with exponential size of the state and joint action space,\nmake it difficult for these algorithms to provide both efficiency and\nscalability. Recently, Centralized planning algorithm FV-MCTS-MP and\ndecentralized planning algorithm \\textit{Alternate maximization with\nBehavioural Cloning} (ABC) have achieved notable performance in solving MMDPs.\nHowever, they are not capable of adapting to dynamically changing environments\nand accounting for the lack of communication among agents, respectively.\nAgainst this background, we introduce a simulation based online planning\nalgorithm, that we call SiCLOP, for multi-agent cooperative environments.\nSpecifically, SiCLOP tailors Monte Carlo Tree Search (MCTS) and uses\nCoordination Graph (CG) and Graph Neural Network (GCN) to learn cooperation and\nprovides real time solution of a MMDP problem. It also improves scalability\nthrough an effective pruning of action space. Additionally, unlike FV-MCTS-MP\nand ABC, SiCLOP supports transfer learning, which enables learned agents to\noperate in different environments. We also provide theoretical discussion about\nthe convergence property of our algorithm within the context of multi-agent\nsettings. Finally, our extensive empirical results show that SiCLOP\nsignificantly outperforms the state-of-the-art online planning algorithms.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:54:32 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08481","submitter":"Liao Wenxing","authors":"Shi Xiaofei, Liao Wenxing","title":"On the randomness analysis of link quality prediction: limitations and\n  benefits","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In wireless multi-hop networks, such as wireless sensor networks, link\nquality (LQ) is one of the most important metrics and is widely used in\nhigher-layer applications such as routing protocols. An accurate link quality\nprediction may greatly help to improve the performance of wireless multi-hop\nnetworks. Researchers have proposed a lot of link quality prediction models in\nrecent years. However, due to the dynamic and stochastic nature of wireless\ntransmission, the performance of link quality prediction remains challenging.\nIn this article, we mainly analyze the influence of the stochastic nature of\nwireless transmission on the link quality prediction model and discuss the\nbenefits in the application of wireless multi-hop networks with the\nperformance-limited link quality prediction models.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:54:33 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08482","submitter":"Matt Kerr","authors":"Charles F. Doran, Matt Kerr, Soumya Sinha Babu","title":"$K_2$ and quantum curves","comments":"51 pages, 1 figure; minor revisions","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG hep-th math-ph math.KT math.MP math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A 2015 conjecture of Codesido-Grassi-Mari\\~no in topological string theory\nrelates the enumerative invariants of toric CY 3-folds to the spectra of\noperators attached to their mirror curves. We deduce two consequences of this\nconjecture for the integral regulators of $K_2$-classes on these curves, and\nthen prove both of them; the results thus give evidence for the CGM conjecture.\n(While the conjecture and the deduction process both entail forms of local\nmirror symmetry, the consequences/theorems do not: they only involve the curves\nthemselves.) Our first theorem relates zeroes of the higher normal function to\nthe spectra of the operators for curves of genus one, and suggests a new link\nbetween analysis and arithmetic geometry. The second theorem provides\ndilogarithm formulas for limits of regulator periods at the maximal conifold\npoint in moduli of the curves.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:00:06 GMT"},{"version":"v2","created":"Thu, 12 May 2022 02:25:14 GMT"}],"update_date":"2022-05-13"}
{"id":"2110.08483","submitter":"Haoyin Xu","authors":"Haoyin Xu, Jayanta Dey, Sambit Panda, Joshua T. Vogelstein","title":"Simplest Streaming Trees","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decision forests, including random forests and gradient boosting trees,\nremain the leading machine learning methods for many real-world data problems,\nspecifically on tabular data. However, current standard implementations only\noperate in batch mode, and therefore cannot incrementally update when more data\narrive. Several previous works developed streaming trees and ensembles to\novercome this limitation. Nonetheless, we found that those state-of-the-art\nalgorithms suffer from a number of drawbacks, including poor performance on\nsome problems and high memory usage on others. We therefore developed the\nsimplest possible extension of decision trees we could think of: given new\ndata, simply update existing trees by continuing to grow them, and replace some\nold trees with new ones to control the total number of trees. On three standard\ndatasets, we illustrate that our approach, Stream Decision Forest (SDF), does\nnot suffer from either of the aforementioned limitations. In a benchmark suite\ncontaining 72 classification problems (the OpenML-CC18 data suite), we\nillustrate that our approach often performs as well, and sometimes better even,\nthan the batch mode decision forest algorithm. Thus, SDFs establish a simple\nstandard for streaming trees and forests that could readily be applied to many\nreal-world problems, including those with distribution drift and continual\nlearning.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:06:36 GMT"},{"version":"v2","created":"Sun, 23 Jan 2022 00:51:56 GMT"},{"version":"v3","created":"Mon, 21 Feb 2022 15:50:08 GMT"},{"version":"v4","created":"Tue, 8 Mar 2022 21:24:54 GMT"},{"version":"v5","created":"Thu, 10 Nov 2022 14:39:53 GMT"}],"update_date":"2022-11-11"}
{"id":"2110.08484","submitter":"Woojeong Jin","authors":"Woojeong Jin, Yu Cheng, Yelong Shen, Weizhu Chen, Xiang Ren","title":"A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based\n  Learning for Vision-Language Models","comments":"Accepted to ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large pre-trained vision-language (VL) models can learn a new task with a\nhandful of examples and generalize to a new task without fine-tuning. However,\nthese VL models are hard to deploy for real-world applications due to their\nimpractically huge sizes and slow inference speed. To solve this limitation, we\nstudy prompt-based low-resource learning of VL tasks with our proposed method,\nFewVLM, relatively smaller than recent few-shot learners. For FewVLM, we\npre-train a sequence-to-sequence transformer model with prefix language\nmodeling (PrefixLM) and masked language modeling (MaskedLM). Furthermore, we\nanalyze the effect of diverse prompts for few-shot tasks. Experimental results\non VQA show that FewVLM with prompt-based learning outperforms Frozen which is\n31x larger than FewVLM by 18.2% point and achieves comparable results to a 246x\nlarger model, PICa. In our analysis, we observe that (1) prompts significantly\naffect zero-shot performance but marginally affect few-shot performance, (2)\nmodels with noisy prompts learn as quickly as hand-crafted prompts given larger\ntraining data, and (3) MaskedLM helps VQA tasks while PrefixLM boosts\ncaptioning performance. Our code is publicly available at\n\\url{https://github.com/woojeongjin/FewVLM}\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:07:59 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 01:52:38 GMT"}],"update_date":"2022-03-16"}
{"id":"2110.08485","submitter":"Liao Wenxing","authors":"Liao Wenxing, Shi Xiaofei","title":"Design of Link-Quality-prediction-based Software-Defined Wireless Sensor\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In wireless multi-hop networks, the instability of the wireless links leads\nto unstable networking. Even in the newly designed Software-Defined Wireless\nSensor Networks (SDWSN), similar problems exist. To further improve the\nstability of SDWSN, we introduce a Link Quality (LQ) prediction model into the\nSDWSN architecture. The prediction model is used to improve the stability\nbetween neighbor nodes, and thus the stability of wireless multi-hop routes.\nSimulation results show that the LQ prediction model can make reasonable\ncorrections to the reality wireless link model, which can well address the\nrestrictive nature of unstable links. As a result, by reducing the use of\nunstable wireless links, the stability of the SDWSN network improved.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:09:21 GMT"}],"update_date":"2021-12-28"}
{"id":"2110.08486","submitter":"Te-Lin Wu","authors":"Te-Lin Wu, Alex Spangher, Pegah Alipoormolabashi, Marjorie Freedman,\n  Ralph Weischedel, Nanyun Peng","title":"Understanding Multimodal Procedural Knowledge by Sequencing Multimodal\n  Instructional Manuals","comments":"In Proceedings of the Conference of the 60th Annual Meeting of the\n  Association for Computational Linguistics (ACL), 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ability to sequence unordered events is an essential skill to comprehend\nand reason about real world task procedures, which often requires thorough\nunderstanding of temporal common sense and multimodal information, as these\nprocedures are often communicated through a combination of texts and images.\nSuch capability is essential for applications such as sequential task planning\nand multi-source instruction summarization. While humans are capable of\nreasoning about and sequencing unordered multimodal procedural instructions,\nwhether current machine learning models have such essential capability is still\nan open question. In this work, we benchmark models' capability of reasoning\nover and sequencing unordered multimodal instructions by curating datasets from\npopular online instructional manuals and collecting comprehensive human\nannotations. We find models not only perform significantly worse than humans\nbut also seem incapable of efficiently utilizing the multimodal information. To\nimprove machines' performance on multimodal event sequencing, we propose\nsequentiality-aware pretraining techniques that exploit the sequential\nalignment properties of both texts and images, resulting in > 5% significant\nimprovements.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:12:15 GMT"},{"version":"v2","created":"Wed, 16 Mar 2022 15:16:02 GMT"},{"version":"v3","created":"Thu, 17 Mar 2022 03:24:54 GMT"}],"update_date":"2022-03-18"}
{"id":"2110.08487","submitter":"Yu-Tian Zhang","authors":"Yu-Tian Zhang, Yun-Peng Wang, Yu-Yang Zhang, Shixuan Du, Sokrates T.\n  Pantelides","title":"Thermal transport of amorphous carbon and boron-nitride monolayers","comments":"18 pages, 6 figures and 4 extended figures","journal-ref":"Appl. Phys. Lett. 120, 222201 (2022)","doi":"10.1063/5.0089967","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.dis-nn","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Two-dimensional (2D) materials like graphene and h-BN usually show high\nthermal conductivity, which enables rich applications in thermal dissipation\nand nanodevices. Disorder, on the other hand, is often present in 2D materials.\nStructural disorder induces localization of electrons and phonons and alters\nthe electronic, mechanical, thermal, and magnetic properties. Here we calculate\nthe in-plane thermal conductivity of both monolayer carbon and monolayer boron\nnitride in the amorphous form, by reverse nonequilibrium molecular dynamics\nsimulations. We find that the thermal conductivity of both monolayer amorphous\ncarbon (MAC) and monolayer amorphous boron nitride (ma-BN) are about two orders\nof magnitude smaller than their crystalline counterparts. Moreover, the\nultralow thermal conductivity is independent of the temperature due to the\nextremely short phonon mean free path in these amorphous materials. The\nrelation between the structure disorder and the reduction of the thermal\nconductivity is analyzed in terms of the vibrational density of states and the\nparticipation ratio. ma-BN shows strong vibrational localization across the\nfrequency range, while MAC exhibits a unique extended G' mode at high frequency\ndue to its sp2 hybridization and the broken E2g symmetry. The present results\npave the way for potential applications of MAC and ma-BN in thermal management.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:13:32 GMT"},{"version":"v2","created":"Fri, 10 Dec 2021 14:39:29 GMT"}],"update_date":"2022-06-01"}
{"id":"2110.08488","submitter":"Rey Wiyatno","authors":"Rey Reza Wiyatno, Anqi Xu, and Liam Paull","title":"Lifelong Topological Visual Navigation","comments":"This paper has been accepted to IEEE Robotics and Automation Letters\n  (RA-L) and International Conference on Intelligent Robots and Systems (IROS)\n  2022. Project page: https://montrealrobotics.ca/ltvn/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Commonly, learning-based topological navigation approaches produce a local\npolicy while preserving some loose connectivity of the space through a\ntopological map. Nevertheless, spurious or missing edges in the topological\ngraph often lead to navigation failure. In this work, we propose a\nsampling-based graph building method, which results in sparser graphs yet with\nhigher navigation performance compared to baseline methods. We also propose\ngraph maintenance strategies that eliminate spurious edges and expand the graph\nas needed, which improves lifelong navigation performance. Unlike controllers\nthat learn from fixed training environments, we show that our model can be\nfine-tuned using only a small number of collected trajectory images from a\nreal-world environment where the agent is deployed. We demonstrate successful\nnavigation after fine-tuning on real-world environments, and notably show\nsignificant navigation improvements over time by applying our lifelong graph\nmaintenance strategies.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:16:14 GMT"},{"version":"v2","created":"Sun, 10 Jul 2022 21:48:35 GMT"}],"update_date":"2022-07-12"}
{"id":"2110.08489","submitter":"Lo\\\"ic Marsot","authors":"Lo\\\"ic Marsot","title":"Planar Carrollean dynamics, and the Carroll quantum equation","comments":"24 pages, 1 figure; added a section about gravitational coupling; to\n  be published in Journal of Geometry and Physics","journal-ref":null,"doi":"10.1016/j.geomphys.2022.104574","report-no":null,"categories":"math-ph gr-qc hep-th math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We expand on the known result that the Carroll algebra in $2+1$ dimensions\nadmits two non-trivial central extensions by computing the associated Lie\ngroup, which we call extended Carroll group. The symplectic geometry associated\nto this group is then computed to describe the motion of planar Carroll\nelementary particles, in the free case, when coupled to an electromagnetic\nfield, and to a gravitational field. We compare to the motions of Carroll\nparticles in $3+1$ dimensions in the same conditions, and also give the\ndynamics of Carroll particles with spin. In an electromagnetic background, the\nplanar Carroll dynamics differ from the known Carroll ones due to 2 new Casimir\ninvariants, and turn out to be non-trivial. The coupling to a gravitational\nfield leaves the dynamics trivial, however. Finally, we obtain the quantum\nequation obeyed by Carroll wave functions \\textit{via} geometric quantization.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:26:28 GMT"},{"version":"v2","created":"Fri, 29 Oct 2021 09:54:46 GMT"},{"version":"v3","created":"Tue, 1 Mar 2022 16:02:37 GMT"},{"version":"v4","created":"Mon, 16 May 2022 12:47:31 GMT"}],"update_date":"2022-07-13"}
{"id":"2110.08490","submitter":"Nicolas Fournier","authors":"Nicolas Fournier and Yoan Tardy","title":"Collisions of the supercritical Keller-Segel particle system","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study a particle system naturally associated to the $2$-dimensional\nKeller-Segel equation. It consists of $N$ Brownian particles in the plane,\ninteracting through a binary attraction in $\\theta/(Nr)$, where $r$ stands for\nthe distance between two particles. When the intensity $\\theta$ of this\nattraction is greater than $2$, this particle system explodes in finite time.\nWe assume that $N>3\\theta$ and study in details what happens near explosion.\nThere are two slightly different scenarios, depending on the values of $N$ and\n$\\theta$, here is one: at explosion, a cluster consisting of precisely $k_0$\nparticles emerges, for some deterministic $k_0\\geq 7$ depending on $N$ and\n$\\theta$. Just before explosion, there are infinitely many $(k_0-1)$-ary\ncollisions. There are also infinitely many $(k_0-2)$-ary collisions before each\n$(k_0-1)$-ary collision. And there are infinitely many binary collisions before\neach $(k_0-2)$-ary collision. Finally, collisions of subsets of $3,\\dots,k_0-3$\nparticles never occur. The other scenario is similar except that there are no\n$(k_0-2)$-ary collisions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:36:43 GMT"},{"version":"v2","created":"Wed, 8 Feb 2023 13:46:56 GMT"}],"update_date":"2023-02-09"}
{"id":"2110.08491","submitter":"Li Sheng","authors":"An-Min Li, Zhao Lian and Li Sheng","title":"Extremal metrics on toric manifolds and homogeneous toric bundles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we prove the Yau-Tian-Donaldson conjecture of the filtration\nversion for toric manifolds and homogeneous toric bundles.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:40:57 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08492","submitter":"Laszlo Babai","authors":"Laszlo Babai","title":"Asymmetric coloring of locally finite graphs and profinite permutation\n  groups: Tucker's Conjecture confirmed","comments":"V.2 updates: Choi 1972 ref. added, Sec. 8.3 (Mathieu groups) updated,\n  question about $M_{24}$ deleted from \"Open questions.\" New material: New Sec.\n  14 added, incl. two conjectures. Minor changes made for improved clarity\n  throughout the paper. None of the updates affects the main results or their\n  proofs","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An asymmetric coloring of a graph is a coloring of its vertices that is not\npreserved by any non-identity automorphism of the graph. The motion of a graph\nis the minimal degree of its automorphism group, i.e., the minimum number of\nelements displaced by any non-identity automorphism. In this paper we confirm\nTom Tucker's \"Infinite Motion Conjecture\" that connected locally finite graphs\nwith infinite motion admit an asymmetric 2-coloring. We infer this from the\nmore general result that the inverse limit of a sequence of finite permutation\ngroups with disjoint domains, viewed as a permutation group on the union of\nthose domains, admits an asymmetric 2-coloring. The proof is based on the study\nof the interaction between epimorphisms of finite permutation groups and the\nstructure of the setwise stabilizers of subsets of their domains.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:51:14 GMT"},{"version":"v2","created":"Sat, 13 Nov 2021 17:05:05 GMT"}],"update_date":"2021-11-16"}
{"id":"2110.08493","submitter":"Aouthithiye Barathwaj Sr Y","authors":"Sai Ganesh CS, Aouthithiye Barathwaj SR Y, R. Swethaa S, R.\n  Azhagumurugan","title":"Improvised Aerial Object Detection approach for YOLOv3 Using Weighted\n  Luminance","comments":"17 pages, 4 figures, Journal Expert Systems with Applications","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Aerial imaging plays a crucial role in navigation and data acquisition for\nunmanned aerial vehicles and satellite imaging systems. In recent days, the\nemployment of drones has been escalated in several applications that are not\nlimited to surveillance, delivery systems, aerial warfare, and agricultural\nactivities. Aerial imaging of ground targets is highly challenging because of\nvarious factors that affect light propagation through different mediums.\nSeveral convolutional neural network-based object detection algorithms that are\ndeveloped require more robustness when applied in the field of aerial imaging\nand remote sensing. In order to handle the adverse effects of light propagation\nwith respect to time and solar radiance, adaptive RGB filters for grayscale\nimaging based on weighted luminance are introduced that extensively solve the\nproblem of rayleigh scattering effect. Images of objects that are easily\ndiminished by rayleigh scattering are acquired in various timezones. The\nacquired images are labelled precisely and subjected to training and\nvalidation. The results show that the proposed method detects the object more\naccurately and efficiently than the traditional YOLOv3 approach.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:51:35 GMT"},{"version":"v2","created":"Fri, 26 Aug 2022 09:12:40 GMT"},{"version":"v3","created":"Tue, 20 Dec 2022 07:11:16 GMT"}],"update_date":"2022-12-21"}
{"id":"2110.08494","submitter":"Youngjin Kim","authors":"Young-Jin Kim","title":"Feedforward Control of DGs for a Self-healing Microgrid","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Network reconfiguration (NR) has recently received significant attention due\nto its potential to improve grid resilience by realizing self-healing\nmicrogrids (MGs). This paper proposes a new strategy for the real-time\nfrequency regulation of a reconfigurable MG, wherein the feedforward control of\nsynchronous and inverter-interfaced distributed generators (DGs) is achieved in\ncoordination with the operations of sectionalizing and tie switches (SWs). This\nenables DGs to compensate more quickly, and preemptively, for a forthcoming\nvariation in load demand due to NR-aided restoration. An analytical dynamic\nmodel of a reconfigurable MG is developed to analyze the MG frequency response\nto NR and hence determine the desired dynamics of the feedforward controllers,\nwith the integration of feedback loops for inertial response emulation and\nprimary and secondary frequency control. A small-signal analysis is conducted\nto analyze the contribution of the supplementary feedforward control to the MG\nfrequency regulation. Simulation case studies of NR-aided load restoration are\nalso performed. The results of the small-signal analysis and case studies\nconfirm that the proposed strategy is effective for improving the MG frequency\nregulation under various conditions of load demand, model parameter errors, and\ncommunication time delays.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:55:15 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08495","submitter":"Fuyan Ma","authors":"Ziyu Ma, Fuyan Ma, Bin Sun, Shutao Li","title":"Hybrid Mutimodal Fusion for Dimensional Emotion Recognition","comments":"8 pages, 2 figures, accepted by ACM MM2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we extensively present our solutions for the MuSe-Stress\nsub-challenge and the MuSe-Physio sub-challenge of Multimodal Sentiment\nChallenge (MuSe) 2021. The goal of MuSe-Stress sub-challenge is to predict the\nlevel of emotional arousal and valence in a time-continuous manner from\naudio-visual recordings and the goal of MuSe-Physio sub-challenge is to predict\nthe level of psycho-physiological arousal from a) human annotations fused with\nb) galvanic skin response (also known as Electrodermal Activity (EDA)) signals\nfrom the stressed people. The Ulm-TSST dataset which is a novel subset of the\naudio-visual textual Ulm-Trier Social Stress dataset that features German\nspeakers in a Trier Social Stress Test (TSST) induced stress situation is used\nin both sub-challenges. For the MuSe-Stress sub-challenge, we highlight our\nsolutions in three aspects: 1) the audio-visual features and the bio-signal\nfeatures are used for emotional state recognition. 2) the Long Short-Term\nMemory (LSTM) with the self-attention mechanism is utilized to capture complex\ntemporal dependencies within the feature sequences. 3) the late fusion strategy\nis adopted to further boost the model's recognition performance by exploiting\ncomplementary information scattered across multimodal sequences. Our proposed\nmodel achieves CCC of 0.6159 and 0.4609 for valence and arousal respectively on\nthe test set, which both rank in the top 3. For the MuSe-Physio sub-challenge,\nwe first extract the audio-visual features and the bio-signal features from\nmultiple modalities. Then, the LSTM module with the self-attention mechanism,\nand the Gated Convolutional Neural Networks (GCNN) as well as the LSTM network\nare utilized for modeling the complex temporal dependencies in the sequence.\nFinally, the late fusion strategy is used. Our proposed method also achieves\nCCC of 0.5412 on the test set, which ranks in the top 3.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:57:18 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08496","submitter":"Kun Lu","authors":"Kun Lu, Qingyang Zhou, Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Jianjun\n  Wu, and Honggang Zhang","title":"Rethinking Modern Communication from Semantic Coding to Semantic\n  Communication","comments":"Accepted by IEEE Wireless Communications","journal-ref":null,"doi":"10.1109/MWC.013.2100642","report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modern communications are usually designed to pursue a higher bit-level\nprecision and fewer bits while transmitting a message. This article rethinks\nthese two major features and introduces the concept and advantage of semantics\nthat characterizes a new kind of semantics-aware communication framework,\nincorporating both the semantic encoding and the semantic communication\nproblem. After analyzing the underlying defects of existing semantics-aware\ntechniques, we establish a confidence-based distillation mechanism for the\njoint semantics-noise coding (JSNC) problem and a reinforcement learning\n(RL)-powered semantic communication paradigm that endows a system the ability\nto convey the semantics instead of pursuing the bit level accuracy. On top of\nthese technical contributions, this work provides a new insight to understand\nhow the semantics are processed and represented in a semantics-aware coding and\ncommunication system, and verifies the significant benefits of doing so.\nTargeted on the next generation's semantics-aware communication, some critical\nconcerns and open challenges such as the information overhead, semantic\nsecurity and implementation cost are also discussed and envisioned.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:03:35 GMT"},{"version":"v2","created":"Thu, 17 Feb 2022 04:43:07 GMT"},{"version":"v3","created":"Wed, 8 Jun 2022 09:05:32 GMT"}],"update_date":"2022-06-09"}
{"id":"2110.08497","submitter":"Tien Mai","authors":"Anh Thuy Ta, Tien Thanh Dam, Tien Mai","title":"Robust Maximum Capture Facility Location under Random Utility\n  Maximization Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a robust version of the maximum capture facility location problem in\na competitive market, assuming that each customer chooses among all available\nfacilities according to a random utility maximization (RUM) model. We employ\nthe generalized extreme value (GEV) family of models and assume that the\nparameters of the RUM model are not given exactly but lie in convex uncertainty\nsets. The problem is to locate new facilities to maximize the worst-case\ncaptured user demand. We show that, interestingly, our robust model preserves\nthe monotonicity and submodularity from its deterministic counterpart, implying\nthat a simple greedy heuristic can guarantee a (1-1/e) approximation solution.\nWe further show the concavity of the objective function under the classical\nmultinomial logit (MNL) model, suggesting that an outer-approximation algorithm\ncan be used to solve the robust model under MNL to optimality. We conduct\nexperiments comparing our robust method to other deterministic and sampling\napproaches, using instances from different discrete choice models. Our results\nclearly demonstrate the advantages of our roust model in protecting the\ndecision-maker from bad-case scenarios.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:16:28 GMT"},{"version":"v2","created":"Sat, 11 Feb 2023 17:14:41 GMT"}],"update_date":"2023-02-14"}
{"id":"2110.08498","submitter":"Zhiqi Huang Prof.","authors":"Lu Huang, Zhiqi Huang, Huan Zhou, Zhuoyang Li","title":"The $S_8$ Tension in Light of Updated Redshift-Space Distortion Data and\n  PAge Approximation","comments":"6 pages, 3 figures; to appear on SCPMA","journal-ref":"SCIENCE CHINA Physics, Mechanics & Astronomy, 2022","doi":"10.1007/s11433-021-1838-1","report-no":"SYSU-SPA-2021","categories":"astro-ph.CO gr-qc hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the most prominent challenges to the standard Lambda cold dark matter\n($\\Lambda$CDM) cosmology is the tension between the structure growth parameter\n$S_8$ constrained by the cosmic microwave background (CMB) data and the smaller\none suggested by the cosmic shear data. Recent studies show that, for\n$\\Lambda$CDM cosmology, redshift-space distortion (RSD) data also prefers a\nsmaller $S_8$ that is $\\sim 2$-$3\\sigma$ lower than the CMB value, but the\nresult is sensitive to the cosmological model. In the present work we update\nthe RSD constraint on $S_8$ with the most up-to-date RSD data set where the\ncorrelation between data points are properly taken into account. To reduce the\nmodel dependence, we add in our Monte Carlo Markov Chain calculation the most\nup-to-date data sets of Type Ia supernovae (SN) and baryon acoustic\noscillations (BAO), whose correlation with RSD is also taken into account, to\nconstrain the background geometry. For $\\Lambda$CDM cosmology we find $S_8=\n0.812 \\pm 0.026$, which is $\\sim 2\\sigma$ larger than previous studies, and\nhence is consistent with the CMB constraint. By replacing $\\Lambda$CDM with the\nParameterization based on cosmic Age (PAge), an almost model-independent\ndescription of the late universe, we find that the RSD + SN + BAO constraint on\n$S_8$ is insensitive to the cosmological model.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:21:28 GMT"},{"version":"v2","created":"Mon, 3 Jan 2022 02:55:35 GMT"}],"update_date":"2022-01-04"}
{"id":"2110.08499","submitter":"Wen Xiao","authors":"Wen Xiao, Iz Beltagy, Giuseppe Carenini, Arman Cohan","title":"PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document\n  Summarization","comments":"19 pages, accepted at the main conference of ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce PRIMERA, a pre-trained model for multi-document representation\nwith a focus on summarization that reduces the need for dataset-specific\narchitectures and large amounts of fine-tuning labeled data. PRIMERA uses our\nnewly proposed pre-training objective designed to teach the model to connect\nand aggregate information across documents. It also uses efficient\nencoder-decoder transformers to simplify the processing of concatenated input\ndocuments. With extensive experiments on 6 multi-document summarization\ndatasets from 3 different domains on zero-shot, few-shot and full-supervised\nsettings, PRIMERA outperforms current state-of-the-art dataset-specific and\npre-trained models on most of these settings with large margins. The code and\npre-trained models can be found at \\url{https://github.com/allenai/PRIMER}.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:22:24 GMT"},{"version":"v2","created":"Thu, 17 Mar 2022 02:23:37 GMT"}],"update_date":"2022-03-18"}
{"id":"2110.08500","submitter":"Xiangming Meng","authors":"Xiangming Meng and Tomoyuki Obuchi and Yoshiyuki Kabashima","title":"On Model Selection Consistency of Lasso for High-Dimensional Ising\n  Models","comments":"AISTATS2023, camera-ready version","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We theoretically analyze the model selection consistency of least absolute\nshrinkage and selection operator (Lasso), both with and without\npost-thresholding, for high-dimensional Ising models. For random regular (RR)\ngraphs of size $p$ with regular node degree $d$ and uniform couplings\n$\\theta_0$, it is rigorously proved that Lasso \\textit{without\npost-thresholding} is model selection consistent in the whole paramagnetic\nphase with the same order of sample complexity $n=\\Omega{(d^3\\log{p})}$ as that\nof $\\ell_1$-regularized logistic regression ($\\ell_1$-LogR). This result is\nconsistent with the conjecture in Meng, Obuchi, and Kabashima 2021 using the\nnon-rigorous replica method from statistical physics and thus complements it\nwith a rigorous proof. For general tree-like graphs, it is demonstrated that\nthe same result as RR graphs can be obtained under mild assumptions of the\ndependency condition and incoherence condition. Moreover, we provide a rigorous\nproof of the model selection consistency of Lasso with post-thresholding for\ngeneral tree-like graphs in the paramagnetic phase without further assumptions\non the dependency and incoherence conditions. Experimental results agree well\nwith our theoretical analysis.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:23:02 GMT"},{"version":"v2","created":"Fri, 4 Feb 2022 13:50:19 GMT"},{"version":"v3","created":"Sat, 15 Oct 2022 03:56:05 GMT"},{"version":"v4","created":"Fri, 17 Feb 2023 06:20:44 GMT"}],"update_date":"2023-02-20"}
{"id":"2110.08501","submitter":"Pei Zhou","authors":"Pei Zhou, Karthik Gopalakrishnan, Behnam Hedayatnia, Seokhwan Kim, Jay\n  Pujara, Xiang Ren, Yang Liu, Dilek Hakkani-Tur","title":"Think Before You Speak: Explicitly Generating Implicit Commonsense\n  Knowledge for Response Generation","comments":"Accepted at ACL 2022 main conference. 16 pages, 9 figures, 9 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Implicit knowledge, such as common sense, is key to fluid human\nconversations. Current neural response generation (RG) models are trained to\ngenerate responses directly, omitting unstated implicit knowledge. In this\npaper, we present Think-Before-Speaking (TBS), a generative approach to first\nexternalize implicit commonsense knowledge (think) and use this knowledge to\ngenerate responses (speak). We expect that externalizing implicit knowledge\nallows more efficient learning, produces more informative responses, and\nenables more explainable models. We analyze different choices to collect\nknowledge-aligned dialogues, represent implicit knowledge, and transition\nbetween knowledge and dialogues. Empirical results show TBS models outperform\nend-to-end and knowledge-augmented RG baselines on most automatic metrics and\ngenerate more informative, specific, and commonsense-following responses, as\nevaluated by human annotators. TBS also generates knowledge that makes sense\nand is relevant to the dialogue around 85\\% of the time.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:27:12 GMT"},{"version":"v2","created":"Sun, 20 Mar 2022 15:59:40 GMT"},{"version":"v3","created":"Tue, 7 Jun 2022 21:50:00 GMT"}],"update_date":"2022-06-09"}
{"id":"2110.08502","submitter":"Zhun Lu","authors":"Chentao Tan and Zhun Lu","title":"Quark spin-orbit correlations in the pion meson in light-cone quark\n  model","comments":"9 pages, two figures, version accepted by PRD","journal-ref":null,"doi":"10.1103/PhysRevD.105.034004","report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the correlation between the quark spin and orbital angular momentum\ninside the pion meson. Similar to the case inside the nucleon, the longitudinal\nspin-orbit correlation $C_z^{q/\\pi}$ in pion meson can be expressed in terms of\nthe corresponding generalized parton distributions (GPDs) and generalized\ntransverse momentum distributions (GTMDs). This provides new information about\nthe spin structure of the pion. Using the wavefunctions of the pion in the\nlight-cone quark model and the overlap representation for GPDs and GTMDs, we\npresent the analytical results for the quark longitudinal spin-orbit\ncorrelation. We find that the GPD approach and the GTMD approach lead to the\nsame results. The numerical results is also obtained, showing that the\ncorrelation in pion is anti-aligned. In addition, we compare $C_z^{q/\\pi}$ from\nthe GPD approach and the GTMD approach, with $x$ and the transverse momentum\n$k_T$ unintegrated.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:38:55 GMT"},{"version":"v2","created":"Thu, 20 Jan 2022 02:23:13 GMT"}],"update_date":"2022-02-16"}
{"id":"2110.08503","submitter":"W{\\l}odzimierz Piechocki","authors":"Andrzej G\\'o\\'zd\\'z, Aleksandra P\\c{e}drak, and W{\\l}odzimierz\n  Piechocki","title":"Ascribing quantum system to Schwarzschild spacetime with naked\n  singularity","comments":"28 pages, one figure, version accepted for publication in Class.\n  Quant. Grav","journal-ref":null,"doi":"10.1088/1361-6382/ac6789","report-no":null,"categories":"gr-qc math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We quantize the Schwarzschild spacetime with naked singularity using the\naffine coherent states quantization method. The novelty of our approach is\nquantization of both temporal and spatial coordinates. Quantization smears the\ngravitational singularity indicated by the Kretschmann invariant avoiding its\nlocalization in the configuration space. This way we resolve the singularity\nproblem of considered spacetime at quantum level.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:39:41 GMT"},{"version":"v2","created":"Sat, 20 Nov 2021 11:56:31 GMT"},{"version":"v3","created":"Fri, 15 Apr 2022 05:46:12 GMT"}],"update_date":"2022-07-27"}
{"id":"2110.08504","submitter":"Lei Chen","authors":"Xiao-Ming Chen, Lei Chen, and Ya-Long Yan","title":"The rationality about the assumption that the signal and decoy states\n  are indistinguishable in decoy-state quantum key distribution","comments":"Even Eve can distinguish signal state from decoy state by the\n  Bayesian decision, the yield of signal state and decoy state is still the\n  same only if the photon number is the same. In our manuscript, the Eq.(14) is\n  wrong. That makes our analysis below is also wrong","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decoy-state quantum key distribution (QKD) has become the most efficient\nmethod to resist the photon-number-splitting (PNS) attack and estimate the\nsecure key rate. The decoy-state method has many assumptions, among which a\ncritical one is that an eavesdropper (Eve) cannot distinguish between the\nsignal and decoy states. However, a rigorous proof of the rationality about\nthis assumption is not yet available so far. In fact, due to the difference of\nphoton-number probability distribution between the signal and decoy states, Eve\nis able to distinguish the two states with a certain probability. In this work,\nwe adopt the Bayesian decision to distinguish the signal and decoy states in\none-decoy-state QKD, and perform different PNS attack strategies for the two\nstates according to the previous decision. The numerical simulations indicate\nthat the attack effect is not obvious or even failed. Thus, it is reasonable to\nassume that the signal and decoy states are indistinguishable in decoy-state\nQKD. In addition, we also provide the method to set the intensities of signal\nand decoy states properly, which can not only reduce the preparation cost and\nimprove the communication efficiency, but also avoid the attack from Eve using\nthe intensity difference between the signal and decoy states.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:44:24 GMT"},{"version":"v2","created":"Fri, 1 Apr 2022 02:52:32 GMT"}],"update_date":"2022-04-04"}
{"id":"2110.08505","submitter":"Yikun Zhang","authors":"Yikun Zhang and Yen-Chi Chen","title":"Mode and Ridge Estimation in Euclidean and Directional Product Spaces: A\n  Mean Shift Approach","comments":"51 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The set of local modes and the ridge lines estimated from a dataset are\nimportant summary characteristics of the data-generating distribution. In this\nwork, we consider estimating the local modes and ridges from point cloud data\nin a product space with two or more Euclidean/directional metric spaces.\nSpecifically, we generalize the well-known (subspace constrained) mean shift\nalgorithm to the product space setting and illuminate some pitfalls in such\ngeneralization. We derive the algorithmic convergence of the proposed method,\nprovide practical guidelines on the implementation, and demonstrate its\neffectiveness on both simulated and real datasets.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 07:49:30 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08506","submitter":"David Ruffolo","authors":"David Ruffolo (1), Nawin Ngampoopun (1), Yash R. Bhora (2), Panisara\n  Thepthong (3), Peera Pongkitiwanichakul (3), William H. Matthaeus (4) and\n  Rohit Chhiber (4,5) ((1) Mahidol University, (2) Wells International School,\n  (3) Kasetsart University, (4) University of Delaware, (5) NASA Goddard Space\n  Flight Center)","title":"Domains of Magnetic Pressure Balance in Parker Solar Probe Observations\n  of the Solar Wind","comments":"16 pages, 10 figures, accepted by the Astrophysical Journal","journal-ref":null,"doi":"10.3847/1538-4357/ac2ee3","report-no":null,"categories":"astro-ph.SR physics.space-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Parker Solar Probe (PSP) spacecraft is performing the first in situ\nexploration of the solar wind within 0.2 au of the Sun. Initial observations\nconfirmed the Alfv\\'enic nature of aligned fluctuations of the magnetic field B\nand velocity V in solar wind plasma close to the Sun, in domains of nearly\nconstant magnetic field magnitude $|{\\bf B}|$, i.e., approximate magnetic\npressure balance. Such domains are interrupted by particularly strong\nfluctuations, including but not limited to radial field (polarity) reversals,\nknown as switchbacks. It has been proposed that nonlinear Kelvin-Helmholtz\ninstabilities form near magnetic boundaries in the nascent solar wind leading\nto extensive shear-driven dynamics, strong turbulent fluctuations including\nswitchbacks, and mixing layers that involve domains of approximate magnetic\npressure balance. In this work we identify and analyze various aspects of such\ndomains using data from the first five PSP solar encounters. The filling\nfraction of domains, a measure of Alfv\\'enicity, varies from median values of\n90% within 0.2 au to 38% outside 0.9 au, with strong fluctuations. We find an\ninverse association between the mean domain duration and plasma $\\beta$. We\nexamine whether the mean domain duration is also related to the crossing time\nof spatial structures frozen into the solar wind flow for extreme cases of the\naspect ratio. Our results are inconsistent with long, thin domains aligned\nalong the radial or Parker spiral direction, and compatible with isotropic\ndomains, which is consistent with prior observations of isotropic density\nfluctuations or ``flocculae'' in the solar wind.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:13:41 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08507","submitter":"Shen Wang","authors":"Yunkai Li, Haotian Li, Beatriz Martinez-Pastor, Shen Wang","title":"Can CAV Reduce Non-Recurrent Urban Road Congestion?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A well-designed resilient and sustainable urban transportation system can\nrecover quickly from the non-recurrent road congestion (NRC), which is often\ncaused by en-route events (e.g., road closure due to car collisions). Existing\nsolutions, such as on-board navigation systems and temporary rerouting road\nsigns, are not effective due to delayed responses. Connected Autonomous\nVehicles (CAV) can be helpful in improving recurrent traffic as they can\nautonomously adjust their speed according to their real-time surrounding\ntraffic, sensed by vehicular communications. Preliminary simulation results in\nthis short paper show that CAV can also improve traffic when non-recurrent\ncongestion occurs. Other results in fuel consumption, CO2 emission, and\ntraditional traffic safety indicators are open for future discussions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:23:55 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08508","submitter":"Pratik Jawahar","authors":"Pratik Jawahar, Thea Aarrestad, Nadezda Chernyavskaya, Maurizio\n  Pierini, Kinga A. Wozniak, Jennifer Ngadiuba, Javier Duarte, Steven Tsan","title":"Improving Variational Autoencoders for New Physics Detection at the LHC\n  with Normalizing Flows","comments":"10 + 3 pages, 7 figures","journal-ref":"Front. Big Data 5, 803685 (2022)","doi":"10.3389/fdata.2022.803685","report-no":null,"categories":"hep-ph hep-ex physics.data-an","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate how to improve new physics detection strategies exploiting\nvariational autoencoders and normalizing flows for anomaly detection at the\nLarge Hadron Collider. As a working example, we consider the DarkMachines\nchallenge dataset. We show how different design choices (e.g., event\nrepresentations, anomaly score definitions, network architectures) affect the\nresult on specific benchmark new physics models. Once a baseline is\nestablished, we discuss how to improve the anomaly detection accuracy by\nexploiting normalizing flow layers in the latent space of the variational\nautoencoder.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:24:29 GMT"},{"version":"v2","created":"Sun, 12 Dec 2021 21:26:52 GMT"},{"version":"v3","created":"Wed, 15 Dec 2021 22:26:28 GMT"}],"update_date":"2023-02-07"}
{"id":"2110.08509","submitter":"Changhee Han Dr.","authors":"Shinji Nakazawa, Changhee Han, Joe Hasei, Ryuichi Nakahara, Toshifumi\n  Ozaki","title":"BAPGAN: GAN-based Bone Age Progression of Femur and Phalange X-ray\n  Images","comments":"6 pages, 5 figures, accepted to SPIE Medical Imaging 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Convolutional Neural Networks play a key role in bone age assessment for\ninvestigating endocrinology, genetic, and growth disorders under various\nmodalities and body regions. However, no researcher has tackled bone age\nprogression/regression despite its valuable potential applications:\nbone-related disease diagnosis, clinical knowledge acquisition, and museum\neducation. Therefore, we propose Bone Age Progression Generative Adversarial\nNetwork (BAPGAN) to progress/regress both femur/phalange X-ray images while\npreserving identity and realism. We exhaustively confirm the BAPGAN's clinical\npotential via Frechet Inception Distance, Visual Turing Test by two expert\northopedists, and t-Distributed Stochastic Neighbor Embedding.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:27:59 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08510","submitter":"Prathyush Potluri","authors":"Viswanatha Reddy G, Chaitanya B S N V, Prathyush P, Sumanth M,\n  Mrinalini C, Dileep Kumar P, Snehasis Mukherjee","title":"DFW-PP: Dynamic Feature Weighting based Popularity Prediction for Social\n  Media Content","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.IR cs.SI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The increasing popularity of social media platforms makes it important to\nstudy user engagement, which is a crucial aspect of any marketing strategy or\nbusiness model. The over-saturation of content on social media platforms has\npersuaded us to identify the important factors that affect content popularity.\nThis comes from the fact that only an iota of the humongous content available\nonline receives the attention of the target audience. Comprehensive research\nhas been done in the area of popularity prediction using several Machine\nLearning techniques. However, we observe that there is still significant scope\nfor improvement in analyzing the social importance of media content. We propose\nthe DFW-PP framework, to learn the importance of different features that vary\nover time. Further, the proposed method controls the skewness of the\ndistribution of the features by applying a log-log normalization. The proposed\nmethod is experimented with a benchmark dataset, to show promising results. The\ncode will be made publicly available at\nhttps://github.com/chaitnayabasava/DFW-PP.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:40:58 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08511","submitter":"Maurice Margenstern","authors":"Maurice Margenstern","title":"What can we learn from universal Turing machines?","comments":"35 pages, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.FL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the present paper, we construct what we call a pedagogical universal\nTuring machine. We try to understand which comparisons with biological\nphenomena can be deduced from its encoding and from its working.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:43:29 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08512","submitter":"Mehdi Bahrami","authors":"Mehdi Bahrami, N.C. Shrikanth, Yuji Mizobuchi, Lei Liu, Masahiro\n  Fukuyori, Wei-Peng Chen, Kazuki Munakata","title":"AugmentedCode: Examining the Effects of Natural Language Resources in\n  Code Retrieval Models","comments":"7 pages, 2 figures, 5 tables, 1 video","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Code retrieval is allowing software engineers to search codes through a\nnatural language query, which relies on both natural language processing and\nsoftware engineering techniques. There have been several attempts on code\nretrieval from searching snippet codes to function codes. In this paper, we\nintroduce Augmented Code (AugmentedCode) retrieval which takes advantage of\nexisting information within the code and constructs augmented programming\nlanguage to improve the code retrieval models' performance. We curated a large\ncorpus of Python and showcased the the framework and the results of augmented\nprogramming language which outperforms on CodeSearchNet and CodeBERT with a\nMean Reciprocal Rank (MRR) of 0.73 and 0.96, respectively. The outperformed\nfine-tuned augmented code retrieval model is published in HuggingFace at\nhttps://huggingface.co/Fujitsu/AugCode and a demonstration video is available\nat: https://youtu.be/mnZrUTANjGs .\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:44:48 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08513","submitter":"Ramin Hashemi","authors":"Ramin Hashemi, Samad Ali, Nurul Huda Mahmood, Matti Latva-aho","title":"Deep Reinforcement Learning for Practical Phase Shift Optimization in\n  RIS-aided MISO URLLC Systems","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the joint active/passive beamforming and channel blocklength (CBL)\nallocation in a non-ideal reconfigurable intelligent surface (RIS)-aided\nultra-reliable and low-latency communication (URLLC) system. The considered\nscenario is a finite blocklength (FBL) regime and the problem is solved by\nleveraging a novel deep reinforcement learning (DRL) algorithm named\ntwin-delayed deep deterministic policy gradient (TD3). First, assuming an\nindustrial automation system with multiple actuators, the\nsignal-to-interference-plus-noise ratio and achievable rate in the FBL regime\nare identified for each actuator in terms of the phase shift configuration\nmatrix at the RIS. Next, the joint active/passive beamforming and CBL\noptimization problem is formulated where the objective is to maximize the total\nachievable FBL rate in all actuators, subject to non-linear amplitude response\nat the RIS elements, BS transmit power budget, and total available CBL. Since\nthe amplitude response equality constraint is highly non-convex and non-linear,\nwe resort to employing an actor-critic policy gradient DRL algorithm based on\nTD3. The considered method relies on interacting RIS with the industrial\nautomation environment by taking actions which are the phase shifts at the RIS\nelements, CBL variables, and BS beamforming to maximize the expected observed\nreward, i.e., the total FBL rate. We assess the performance loss of the system\nwhen the RIS is non-ideal, i.e., with non-linear amplitude response, and\ncompare it with ideal RIS without impairments. The numerical results show that\noptimizing the RIS phase shifts, BS beamforming, and CBL variables via the\nproposed TD3 method is highly beneficial to improving the network total FBL\nrate as the proposed method with deterministic policy outperforms conventional\nmethods.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:45:12 GMT"},{"version":"v2","created":"Fri, 22 Oct 2021 09:31:29 GMT"},{"version":"v3","created":"Tue, 19 Apr 2022 09:15:59 GMT"}],"update_date":"2022-04-20"}
{"id":"2110.08514","submitter":"Eric Wallace","authors":"Eric Wallace, Adina Williams, Robin Jia, Douwe Kiela","title":"Analyzing Dynamic Adversarial Training Data in the Limit","comments":"ACL Findings 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To create models that are robust across a wide range of test inputs, training\ndatasets should include diverse examples that span numerous phenomena. Dynamic\nadversarial data collection (DADC), where annotators craft examples that\nchallenge continually improving models, holds promise as an approach for\ngenerating such diverse training sets. Prior work has shown that running DADC\nover 1-3 rounds can help models fix some error types, but it does not\nnecessarily lead to better generalization beyond adversarial test data. We\nargue that running DADC over many rounds maximizes its training-time benefits,\nas the different rounds can together cover many of the task-relevant phenomena.\nWe present the first study of longer-term DADC, where we collect 20 rounds of\nNLI examples for a small set of premise paragraphs, with both adversarial and\nnon-adversarial approaches. Models trained on DADC examples make 26% fewer\nerrors on our expert-curated test set compared to models trained on\nnon-adversarial data. Our analysis shows that DADC yields examples that are\nmore difficult, more lexically and syntactically diverse, and contain fewer\nannotation artifacts compared to non-adversarial examples.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:48:52 GMT"},{"version":"v2","created":"Mon, 26 Sep 2022 18:59:43 GMT"}],"update_date":"2022-09-28"}
{"id":"2110.08515","submitter":"Qingfeng Sun","authors":"Qingfeng Sun, Yujing Wang, Can Xu, Kai Zheng, Yaming Yang, Huang Hu,\n  Fei Xu, Jessica Zhang, Xiubo Geng, Daxin Jiang","title":"Multimodal Dialogue Response Generation","comments":"Accepted to ACL 2022 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV cs.LG cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Responsing with image has been recognized as an important capability for an\nintelligent conversational agent. Yet existing works only focus on exploring\nthe multimodal dialogue models which depend on retrieval-based methods, but\nneglecting generation methods. To fill in the gaps, we first present a\nmultimodal dialogue generation model, which takes the dialogue history as\ninput, then generates a textual sequence or an image as response. Learning such\na model often requires multimodal dialogues containing both texts and images\nwhich are difficult to obtain. Motivated by the challenge in practice, we\nconsider multimodal dialogue generation under a natural assumption that only\nlimited training examples are available. In such a low-resource setting, we\ndevise a novel conversational agent, Divter, in order to isolate parameters\nthat depend on multimodal dialogues from the entire generation model. By this\nmeans, the major part of the model can be learned from a large number of\ntext-only dialogues and text-image pairs respectively, then the whole\nparameters can be well fitted using the limited training examples. Extensive\nexperiments demonstrate our method achieves state-of-the-art results in both\nautomatic and human evaluation, and can generate informative text and\nhigh-resolution image responses.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:52:26 GMT"},{"version":"v2","created":"Tue, 29 Mar 2022 13:39:57 GMT"}],"update_date":"2022-03-30"}
{"id":"2110.08516","submitter":"Karen Mulleners","authors":"Fatma Ayancik, Karen Mulleners","title":"All you need is time to generalise the Goman-Khrabrov dynamic stall\n  model","comments":null,"journal-ref":null,"doi":"10.1017/jfm.2022.381","report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dynamic stall on airfoils negatively impacts their aerodynamic performance\nand can lead to structural damage. Accurate prediction and modelling of the\ndynamic stall loads are crucial for a more robust design of wings and blades\nthat operate under unsteady conditions susceptible to dynamic stall and for\nwidening the range of operation of these lifting surfaces. Many dynamic stall\nmodels rely on empirical parameters that need to be obtained from experimental\nor numerical data which limits their generalisability. Here, we introduce\nphysically derived times scales to replace the empirical parameters in the\nGoman-Khrabrov dynamic stall model. The physics-based time constants correspond\nto the dynamic stall delay and the decay rate of post-stall load fluctuations.\nThe dynamic stall delay is largely independent of the type of the motion, the\nReynolds number, and the airfoil geometry and is described as a function of a\nnormalised instantaneous pitch rate. The post-stall decay rate is independent\nof the motion kinematics and is directly related to the Strouhal number of the\npost-stall vortex shedding. The general validity of our physics-based time\nconstants is demonstrated using three sets of experimental dynamic stall data\ncovering various airfoil profiles, Reynolds numbers varying from 75'000 to\n1'000'000, and sinusoidal and ramp-up pitching motions. The use of\nphysics-based time constants generalises the Goman-Khrabrov dynamic stall model\nand extends its range of application.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 08:53:13 GMT"},{"version":"v2","created":"Sat, 22 Jan 2022 08:12:22 GMT"}],"update_date":"2022-05-24"}
{"id":"2110.08517","submitter":"Sojhal Ismail Khan","authors":"Sojhal Ismail Khan, Dominika Woszczyk, Chengzeng You, Soteris\n  Demetriou, Muhammad Naveed","title":"Characterizing Improper Input Validation Vulnerabilities of Mobile\n  Crowdsourcing Services","comments":null,"journal-ref":"Annual Computer Security Applications Conference (ACSAC '21),\n  December 6--10, 2021, USA","doi":"10.1145/3485832.3485888","report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Mobile crowdsourcing services (MCS), enable fast and economical data\nacquisition at scale and find applications in a variety of domains. Prior work\nhas shown that Foursquare and Waze (a location-based and a navigation MCS) are\nvulnerable to different kinds of data poisoning attacks. Such attacks can be\nupsetting and even dangerous especially when they are used to inject improper\ninputs to mislead users. However, to date, there is no comprehensive study on\nthe extent of improper input validation (IIV) vulnerabilities and the\nfeasibility of their exploits in MCSs across domains. In this work, we leverage\nthe fact that MCS interface with their participants through mobile apps to\ndesign tools and new methodologies embodied in an end-to-end feedback-driven\nanalysis framework which we use to study 10 popular and previously unexplored\nservices in five different domains. Using our framework we send tens of\nthousands of API requests with automatically generated input values to\ncharacterize their IIV attack surface. Alarmingly, we found that most of them\n(8/10) suffer from grave IIV vulnerabilities which allow an adversary to launch\ndata poisoning attacks at scale: 7400 spoofed API requests were successful in\nfaking online posts for robberies, gunshots, and other dangerous incidents,\nfaking fitness activities with supernatural speeds and distances among many\nothers. Lastly, we discuss easy to implement and deploy mitigation strategies\nwhich can greatly reduce the IIV attack surface and argue for their use as a\nnecessary complementary measure working toward trustworthy mobile crowdsourcing\nservices.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:02:39 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 02:40:34 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.08518","submitter":"Lei Cui","authors":"Junlong Li, Yiheng Xu, Lei Cui, Furu Wei","title":"MarkupLM: Pre-training of Text and Markup Language for Visually-rich\n  Document Understanding","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Multimodal pre-training with text, layout, and image has made significant\nprogress for Visually Rich Document Understanding (VRDU), especially the\nfixed-layout documents such as scanned document images. While, there are still\na large number of digital documents where the layout information is not fixed\nand needs to be interactively and dynamically rendered for visualization,\nmaking existing layout-based pre-training approaches not easy to apply. In this\npaper, we propose MarkupLM for document understanding tasks with markup\nlanguages as the backbone, such as HTML/XML-based documents, where text and\nmarkup information is jointly pre-trained. Experiment results show that the\npre-trained MarkupLM significantly outperforms the existing strong baseline\nmodels on several document understanding tasks. The pre-trained model and code\nwill be publicly available at https://aka.ms/markuplm.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:17:28 GMT"},{"version":"v2","created":"Fri, 11 Mar 2022 15:38:07 GMT"}],"update_date":"2022-03-14"}
{"id":"2110.08519","submitter":"Peera Pongkitiwanichakul","authors":"Peera Pongkitiwanichakul, David Ruffolo, Fan Guo, Senbei Du, Piyawat\n  Suetrong, Chutima Yannawa, Kirit Makwana, and Kittipat Malakit","title":"Role of Parallel Solenoidal Electric Field on Energy Conversion in 2.5D\n  Decaying Turbulence with a Guide Magnetic Field","comments":null,"journal-ref":null,"doi":"10.3847/1538-4357/ac2f45","report-no":null,"categories":"astro-ph.SR astro-ph.HE physics.plasm-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We perform 2.5D particle-in-cell simulations of decaying turbulence in the\npresence of a guide (out-of-plane) background magnetic field. The fluctuating\nmagnetic field initially consists of Fourier modes at low wavenumbers (long\nwavelengths). With time, the electromagnetic energy is converted to plasma\nkinetic energy (bulk flow+thermal energy) at the rate per unit volume of ${\\pp\nJ}\\cdot{\\pp E}$ for current density ${\\pp J}$ and electric field ${\\pp E}$.\nSuch decaying turbulence is well known to evolve toward a state with strongly\nintermittent plasma current. Here we decompose the electric field into\ncomponents that are irrotational, ${\\pp E}_{\\rm ir}$, and solenoidal\n(divergence-free), ${\\pp E}_{\\rm so}$. ${\\pp E}_{\\rm ir}$ is associated with\ncharge separation, and ${\\pp J}\\cdot{\\pp E}_{\\rm ir}$ is a rate of energy\ntransfer between ions and electrons with little net change in plasma kinetic\nenergy. Therefore, the net rate of conversion of electromagnetic energy to\nplasma kinetic energy is strongly dominated by ${\\pp J}\\cdot{\\pp E}_{\\rm so}$,\nand for a strong guide magnetic field, this mainly involves the component ${\\pp\nE}_{\\rm so,\\parallel}$ parallel to the total magnetic field ${\\pp B}$. We\nexamine various indicators of the spatial distribution of the energy transfer\nrate {\\bf J$_\\parallel\\cdot$E$_{so,\\parallel}$}, which relates to magnetic\nreconnection, the best of which are 1) the ratio of the out-of-plane electric\nfield to the in-plane magnetic field, 2) the out-of-plane component of the\nnon-ideal electric field, and 3) the magnitude of the estimate of current\nhelicity.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:18:09 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08520","submitter":"Neha Kennard","authors":"Neha Kennard, Tim O'Gorman, Rajarshi Das, Akshay Sharma, Chhandak\n  Bagchi, Matthew Clinton, Pranay Kumar Yelugam, Hamed Zamani, Andrew McCallum","title":"DISAPERE: A Dataset for Discourse Structure in Peer Review Discussions","comments":null,"journal-ref":null,"doi":"10.18653/v1/2022.naacl-main.89","report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  At the foundation of scientific evaluation is the labor-intensive process of\npeer review. This critical task requires participants to consume vast amounts\nof highly technical text. Prior work has annotated different aspects of review\nargumentation, but discourse relations between reviews and rebuttals have yet\nto be examined. We present DISAPERE, a labeled dataset of 20k sentences\ncontained in 506 review-rebuttal pairs in English, annotated by experts.\nDISAPERE synthesizes label sets from prior work and extends them to include\nfine-grained annotation of the rebuttal sentences, characterizing their context\nin the review and the authors' stance towards review arguments. Further, we\nannotate every review and rebuttal sentence. We show that discourse cues from\nrebuttals can shed light on the quality and interpretation of reviews. Further,\nan understanding of the argumentative strategies employed by the reviewers and\nauthors provides useful signal for area chairs and other decision makers.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:18:12 GMT"},{"version":"v2","created":"Mon, 7 Nov 2022 01:29:28 GMT"}],"update_date":"2022-11-08"}
{"id":"2110.08521","submitter":"Keyan Ding","authors":"Keyan Ding, Yi Liu, Xueyi Zou, Shiqi Wang, Kede Ma","title":"Locally Adaptive Structure and Texture Similarity for Image Quality\n  Assessment","comments":null,"journal-ref":"Proceedings of the 29th ACM International Conference on\n  Multimedia, 2021","doi":"10.1145/3474085.3475419","report-no":null,"categories":"eess.IV cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The latest advances in full-reference image quality assessment (IQA) involve\nunifying structure and texture similarity based on deep representations. The\nresulting Deep Image Structure and Texture Similarity (DISTS) metric, however,\nmakes rather global quality measurements, ignoring the fact that natural\nphotographic images are locally structured and textured across space and scale.\nIn this paper, we describe a locally adaptive structure and texture similarity\nindex for full-reference IQA, which we term A-DISTS. Specifically, we rely on a\nsingle statistical feature, namely the dispersion index, to localize texture\nregions at different scales. The estimated probability (of one patch being\ntexture) is in turn used to adaptively pool local structure and texture\nmeasurements. The resulting A-DISTS is adapted to local image content, and is\nfree of expensive human perceptual scores for supervised training. We\ndemonstrate the advantages of A-DISTS in terms of correlation with human data\non ten IQA databases and optimization of single image super-resolution methods.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:19:56 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08522","submitter":"Tian Shang","authors":"H. Zhang, X. Y. Zhu, Y. Xu, D. J. Gawryluk, W. Xie, S. L. Ju, M. Shi,\n  T. Shiroka, Q. F. Zhan, E. Pomjakushina, and T. Shang","title":"Giant magnetoresistance and topological Hall effect in the EuGa4\n  antiferromagnet","comments":"15 pages, 6 figures; to be appeared on JPCM","journal-ref":"J. Phys.: Condens. Matter 34, 034005 (2022)","doi":"10.1088/1361-648X/ac3102","report-no":null,"categories":"cond-mat.str-el cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report on systematic temperature- and magnetic field-dependent studies of\nthe EuGa$_4$ binary compound, which crystallizes in a centrosymmetric\ntetragonal BaAl$_4$-type structure with space group $I4/mmm$. The electronic\nproperties of EuGa$_4$ single crystals, with an antiferromagnetic (AFM)\ntransition at $T_\\mathrm{N} \\sim 16.4$ K, were characterized via electrical\nresistivity and magnetization measurements. A giant nonsaturating\nmagnetoresistance was observed at low temperatures, reaching $\\sim 7 \\times\n10^4$ % at 2 K in a magnetic field of 9 T. In the AFM state, EuGa$_4$ undergoes\na series of metamagnetic transitions in an applied magnetic field, clearly\nmanifested in its field-dependent electrical resistivity. Below $T_\\mathrm{N}$,\nin the $\\sim$4-7 T field range, we observe also a clear hump-like anomaly in\nthe Hall resistivity which is part of the anomalous Hall resistivity. We\nattribute such a hump-like feature to the topological Hall effect, usually\noccurring in noncentrosymmetric materials known to host topological spin\ntextures (as e.g., magnetic skyrmions). Therefore, the family of materials with\na tetragonal BaAl$_4$-type structure, to which EuGa$_4$ and EuAl$_4$ belong,\nseems to comprise suitable candidates on which one can study the interplay\namong correlated-electron phenomena (such as charge-density wave or exotic\nmagnetism) with topological spin textures and topologically nontrivial bands.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:20:27 GMT"}],"update_date":"2021-12-08"}
{"id":"2110.08523","submitter":"Walid Hachem","authors":"Arup Bose and Walid Hachem","title":"Spectral measure of empirical autocovariance matrices of high\n  dimensional Gaussian stationary processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST math.PR stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Consider the empirical autocovariance matrix at a given non-zero time lag\nbased on observations from a multivariate complex Gaussian stationary time\nseries. The spectral analysis of these autocovariance matrices can be useful in\ncertain statistical problems, such as those related to testing for white noise.\nWe study the behavior of their spectral measures in the asymptotic regime where\nthe time series dimension and the observation window length both grow to\ninfinity, and at the same rate. Following a general framework in the field of\nthe spectral analysis of large random non-Hermitian matrices, at first the\nprobabilistic behavior of the small singular values of the shifted versions of\nthe autocovariance matrix are obtained. This is then used to infer about the\nlarge sample behaviour of the empirical spectral measure of the autocovariance\nmatrices at any lag. Matrix orthogonal polynomials on the unit circle play a\ncrucial role in our study.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:27:08 GMT"},{"version":"v2","created":"Tue, 31 May 2022 09:16:29 GMT"}],"update_date":"2022-06-01"}
{"id":"2110.08524","submitter":"Brajesh Kumar Mani","authors":"Ravi Kumar, D. Angom, and B. K. Mani","title":"Fock-space perturbed relativistic coupled-cluster theory for electric\n  dipole polarizability of one-valence atomic systems: Application to Al and In","comments":"17 pages, 15 figures, 6 tables","journal-ref":null,"doi":"10.1103/PhysRevA.106.032801","report-no":null,"categories":"physics.atom-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We have developed a Fock-space relativistic coupled-cluster theory based\nmethod for the calculation of electric dipole polarizability of one-valence\natoms and ions. We employ this method to compute the ground-state and\nspin-orbit coupled excited state electric dipole polarizability of Al and In.\nTo check the quality of many-electron wavefunctions, we also compute the\nexcitation energies of some low-lying states of Al and In. The effects of Breit\ninteraction and QED corrections from the Uehling potential and the self-energy\nare included to improve the accuracy of $\\alpha$ further. Our recommended value\nof ground-state $\\alpha$ for both atoms are in good agreement with the previous\ntheoretical results. From our computations, we find that more than 65\\% of\ncontributions come from the dipolar mixing of $3p$($5p$) with $3d$($5d$) and\n$4s$($6s$)-electrons for Al(In). The largest Breit and QED contributions are\nfound to be 1.3\\% and 0.6\\%, respectively.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:28:13 GMT"}],"update_date":"2022-09-21"}
{"id":"2110.08525","submitter":"Nathan Schucher","authors":"Nathan Schucher, Siva Reddy, Harm de Vries","title":"The Power of Prompt Tuning for Low-Resource Semantic Parsing","comments":"ACL 2022 (main conference); updated results","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Prompt tuning has recently emerged as an effective method for adapting\npre-trained language models to a number of language understanding and\ngeneration tasks. In this paper, we investigate prompt tuning for semantic\nparsing -- the task of mapping natural language utterances onto formal meaning\nrepresentations. On the low-resource splits of Overnight and TOPv2, we find\nthat a prompt tuned T5-xl significantly outperforms its fine-tuned counterpart,\nas well as strong GPT-3 and BART baselines. We also conduct ablation studies\nacross different model scales and target representations, finding that, with\nincreasing model scale, prompt tuned T5 models improve at generating target\nrepresentations that are far from the pre-training distribution.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:33:09 GMT"},{"version":"v2","created":"Fri, 1 Apr 2022 13:59:36 GMT"}],"update_date":"2022-04-04"}
{"id":"2110.08526","submitter":"Yulei Wang","authors":"Yulei Wang, Xin Cheng, Mingde Ding, Quanming Lu","title":"Annihilation of Magnetic Islands at the Top of Solar Flare Loops","comments":null,"journal-ref":null,"doi":"10.3847/1538-4357/ac3142","report-no":null,"categories":"astro-ph.SR physics.plasm-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The dynamics of magnetic reconnection in the solar current sheet (CS) is\nstudied by high-resolution 2.5-dimensional MHD simulation. With the commence of\nmagnetic reconnection, a number of magnetic islands are formed intermittently\nand move quickly upward and downward along the CS. When colliding with the\nsemi-closed flux of flare loops, the downflow islands cause a second\nreconnection with a rate even comparable with that in the main CS. Though the\ntime-integrated magnetic energy release is still dominated by the reconnection\nin main CS, the second reconnection can release substantial magnetic energy,\nannihilating the main islands and generating secondary islands with various\nscales at the flare loop top. The distribution function of the flux of the\nsecond islands is found to follow a power-law varying from\n$f\\left(\\psi\\right)\\sim\\psi^{-1}$ (small scale) to $\\psi^{-2}$ (large scale),\nwhich seems to be independent with background plasma $\\beta$ and if including\nthermal conduction. However, the spatial scale and the strength of the\ntermination shocks driven by main reconnection outflows or islands decrease if\n$\\beta$ increases or thermal conduction is included. We suggest that the\nannihilation of magnetic islands at the flare loop top, which is not included\nin the standard flare model, plays a non-negligible role in releasing magnetic\nenergy to heat flare plasma and accelerate particles.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:33:27 GMT"},{"version":"v2","created":"Fri, 22 Oct 2021 00:29:12 GMT"},{"version":"v3","created":"Thu, 11 Nov 2021 03:22:59 GMT"}],"update_date":"2022-01-05"}
{"id":"2110.08527","submitter":"Nicholas Meade","authors":"Nicholas Meade, Elinor Poole-Dayan, Siva Reddy","title":"An Empirical Survey of the Effectiveness of Debiasing Techniques for\n  Pre-trained Language Models","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent work has shown pre-trained language models capture social biases from\nthe large amounts of text they are trained on. This has attracted attention to\ndeveloping techniques that mitigate such biases. In this work, we perform an\nempirical survey of five recently proposed bias mitigation techniques:\nCounterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace\nProjection, Self-Debias, and SentenceDebias. We quantify the effectiveness of\neach technique using three intrinsic bias benchmarks while also measuring the\nimpact of these techniques on a model's language modeling ability, as well as\nits performance on downstream NLU tasks. We experimentally find that: (1)\nSelf-Debias is the strongest debiasing technique, obtaining improved scores on\nall bias benchmarks; (2) Current debiasing techniques perform less consistently\nwhen mitigating non-gender biases; And (3) improvements on bias benchmarks such\nas StereoSet and CrowS-Pairs by using debiasing strategies are often\naccompanied by a decrease in language modeling ability, making it difficult to\ndetermine whether the bias mitigation was effective.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:40:30 GMT"},{"version":"v2","created":"Wed, 23 Mar 2022 03:47:26 GMT"},{"version":"v3","created":"Sun, 3 Apr 2022 00:08:13 GMT"}],"update_date":"2022-04-05"}
{"id":"2110.08528","submitter":"Yan Beygelzimer","authors":"Emmanuil Beygelzimer, Yan Beygelzimer","title":"Generalized estimates for thermal expansion of oxide scale in the range\n  from 0C to 1300C with account for movability of phase transitions in its\n  components","comments":"10 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The thermophysical properties of oxide scale, in the general case, are\naffected by the variation of the temperature of phase transitions (either\nmagnetic or polymorphic) in its components due to impurities, lattice defects,\ngrain sizes, etc. In this case, since the phase transition is usually\naccompanied by a sharp change in properties, even a small shift of such a\ncritical temperature can lead to large changes in properties in its vicinity.\nIn order to account for this effect, data known from various sources on the\ntrue coefficient of linear thermal expansion (CLTE) of w\\\"ustite , magnetite ,\nhematite , and metallic iron are generalized by approximating functions that\ninclude critical temperatures as variable parameters. It is shown that the true\nCLTE of magnetite at the same rated temperature can differ by up to 30%\ndepending on the position of the Curie point within the limits of its possible\n\"movability\". The proposed methods allow to take into account the critical\ntemperatures as adaptation parameters in engineering calculations of thermal\nexpansion of oxide scale. Generalized formulas for each scale component are\nalso given in a particular form for fixed (basic) values of critical\ntemperatures. The dependence of the true CLTE of oxide scale as a whole\n({\\alpha}sc) on the volume fraction of each component is proposed. It is shown\nby model computations that there are temperatures at which {\\alpha}sc is almost\nindependent of the scale composition, as well as areas of instability, where\n{\\alpha}sc depends significantly on the percentage of components. The results\nof the work are recommended to be used when mathematical modeling of production\nand processing of steel products in the presence of oxide scale on their\nsurface.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:43:14 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08529","submitter":"Dara Bahri","authors":"Dara Bahri and Hossein Mobahi and Yi Tay","title":"Sharpness-Aware Minimization Improves Language Model Generalization","comments":"ACL 2022 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The allure of superhuman-level capabilities has led to considerable interest\nin language models like GPT-3 and T5, wherein the research has, by and large,\nrevolved around new model architectures, training tasks, and loss objectives,\nalong with substantial engineering efforts to scale up model capacity and\ndataset size. Comparatively little work has been done to improve the\ngeneralization of these models through better optimization. In this work, we\nshow that Sharpness-Aware Minimization (SAM), a recently proposed optimization\nprocedure that encourages convergence to flatter minima, can substantially\nimprove the generalization of language models without much computational\noverhead. We show that SAM is able to boost performance on SuperGLUE, GLUE, Web\nQuestions, Natural Questions, Trivia QA, and TyDiQA, with particularly large\ngains when training data for these tasks is limited.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:44:06 GMT"},{"version":"v2","created":"Tue, 15 Mar 2022 23:33:33 GMT"}],"update_date":"2022-03-17"}
{"id":"2110.08530","submitter":"Nathalie T. Khalil","authors":"Giovanni Colombo, Nathalie T. Khalil, and Franco Rampazzo","title":"Rotational controls and uniqueness of constrained viscosity solutions of\n  Hamilton-Jacobi PDE","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The classical inward pointing condition (IPC) for a control system whose\nstate $x$ is constrained in the closure $C:=\\bar\\Omega$ of an open set $\\Omega$\nprescribes that at each point of the boundary $x\\in \\partial \\Omega$ the\nintersection between the dynamics and the interior of the tangent space of\n$\\bar \\Omega$ at $x$ is nonempty. Under this hypothesis, for every system\ntrajectory $x(.)$ on a time-interval $[0,T]$, possibly violating the\nconstraint, one can construct a new system trajectory $\\hat x(.)$ that\nsatisfies the constraint and whose distance from $x(.)$ is bounded by a\nquantity proportional to the maximal deviation\n$d:=\\mathrm{dist}(\\Omega,x([0,T]))$. When (IPC) is violated, the construction\nof such a constrained trajectory is not possible in general. However, for a\ncontrol system of the form $\\dot{x}=f_1(x)u_1+f_2(x)u_2$, we prove in this\npaper that a \"higher order\" inward pointing condition involving Lie brackets of\nthe dynamics' vector fields allows for a novel construction of a constrained\ntrajectory $\\hat x(.)$ whose distance from the reference trajectory $x(.)$ is\nbounded by a quantity proportional to $\\sqrt{d}$. Our method requires a further\nassumption of non-positiveness of a sort of curvature and is based on the\nimplementation of a suitable \"rotating\" control strategy. As an application, we\nestablish the continuity up to the boundary of the value function $V$ of a\nclassical optimal control problem, a continuity that allows to regard $V$ as\nthe unique constrained viscosity solution of the corresponding Bellman\nequation.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:46:48 GMT"},{"version":"v2","created":"Tue, 26 Oct 2021 10:06:42 GMT"}],"update_date":"2021-10-27"}
{"id":"2110.08531","submitter":"Cristian Alecsa","authors":"Cristian Daniel Alecsa","title":"A theoretical and empirical study of new adaptive algorithms with\n  additional momentum steps and shifted updates for stochastic non-convex\n  optimization","comments":"36 pages, 5 figures, 6 tables, 35 references","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the following paper we introduce new adaptive algorithms endowed with\nmomentum terms for stochastic non-convex optimization problems. We investigate\nthe almost sure convergence to stationary points, along with a finite-time\nhorizon analysis with respect to a chosen final iteration, and we also inspect\nthe worst-case iteration complexity. An estimate for the expectation of the\nsquared Euclidean norm of the gradient is given and the theoretical analysis\nthat we perform is assisted by various computational simulations for neural\nnetwork training.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:47:57 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08532","submitter":"Mehdi Rezagholizadeh","authors":"Mehdi Rezagholizadeh, Aref Jafari, Puneeth Salad, Pranav Sharma, Ali\n  Saheb Pasand, Ali Ghodsi","title":"Pro-KD: Progressive Distillation by Following the Footsteps of the\n  Teacher","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  With ever growing scale of neural models, knowledge distillation (KD)\nattracts more attention as a prominent tool for neural model compression.\nHowever, there are counter intuitive observations in the literature showing\nsome challenging limitations of KD. A case in point is that the best performing\ncheckpoint of the teacher might not necessarily be the best teacher for\ntraining the student in KD. Therefore, one important question would be how to\nfind the best checkpoint of the teacher for distillation? Searching through the\ncheckpoints of the teacher would be a very tedious and computationally\nexpensive process, which we refer to as the \\textit{checkpoint-search problem}.\nMoreover, another observation is that larger teachers might not necessarily be\nbetter teachers in KD which is referred to as the \\textit{capacity-gap}\nproblem. To address these challenging problems, in this work, we introduce our\nprogressive knowledge distillation (Pro-KD) technique which defines a smoother\ntraining path for the student by following the training footprints of the\nteacher instead of solely relying on distilling from a single mature\nfully-trained teacher. We demonstrate that our technique is quite effective in\nmitigating the capacity-gap problem and the checkpoint search problem. We\nevaluate our technique using a comprehensive set of experiments on different\ntasks such as image classification (CIFAR-10 and CIFAR-100), natural language\nunderstanding tasks of the GLUE benchmark, and question answering (SQuAD 1.1\nand 2.0) using BERT-based models and consistently got superior results over\nstate-of-the-art techniques.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:49:43 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08533","submitter":"Hiroaki Ishida","authors":"Hiroaki Ishida and Hisashi Kasuya","title":"Double sided torus actions and complex geometry on $SU(3)$","comments":"15 pages. Many changes","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV math.SG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct explicit complex structures and transversely K\\\"ahler\nholomorphic foliations on $SU(3)$ corresponding to variations of real quadratic\nequations on a complex quadric in $\\mathbb{C}^{6}$ as generalizations of\nleft-invariant complex structures on $SU(3) $ and an invariant K\\\"ahler\nstructure on the flag variety $SU(3)/T$.Consequently, we obtain orbifold\nvariants of the flag variety $SU(3)/T$ as quotients of double sided torus\nactions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:56:06 GMT"},{"version":"v2","created":"Sun, 20 Nov 2022 10:39:09 GMT"}],"update_date":"2022-11-22"}
{"id":"2110.08534","submitter":"Xisen Jin","authors":"Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai\n  Wei, Andrew Arnold, Xiang Ren","title":"Lifelong Pretraining: Continually Adapting Language Models to Emerging\n  Corpora","comments":"Accepted at NAACL 2022; fixed Figure 7 (a)(b) in Appendix","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pretrained language models (PTLMs) are typically learned over a large, static\ncorpus and further fine-tuned for various downstream tasks. However, when\ndeployed in the real world, a PTLM-based model must deal with data\ndistributions that deviate from what the PTLM was initially trained on. In this\npaper, we study a lifelong language model pretraining challenge where a PTLM is\ncontinually updated so as to adapt to emerging data. Over a domain-incremental\nresearch paper stream and a chronologically-ordered tweet stream, we\nincrementally pretrain a PTLM with different continual learning algorithms, and\nkeep track of the downstream task performance (after fine-tuning). We evaluate\nPTLM's ability to adapt to new corpora while retaining learned knowledge in\nearlier corpora. Our experiments show distillation-based approaches to be most\neffective in retaining downstream performance in earlier domains. The\nalgorithms also improve knowledge transfer, allowing models to achieve better\ndownstream performance over the latest data, and improve temporal\ngeneralization when distribution gaps exist between training and evaluation\nbecause of time. We believe our problem formulation, methods, and analysis will\ninspire future studies towards continual pretraining of language models.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 09:59:33 GMT"},{"version":"v2","created":"Thu, 12 May 2022 22:59:56 GMT"},{"version":"v3","created":"Tue, 19 Jul 2022 02:09:00 GMT"}],"update_date":"2022-07-20"}
{"id":"2110.08535","submitter":"Alexey Kalachev","authors":"D.A. Turaykhanov, D.O. Akat'ev, A.V. Vasiliev, F.M. Ablayev, A.A.\n  Kalachev","title":"Quantum hashing via single-photon states with orbital angular momentum","comments":"Accepted for publication in PRA","journal-ref":null,"doi":"10.1103/PhysRevA.104.052606","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum hashing is a promising generalization of the cryptographic hashing\nconcept on the quantum domain. In this paper, we construct a quantum hash via a\nsequence of single-photon states and perform a proof-of-principle experiment\nusing orbital angular momentum (OAM) encoding. We experimentally verify the\ncollision resistance of the quantum hash function depending on the number of\nqubits in use. Based on these results, we conclude that theoretical estimates\nare confirmed for different bases of OAM states and the proposed technique can\nbe useful in computational and cryptographic scenarios. The possibility of\nmultiplexing different OAM bases can make this approach even more efficient.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:02:01 GMT"}],"update_date":"2021-11-24"}
{"id":"2110.08536","submitter":"Qinyuan Ye","authors":"Qinyuan Ye, Madian Khabsa, Mike Lewis, Sinong Wang, Xiang Ren, Aaron\n  Jaech","title":"Sparse Distillation: Speeding Up Text Classification by Using Bigger\n  Student Models","comments":"NAACL 2022 camera-ready version. Code:\n  https://github.com/ink-usc/sparse-distillation. In v2, we updated the\n  performance of KD-BiLSTM baselines after fixing a bug","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Distilling state-of-the-art transformer models into lightweight student\nmodels is an effective way to reduce computation cost at inference time. The\nstudent models are typically compact transformers with fewer parameters, while\nexpensive operations such as self-attention persist. Therefore, the improved\ninference speed may still be unsatisfactory for real-time or high-volume use\ncases. In this paper, we aim to further push the limit of inference speed by\ndistilling teacher models into bigger, sparser student models -- bigger in that\nthey scale up to billions of parameters; sparser in that most of the model\nparameters are n-gram embeddings. Our experiments on six single-sentence text\nclassification tasks show that these student models retain 97% of the\nRoBERTa-Large teacher performance on average, and meanwhile achieve up to 600x\nspeed-up on both GPUs and CPUs at inference time. Further investigation reveals\nthat our pipeline is also helpful for sentence-pair classification tasks, and\nin domain generalization settings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:04:14 GMT"},{"version":"v2","created":"Mon, 25 Jul 2022 04:28:39 GMT"}],"update_date":"2022-07-26"}
{"id":"2110.08537","submitter":"Andrew Mironov","authors":"Andrew M. Mironov","title":"Verification of MPI programs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.PL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we outline an approach to verifying parallel programs. A new\nmathematical model of parallel programs is introduced. The introduced model is\nillustrated by the verification of the matrix multiplication MPI program.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:09:31 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08538","submitter":"Haoyue Shi","authors":"Haoyue Shi, Kevin Gimpel, Karen Livescu","title":"Substructure Distribution Projection for Zero-Shot Cross-Lingual\n  Dependency Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present substructure distribution projection (SubDP), a technique that\nprojects a distribution over structures in one domain to another, by projecting\nsubstructure distributions separately. Models for the target domains can be\nthen trained, using the projected distributions as soft silver labels. We\nevaluate SubDP on zero-shot cross-lingual dependency parsing, taking dependency\narcs as substructures: we project the predicted dependency arc distributions in\nthe source language(s) to target language(s), and train a target language\nparser to fit the resulting distributions. When an English treebank is the only\nannotation that involves human effort, SubDP achieves better unlabeled\nattachment score than all prior work on the Universal Dependencies v2.2 (Nivre\net al., 2020) test set across eight diverse target languages, as well as the\nbest labeled attachment score on six out of eight languages. In addition, SubDP\nimproves zero-shot cross-lingual dependency parsing with very few (e.g., 50)\nsupervised bitext pairs, across a broader range of target languages.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:12:28 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08539","submitter":"Stoyan Dimitrov","authors":"S. I. Dimitrov","title":"A tangent inequality over primes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we introduce a new diophantine inequality with prime numbers.\nLet $1<c<\\frac{10}{9}$. We show that for any fixed $\\theta>1$, every\nsufficiently large positive number $N$ and a small constant $\\varepsilon>0$,\nthe tangent inequality \\begin{equation*} \\big|p^c_1\\tan^\\theta(\\log p_1)+\np^c_2\\tan^\\theta(\\log p_2)+ p^c_3\\tan^\\theta(\\log p_3) -N\\big|<\\varepsilon\n\\end{equation*} has a solution in prime numbers $p_1,\\,p_2,\\,p_3$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:18:07 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08540","submitter":"Ali Pedram","authors":"Ali Pedram, Onur Pusuluk, \\\"Ozg\\\"ur E. M\\\"ustecapl{\\i}o\\u{g}lu","title":"Quantum Correlations in Jahn-Teller Molecular Systems Simulated with\n  Superconducting Circuits","comments":"9 pages, 6 figures","journal-ref":null,"doi":"10.1088/1742-6596/2191/1/012018","report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We explore quantum correlations, in particular, quantum entanglement, among\nvibrational phonon modes as well as between electronic and vibrational degrees\nof freedom in molecular systems, described by Jahn-Teller mechanism.\nSpecifically, to isolate and simplify the phonon-electron interactions in a\ncomplex molecular system, the basis of our discussions is taken to be the\nproposal of simulating two-frequency Jahn-Teller systems using superconducting\ncircuit quantum electrodynamics systems (circuit QED) by Tekin Dereli and\nco-workers in 2012. We evaluate the quantum correlations, in particular\nentanglement between the vibrational phonon modes, and present analytical\nexplanations using a single privileged Jahn-Teller mode picture. Furthermore,\nspin-orbit entanglement or quantum correlations between electronic and\nvibrational degrees of freedom are examined, too. We conclude by discussing\nexperimental feasibility to detect such quantum correlations, considering the\ndephasing and decoherence in state-of-the-art superconducting two-level systems\n(qubits).\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:22:44 GMT"}],"update_date":"2022-02-23"}
{"id":"2110.08541","submitter":"Peter Hornung","authors":"Peter Hornung","title":"Deformation of Framed Curves","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider curves $\\gamma : [0, 1]\\to\\mathbb{R}^3$ endowed with an adapted\northonormal frame $r : [0, 1]\\to SO(3)$. We are interested in the cases where\nthe frame is constrained, in the sense that one of its `curvatures' (i.e.,\noff-diagonal elements of $r'r^T$) is prescribed. One example is the Fr\\'enet\nframe. In order to deform such constrained framed curves without spoiling the\nconstraint, we proceed in two stages. First we deform the frame $r$ in a way\nthat is naturally compatible with the differential constraint, by interpreting\nit in terms of parallel transport on the sphere. The deformation of the base\ncurve $\\gamma$ is achieved in a second step, by means of a suitable\nreparametrization of the frame. We illustrate this deformation procedure by\nproviding some applications.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:37:13 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08542","submitter":"Tushar Khot","authors":"Tushar Khot and Kyle Richardson and Daniel Khashabi and Ashish\n  Sabharwal","title":"Hey AI, Can You Solve Complex Tasks by Talking to Agents?","comments":"Accepted to Findings of ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Training giant models from scratch for each complex task is resource- and\ndata-inefficient. To help develop models that can leverage existing systems, we\npropose a new challenge: Learning to solve complex tasks by communicating with\nexisting agents (or models) in natural language. We design a synthetic\nbenchmark, CommaQA, with three complex reasoning tasks (explicit, implicit,\nnumeric) designed to be solved by communicating with existing QA agents. For\ninstance, using text and table QA agents to answer questions such as \"Who had\nthe longest javelin throw from USA?\". We show that black-box models struggle to\nlearn this task from scratch (accuracy under 50\\%) even with access to each\nagent's knowledge and gold facts supervision. In contrast, models that learn to\ncommunicate with agents outperform black-box models, reaching scores of 100\\%\nwhen given gold decomposition supervision. However, we show that the challenge\nof learning to solve complex tasks by communicating with existing agents\n\\emph{without relying on any auxiliary supervision or data} still remains\nhighly elusive. We release CommaQA, along with a compositional generalization\ntest split, to advance research in this direction. Dataset and Code available\nat https://github.com/allenai/commaqa.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:37:34 GMT"},{"version":"v2","created":"Mon, 9 May 2022 18:15:36 GMT"}],"update_date":"2022-05-11"}
{"id":"2110.08543","submitter":"Dmytro Skorokhodov","authors":"V. F. Babenko, N. V. Parfinovych, D. S. Skorokhodov","title":"Optimal recovery of operator sequences","comments":null,"journal-ref":"Matematychni Studii. 56, 2 (2021) 193-207","doi":"10.30970/ms.56.2.193-207","report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we consider two recovery problems based on information given\nwith an error. First is the problem of optimal recovery of the class $W^T_q =\n\\{(t_1h_1,t_2h_2,\\ldots)\\in \\ell_q\\,:\\,\\|h\\|_q\\leqslant 1\\}$, where $1\\le q <\n\\infty$ and $t_1\\geqslant t_2\\geqslant \\ldots \\geqslant 0$, in the space\n$\\ell_q$ when in the capacity of inexact information we know either the first\n$n\\in\\mathbb{N}$ elements of a sequence with an error measured in the space of\nfinite sequences $\\ell_r^n$, $0 < r \\le \\infty$, or a sequence itself is known\nwith an error measured in the space $\\ell_r$. The second is the problem of\noptimal recovery of scalar products acting on Cartesian product $W^{T,S}_{p,q}$\nof classes $W^T_p$ and $W^S_q$, where $1 < p,q < \\infty$, $\\frac{1}{p} +\n\\frac{1}{q} = 1$ and $s_1\\ge s_2\\ge \\ldots \\ge 0$, when in the capacity of\ninexact information we know the first $n$ coordinate-wise products $x_1y_1,\nx_2y_2,\\ldots,x_ny_m$ of the element $x\\times y \\in W^{T,S}_{p,q}$ with an\nerror measured in the space $\\ell_r^n$. We find exact solutions to above\nproblems and construct optimal methods of recovery. As an application of our\nresults we consider the problem of optimal recovery of classes in Hilbert\nspaces by Fourier coefficients known with an error measured in the space\n$\\ell_p$ with $p > 2$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:39:09 GMT"}],"update_date":"2022-01-19"}
{"id":"2110.08544","submitter":"Zhihong Shao","authors":"Zhihong Shao and Minlie Huang","title":"Answering Open-Domain Multi-Answer Questions via a Recall-then-Verify\n  Framework","comments":"Accepted to ACL 2022 Main conference; Code available at\n  https://github.com/ZhihongShao/RECTIFY","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Open-domain questions are likely to be open-ended and ambiguous, leading to\nmultiple valid answers. Existing approaches typically adopt the\nrerank-then-read framework, where a reader reads top-ranking evidence to\npredict answers. According to our empirical analysis, this framework faces\nthree problems: first, to leverage a large reader under a memory constraint,\nthe reranker should select only a few relevant passages to cover diverse\nanswers, while balancing relevance and diversity is non-trivial; second, the\nsmall reading budget prevents the reader from accessing valuable retrieved\nevidence filtered out by the reranker; third, when using a generative reader to\npredict answers all at once based on all selected evidence, whether a valid\nanswer will be predicted also pathologically depends on the evidence of some\nother valid answer(s). To address these issues, we propose to answer\nopen-domain multi-answer questions with a recall-then-verify framework, which\nseparates the reasoning process of each answer so that we can make better use\nof retrieved evidence while also leveraging large models under the same memory\nconstraint. Our framework achieves state-of-the-art results on two multi-answer\ndatasets, and predicts significantly more gold answers than a rerank-then-read\nsystem that uses an oracle reranker.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:48:10 GMT"},{"version":"v2","created":"Tue, 1 Mar 2022 07:12:25 GMT"}],"update_date":"2022-03-02"}
{"id":"2110.08545","submitter":"Yingzhu Zhao","authors":"Yingzhu Zhao, Chongjia Ni, Cheung-Chi Leung, Shafiq Joty, Eng Siong\n  Chng, Bin Ma","title":"A Unified Speaker Adaptation Approach for ASR","comments":"Accepted by EMNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.LG cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transformer models have been used in automatic speech recognition (ASR)\nsuccessfully and yields state-of-the-art results. However, its performance is\nstill affected by speaker mismatch between training and test data. Further\nfinetuning a trained model with target speaker data is the most natural\napproach for adaptation, but it takes a lot of compute and may cause\ncatastrophic forgetting to the existing speakers. In this work, we propose a\nunified speaker adaptation approach consisting of feature adaptation and model\nadaptation. For feature adaptation, we employ a speaker-aware persistent memory\nmodel which generalizes better to unseen test speakers by making use of speaker\ni-vectors to form a persistent memory. For model adaptation, we use a novel\ngradual pruning method to adapt to target speakers without changing the model\narchitecture, which to the best of our knowledge, has never been explored in\nASR. Specifically, we gradually prune less contributing parameters on model\nencoder to a certain sparsity level, and use the pruned parameters for\nadaptation, while freezing the unpruned parameters to keep the original model\nperformance. We conduct experiments on the Librispeech dataset. Our proposed\napproach brings relative 2.74-6.52% word error rate (WER) reduction on general\nspeaker adaptation. On target speaker adaptation, our method outperforms the\nbaseline with up to 20.58% relative WER reduction, and surpasses the finetuning\nmethod by up to relative 2.54%. Besides, with extremely low-resource adaptation\ndata (e.g., 1 utterance), our method could improve the WER by relative 6.53%\nwith only a few epochs of training.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:48:52 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08546","submitter":"Evgenii Ievlev","authors":"E. Ievlev, A. Yung","title":"Critical Non-Abelian Vortex and Holography for Little String Theory","comments":"34 pages + appendices, 1 figure","journal-ref":null,"doi":"10.1103/PhysRevD.104.114033","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It has been shown that non-Abelian vortex string supported in four\ndimensional (4D) ${\\mathcal N}=2$ supersymmetric QCD (SQCD) with the U(2) gauge\ngroup and $N_f = 4$ quark flavors becomes a critical superstring. This string\npropagates in the ten dimensional space formed by a product of the flat 4D\nspace and an internal space given by a Calabi-Yau non-compact threefold,\nnamely, the conifold. The spectrum of closed string states of the associated\nstring theory was obtained using the equivalence between the critical string on\nthe conifold and the non-critical string on the semi-infinite cigar described\nby SL($2, \\mathbb{R}$)/U(1) Wess-Zumino-Novikov-Witten model. This spectrum was\nidentified with the spectrum of hadrons in 4D ${\\mathcal N}=2$ SQCD. In order\nto describe effective interactions of these 4D hadrons in this paper we study\ncorrelation functions of normalizable vertex operators localized near the tip\nof the SL($2, \\mathbb{R}$)/U(1) cigar. We also compare our solitonic string\napproach to the gauge-string duality to the AdS/CFT-type holography for little\nstring theories (LSTs). The latter relates off mass-shell correlation functions\non the field theory side to correlation functions of non-normalizable vertex\noperators on the cigar. We show that in most channels holographic approach\nworks in our theory because normalizable and non-normalizable vertex operators\nwith the same conformal dimension are related due to the reflection from the\ntip of the cigar. However, we find that holography does not work for lightest\nhadrons with given baryonic charge.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:56:36 GMT"}],"update_date":"2022-01-12"}
{"id":"2110.08547","submitter":"Guanhua Chen","authors":"Guanhua Chen, Shuming Ma, Yun Chen, Dongdong Zhang, Jia Pan, Wenping\n  Wang, Furu Wei","title":"Towards Making the Most of Multilingual Pretraining for Zero-Shot Neural\n  Machine Translation","comments":"Accepted to ACL 2022. Code will be available at\n  [https://github.com/ghchen18/acl22-sixtp]","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper demonstrates that multilingual pretraining and multilingual\nfine-tuning are both critical for facilitating cross-lingual transfer in\nzero-shot translation, where the neural machine translation (NMT) model is\ntested on source languages unseen during supervised training. Following this\nidea, we present SixT+, a strong many-to-English NMT model that supports 100\nsource languages but is trained with a parallel dataset in only six source\nlanguages. SixT+ initializes the decoder embedding and the full encoder with\nXLM-R large and then trains the encoder and decoder layers with a simple\ntwo-stage training strategy. SixT+ achieves impressive performance on\nmany-to-English translation. It significantly outperforms CRISS and m2m-100,\ntwo strong multilingual NMT systems, with an average gain of 7.2 and 5.0 BLEU\nrespectively. Additionally, SixT+ offers a set of model parameters that can be\nfurther fine-tuned to other unsupervised tasks. We demonstrate that adding\nSixT+ initialization outperforms state-of-the-art explicitly designed\nunsupervised NMT models on Si<->En and Ne<->En by over 1.2 average BLEU. When\napplied to zero-shot cross-lingual abstractive summarization, it produces an\naverage performance gain of 12.3 ROUGE-L over mBART-ft. We conduct detailed\nanalyses to understand the key ingredients of SixT+, including multilinguality\nof the auxiliary parallel data, positional disentangled encoder, and the\ncross-lingual transferability of its encoder.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:59:39 GMT"},{"version":"v2","created":"Wed, 13 Apr 2022 12:29:30 GMT"}],"update_date":"2022-04-14"}
{"id":"2110.08548","submitter":"Pavel Galashin","authors":"Pavel Galashin","title":"Totally nonnegative critical varieties","comments":"31 pages, 11 figures. Final version to appear in IMRN","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math-ph math.CO math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study totally nonnegative parts of critical varieties in the Grassmannian.\nWe show that each totally nonnegative critical variety Crit$^{\\ge0}_f$ is the\nimage of an affine poset cyclohedron under a continuous map and use this map to\ndefine a boundary stratification of Crit$^{\\ge0}_f$. For the case of the\ntop-dimensional positroid cell, we show that the totally nonnegative critical\nvariety Crit$^{\\ge0}_{k,n}$ is homeomorphic to the second hypersimplex\n$\\Delta_{2,n}$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:08:09 GMT"},{"version":"v2","created":"Tue, 14 Mar 2023 18:04:56 GMT"}],"update_date":"2023-03-16"}
{"id":"2110.08549","submitter":"Michael P. Evans","authors":"Michael P. Evans, Simon H. Tindemans and David Angeli","title":"Flexibility Framework with Recovery Guarantees for Aggregated Energy\n  Storage Devices","comments":null,"journal-ref":"IEEE Transactions on Smart Grid, vol. 13, no. 5, pp. 3519-3531,\n  Sept. 2022","doi":"10.1109/TSG.2022.3173900","report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a framework for the procurement of flexibility reserve\nfrom aggregated storage fleets. It allows for arbitrary tree structures of\naggregation hierarchy, as well as easily implementable disaggregation via\nbroadcast dispatch. By coupling discharge and recovery modes, the proposed\nframework enables full-cycle capacity to be procured ahead of real time, with\nguaranteed recovery and exact accounting for losses. The set of feasible\ndischarging requests is exactly encoded, so that there is no reduction in the\nability to meet discharging signals, and recovery capabilities are parametrised\nas a single virtual battery. Included in this paper is a numerical\ndemonstration of the construction of the constituent curves of the framework\nand the approach is also benchmarked against relevant alternatives.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:17:48 GMT"},{"version":"v2","created":"Fri, 4 Mar 2022 23:00:47 GMT"},{"version":"v3","created":"Sat, 7 May 2022 09:38:12 GMT"}],"update_date":"2022-12-14"}
{"id":"2110.08550","submitter":"Ilya Makarov A","authors":"I. A. Makarov (1), S. G. Ovchinnikov (1) ((1) Kirensky Institute of\n  Physics, Federal Research Center KSC SB RAS, Krasnoyarsk, Russia)","title":"The enhanced s*-wave component of the superconducting gap in the\n  overdoped HTSC cuprates with orthorhombic distortion","comments":"17 pages, 11 figures","journal-ref":null,"doi":"10.1016/j.physleta.2022.128226","report-no":null,"categories":"cond-mat.supr-con cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, the concentration and temperature dependences of the\nsuperconducting gap of the HTSC cuprate in the orthorhombic phase are obtained\nwithin the framework of the Hubbard model taking into account the exchange\nmechanism of pairing. The enhanced s*-wave component of the superconducting gap\nagainst the background of the prevailing d-wave component in a narrow range of\nhole concentrations in the overdoped region is found. To elucidate the reasons\nfor such unusual behavior the electronic structure of the low-energy\nexcitations and the structure of the contributions of the pair states to the\nsuperconducting gap in momentum space were investigated at different doping. It\nis shown that the presence of a shallow pocket in the region of the maximum\nvalue of the s*-wave component of the gap results in different symmetry of the\nsuperconducting gap in different regions of the k-space and an increase in the\ns*-wave component.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:21:25 GMT"}],"update_date":"2022-06-22"}
{"id":"2110.08551","submitter":"Chenhe Dong","authors":"Chenhe Dong, Yaliang Li, Ying Shen, Minghui Qiu","title":"HRKD: Hierarchical Relational Knowledge Distillation for Cross-domain\n  Language Model Compression","comments":"EMNLP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  On many natural language processing tasks, large pre-trained language models\n(PLMs) have shown overwhelming performances compared with traditional neural\nnetwork methods. Nevertheless, their huge model size and low inference speed\nhave hindered the deployment on resource-limited devices in practice. In this\npaper, we target to compress PLMs with knowledge distillation, and propose a\nhierarchical relational knowledge distillation (HRKD) method to capture both\nhierarchical and domain relational information. Specifically, to enhance the\nmodel capability and transferability, we leverage the idea of meta-learning and\nset up domain-relational graphs to capture the relational information across\ndifferent domains. And to dynamically select the most representative prototypes\nfor each domain, we propose a hierarchical compare-aggregate mechanism to\ncapture hierarchical relationships. Extensive experiments on public\nmulti-domain datasets demonstrate the superior performance of our HRKD method\nas well as its strong few-shot learning ability. For reproducibility, we\nrelease the code at https://github.com/cheneydon/hrkd.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:23:02 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08552","submitter":"Dejiao Zhang","authors":"Dejiao Zhang, Wei Xiao, Henghui Zhu, Xiaofei Ma, Andrew O. Arnold","title":"Virtual Augmentation Supported Contrastive Learning of Sentence\n  Representations","comments":"8 pages, 3 figures, 3 tables","journal-ref":"Findings of ACL 2022","doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Despite profound successes, contrastive representation learning relies on\ncarefully designed data augmentations using domain specific knowledge. This\nchallenge is magnified in natural language processing where no general rules\nexist for data augmentation due to the discrete nature of natural language. We\ntackle this challenge by presenting a Virtual augmentation Supported\nContrastive Learning of sentence representations (VaSCL). Originating from the\ninterpretation that data augmentation essentially constructs the neighborhoods\nof each training instance, we in turn utilize the neighborhood to generate\neffective data augmentations. Leveraging the large training batch size of\ncontrastive learning, we approximate the neighborhood of an instance via its\nK-nearest in-batch neighbors in the representation space. We then define an\ninstance discrimination task regarding this neighborhood and generate the\nvirtual augmentation in an adversarial training manner. We access the\nperformance of VaSCL on a wide range of downstream tasks, and set a new\nstate-of-the-art for unsupervised sentence representation learning.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:29:03 GMT"},{"version":"v2","created":"Fri, 25 Feb 2022 02:41:51 GMT"}],"update_date":"2022-02-28"}
{"id":"2110.08553","submitter":"Marjeta Kramar Fijav\\v{z}","authors":"Klaus-Jochen Engel and Marjeta Kramar Fijav\\v{z}","title":"Flows on Metric Graphs with General Boundary Conditions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this note we study the generation of $C_0$-semigroups by first order\ndifferential operators on $\\mathrm{L}^p (\\mathbb{R}_+,\\mathbb{C}^{\\ell})\\times\n\\mathrm{L}^p ([0,1],\\mathbb{C}^{m})$ with general boundary conditions. In many\ncases we are able to characterize the generation property in terms of the\ninvertibility of a matrix associated to the boundary conditions. The abstract\nresults are used to study well-posedness of transport equations on non-compact\nmetric graphs.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:34:40 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08554","submitter":"Iacopo Poli","authors":"Julien Launay, Elena Tommasone, Baptiste Pannier, Fran\\c{c}ois\n  Boniface, Am\\'elie Chatelain, Alessandro Cappelli, Iacopo Poli, Djam\\'e\n  Seddah","title":"PAGnol: An Extra-Large French Generative Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Access to large pre-trained models of varied architectures, in many different\nlanguages, is central to the democratization of NLP. We introduce PAGnol, a\ncollection of French GPT models. Using scaling laws, we efficiently train\nPAGnol-XL (1.5B parameters) with the same computational budget as CamemBERT, a\nmodel 13 times smaller. PAGnol-XL is the largest model trained to date for the\nFrench language. We plan to train increasingly large and performing versions of\nPAGnol, exploring the capabilities of French extreme-scale models.\n  For this first release, we focus on the pre-training and scaling calculations\nunderlining PAGnol. We fit a scaling law for compute for the French language,\nand compare it with its English counterpart. We find the pre-training dataset\nsignificantly conditions the quality of the outputs, with common datasets such\nas OSCAR leading to low-quality offensive text. We evaluate our models on\ndiscriminative and generative tasks in French, comparing to other\nstate-of-the-art French and multilingual models, and reaching the state of the\nart in the abstract summarization task. Our research was conducted on the\npublic GENCI Jean Zay supercomputer, and our models up to the Large are made\npublicly available.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:44:23 GMT"}],"update_date":"2022-10-26"}
{"id":"2110.08555","submitter":"Jun Yan","authors":"Jun Yan, Yang Xiao, Sagnik Mukherjee, Bill Yuchen Lin, Robin Jia,\n  Xiang Ren","title":"On the Robustness of Reading Comprehension Models to Entity Renaming","comments":"Accepted to NAACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the robustness of machine reading comprehension (MRC) models to\nentity renaming -- do models make more wrong predictions when the same\nquestions are asked about an entity whose name has been changed? Such failures\nimply that models overly rely on entity information to answer questions, and\nthus may generalize poorly when facts about the world change or questions are\nasked about novel entities. To systematically audit this issue, we present a\npipeline to automatically generate test examples at scale, by replacing entity\nnames in the original test sample with names from a variety of sources, ranging\nfrom names in the same test set, to common names in life, to arbitrary strings.\nAcross five datasets and three pretrained model architectures, MRC models\nconsistently perform worse when entities are renamed, with particularly large\naccuracy drops on datasets constructed via distant supervision. We also find\nlarge differences between models: SpanBERT, which is pretrained with span-level\nmasking, is more robust than RoBERTa, despite having similar accuracy on\nunperturbed test data. We further experiment with different masking strategies\nas the continual pretraining objective and find that entity-based masking can\nimprove the robustness of MRC models.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:46:32 GMT"},{"version":"v2","created":"Wed, 4 May 2022 11:22:31 GMT"}],"update_date":"2022-05-05"}
{"id":"2110.08556","submitter":"Zihang Wan","authors":"Zihang Wan","title":"Multi-View Stereo Network with attention thin volume","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an efficient multi-view stereo (MVS) network for infering depth\nvalue from multiple RGB images. Recent studies have shown that mapping the\ngeometric relationship in real space to neural network is an essential topic of\nthe MVS problem. Specifically, these methods focus on how to express the\ncorrespondence between different views by constructing a nice cost volume. In\nthis paper, we propose a more complete cost volume construction approach based\non absorbing previous experience. First of all, we introduce the self-attention\nmechanism to fully aggregate the dominant information from input images and\naccurately model the long-range dependency, so as to selectively aggregate\nreference features. Secondly, we introduce the group-wise correlation to\nfeature aggregation, which greatly reduces the memory and calculation burden.\nMeanwhile, this method enhances the information interaction between different\nfeature channels. With this approach, a more lightweight and efficient cost\nvolume is constructed. Finally we follow the coarse to fine strategy and refine\nthe depth sampling range scale by scale with the help of uncertainty\nestimation. We further combine the previous steps to get the attention thin\nvolume. Quantitative and qualitative experiments are presented to demonstrate\nthe performance of our model.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:51:23 GMT"},{"version":"v2","created":"Sat, 16 Jul 2022 06:28:37 GMT"}],"update_date":"2022-07-19"}
{"id":"2110.08557","submitter":"Anda Cheng","authors":"Anda Cheng, Jiaxing Wang, Xi Sheryl Zhang, Qiang Chen, Peisong Wang,\n  Jian Cheng","title":"DPNAS: Neural Architecture Search for Deep Learning with Differential\n  Privacy","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training deep neural networks (DNNs) for meaningful differential privacy (DP)\nguarantees severely degrades model utility. In this paper, we demonstrate that\nthe architecture of DNNs has a significant impact on model utility in the\ncontext of private deep learning, whereas its effect is largely unexplored in\nprevious studies. In light of this missing, we propose the very first framework\nthat employs neural architecture search to automatic model design for private\ndeep learning, dubbed as DPNAS. To integrate private learning with architecture\nsearch, we delicately design a novel search space and propose a DP-aware method\nfor training candidate models. We empirically certify the effectiveness of the\nproposed framework. The searched model DPNASNet achieves state-of-the-art\nprivacy/utility trade-offs, e.g., for the privacy budget of $(\\epsilon,\n\\delta)=(3, 1\\times10^{-5})$, our model obtains test accuracy of $98.57\\%$ on\nMNIST, $88.09\\%$ on FashionMNIST, and $68.33\\%$ on CIFAR-10. Furthermore, by\nstudying the generated architectures, we provide several intriguing findings of\ndesigning private-learning-friendly DNNs, which can shed new light on model\ndesign for deep learning with differential privacy.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:56:39 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 03:20:36 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.08558","submitter":"Muhammad Umair Haider Dogar","authors":"Shehryar Malik, Muhammad Umair Haider, Omer Iqbal, Murtaza Taj","title":"Neural Network Pruning Through Constrained Reinforcement Learning","comments":"Submitted to ICASSP 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Network pruning reduces the size of neural networks by removing (pruning)\nneurons such that the performance drop is minimal. Traditional pruning\napproaches focus on designing metrics to quantify the usefulness of a neuron\nwhich is often quite tedious and sub-optimal. More recent approaches have\ninstead focused on training auxiliary networks to automatically learn how\nuseful each neuron is however, they often do not take computational limitations\ninto account. In this work, we propose a general methodology for pruning neural\nnetworks. Our proposed methodology can prune neural networks to respect\npre-defined computational budgets on arbitrary, possibly non-differentiable,\nfunctions. Furthermore, we only assume the ability to be able to evaluate these\nfunctions for different inputs, and hence they do not need to be fully\nspecified beforehand. We achieve this by proposing a novel pruning strategy via\nconstrained reinforcement learning algorithms. We prove the effectiveness of\nour approach via comparison with state-of-the-art methods on standard image\nclassification datasets. Specifically, we reduce 83-92.90 of total parameters\non various variants of VGG while achieving comparable or better performance\nthan that of original networks. We also achieved 75.09 reduction in parameters\non ResNet18 without incurring any loss in accuracy.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:57:38 GMT"},{"version":"v2","created":"Thu, 28 Oct 2021 22:38:14 GMT"}],"update_date":"2021-11-01"}
{"id":"2110.08559","submitter":"Moussa Kamal Eddine","authors":"Moussa Kamal Eddine and Guokan Shang and Antoine J.-P. Tixier and\n  Michalis Vazirgiannis","title":"FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metricsfor\n  Automatic Text Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Fast and reliable evaluation metrics are key to R&D progress. While\ntraditional natural language generation metrics are fast, they are not very\nreliable. Conversely, new metrics based on large pretrained language models are\nmuch more reliable, but require significant computational resources. In this\npaper, we propose FrugalScore, an approach to learn a fixed, low cost version\nof any expensive NLG metric, while retaining most of its original performance.\nExperiments with BERTScore and MoverScore on summarization and translation show\nthat FrugalScore is on par with the original metrics (and sometimes better),\nwhile having several orders of magnitude less parameters and running several\ntimes faster. On average over all learned metrics, tasks, and variants,\nFrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35\ntimes less parameters than the original metrics. We make our trained metrics\npublicly available, to benefit the entire NLP community and in particular\nresearchers and practitioners with limited resources.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 11:59:48 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08560","submitter":"Gamal G.L. Nashed","authors":"G.G.L. Nashed and Shin'ichi Nojiri","title":"Black holes with Lagrange multiplier and potential in mimetic-like\n  gravitational theory: multi-horizon black holes","comments":"14 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2107.13550","journal-ref":"JCAP05(2022)011","doi":"10.1088/1475-7516/2022/05/011","report-no":null,"categories":"gr-qc hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we employ the {\\bf mimetic-like} field equations coupled with\nthe Lagrange multiplier and %mimetic {\\bf potential} to derive non-trivial\nspherically symmetric black hole (BH) solutions. We divided this study into\nthree cases: The first one in which we take the Lagrange multiplier and\n%mimetic {\\bf the potential} to have vanishing value and derive a BH solution\nthat completely coincides with the BH of the Einstein general relativity\ndespite the non-vanishing value of the {\\bf mimetic-like scalar field}. The\nfirst case is completely consistent with the previous studies in the literature\nthat mimetic theory coincides with GR \\cite{Nashed:2018qag}. In the second\ncase, we derive a solution with a constant value of the {\\bf potential} and a\ndynamical value of the Lagrange multiplier. This solution has no horizon and\ntherefore the obtained spacetime does not correspond to the BH. In this\nsolution, there appears the region of the Euclidian signature where the\nsignature of the diagonal components of the metric is $(+,+,+,+)$ or the region\nwith two times where the signature is $(+,+,-,-)$. Finally, we derive a BH\nsolution with non-vanishing values of the Lagrange multiplier, {\\bf potential},\nand {\\bf mimetic-like scalar field}. This BH shows a soft singularity compared\nwith the Einstein BH solution. The relevant physics of the third case is\ndiscussed by showing their behavior of the metric potential at infinity,\ncalculating their energy conditions, and study their thermodynamical\nquantities. We give a brief discussion on how our third case can generate a BH\nwith three horizons as in the de Sitter-Reissner-Nordstr\\\"om black hole\nspacetime, where the largest horizon is the cosmological one and two correspond\nto the outer and inner horizons of the BH. Even in the third case, there\nappears the region of the Euclidian signature or the region with two times.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:04:46 GMT"},{"version":"v2","created":"Tue, 19 Oct 2021 06:56:41 GMT"},{"version":"v3","created":"Tue, 7 Dec 2021 18:13:02 GMT"},{"version":"v4","created":"Thu, 9 Dec 2021 08:39:19 GMT"},{"version":"v5","created":"Sun, 2 Jan 2022 07:27:56 GMT"},{"version":"v6","created":"Fri, 15 Apr 2022 16:56:43 GMT"},{"version":"v7","created":"Mon, 9 May 2022 11:45:45 GMT"}],"update_date":"2022-05-18"}
{"id":"2110.08561","submitter":"Zhiguang Zhao","authors":"Zhiguang Zhao","title":"Sahlqvist Correspondence Theory for Second-Order Propositional Modal\n  Logic","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modal logic with propositional quantifiers (i.e. second-order propositional\nmodal logic (SOPML)) has been considered since the early time of modal logic.\nIts expressive power and complexity are high, and its van-Benthem-Rosen theorem\nand Goldblatt-Thomason theorem have been proved by ten Cate (2006). However,\nthe Sahlqvist theory of SOPML has not been considered in the literature. In the\npresent paper, we fill in this gap. We develop the Sahlqvist correspondence\ntheory for SOPML, which covers and properly extends existing Sahlqvist formulas\nin basic modal logic. We define the class of Sahlqvist formulas for SOMPL step\nby step in a hierarchical way, each formula of which is shown to have a\nfirst-order correspondent over Kripke frames effectively computable by an\nalgorithm $ALBA^{SOMPL}$. In addition, we show that certain $\\Pi_2$-rules\ncorrespond to $\\Pi_2$-Sahlqvist formulas in SOMPL, which further correspond to\nfirst-order conditions, and that even for very simple SOMPL Sahlqvist formulas,\nthey could already be non-canonical.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:23:44 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08562","submitter":"Dahyun Kim","authors":"Dahyun Kim, Kunal Pratap Singh, Jonghyun Choi","title":"BNAS v2: Learning Architectures for Binary Networks with Empirical\n  Improvements","comments":"arXiv admin note: text overlap with arXiv:2002.06963","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Backbone architectures of most binary networks are well-known floating point\n(FP) architectures such as the ResNet family. Questioning that the\narchitectures designed for FP networks might not be the best for binary\nnetworks, we propose to search architectures for binary networks (BNAS) by\ndefining a new search space for binary architectures and a novel search\nobjective. Specifically, based on the cell based search method, we define the\nnew search space of binary layer types, design a new cell template, and\nrediscover the utility of and propose to use the Zeroise layer instead of using\nit as a placeholder. The novel search objective diversifies early search to\nlearn better performing binary architectures. We show that our method searches\narchitectures with stable training curves despite the quantization error\ninherent in binary networks. Quantitative analyses demonstrate that our\nsearched architectures outperform the architectures used in state-of-the-art\nbinary networks and outperform or perform on par with state-of-the-art binary\nnetworks that employ various techniques other than architectural changes. In\naddition, we further propose improvements to the training scheme of our\nsearched architectures. With the new training scheme for our searched\narchitectures, we achieve the state-of-the-art performance by binary networks\nby outperforming all previous methods by non-trivial margins.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:38:26 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08563","submitter":"Sung-Ha Hwang","authors":"Sosung Baik, Sung-Ha Hwang","title":"Auction design with ambiguity: Optimality of the first-price and all-pay\n  auctions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the optimal auction design problem when bidders' preferences follow\nthe maxmin expected utility model. We suppose that each bidder's set of priors\nconsists of beliefs close to the seller's belief, where \"closeness\" is defined\nby a divergence. For a given allocation rule, we identify a class of optimal\ntransfer candidates, named the win-lose dependent transfers, with the following\nproperty: each type of bidder's transfer conditional on winning or losing is\nindependent of the competitor's type report. Our result reduces the\ninfinite-dimensional optimal transfer problem to a two-dimensional optimization\nproblem. By solving the reduced problem, we find that: (i) among efficient\nmechanisms with no premiums for losers, the first-price auction is optimal;\nand, (ii) among efficient winner-favored mechanisms where each bidder pays\nsmaller amounts when she wins than loses: the all-pay auction is optimal. Under\na simplifying assumption, these two auctions remain optimal under the\nendogenous allocation rule.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:45:59 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08564","submitter":"Hiroaki Kaneko","authors":"Hiroaki Kaneko, Sota Arakawa, and Taishi Nakamoto","title":"Dependence of the initial internal structure of chondrule rim on dust\n  size distribution","comments":"56 pages, 20 figures, 6 tables. Accepted for publication in Icarus","journal-ref":null,"doi":"10.1016/j.icarus.2021.114726","report-no":null,"categories":"astro-ph.EP physics.geo-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Coarse objects in chondrites such as chondrules and CAIs are mostly coated\nwith fine-grained rims (FGRs). FGRs can be formed on the surface of free\nfloating chondrules in a turbulent nebula, where dust aggregation also occurs.\nA former study has reported that the morphology of the dust populations\naccreting onto chondrules affects the initial structures of FGRs. It was\nrevealed that, if monomer grains accrete onto chondrules, the smaller grains\ntend to accumulate near the surface of chondrules, and FGRs exhibit grain size\ncoarsening from the bottom to the top. However, the study did not consider the\neffect of temporal growth of dust aggregates on FGRs formation. In this study,\nwe calculate the aggregation of polydisperse monomer grains and their accretion\nonto chondrules. The following two different stages of dust aggregation can be\nidentified: the monomer-aggregation stage and the BCCA-like stage. In the\nmonomer-aggregation stage, monomer grains are incorporated into aggregates when\nthe average aggregate size reaches the size of the monomer. In the BCCA-like\nstage, aggregates evolve fractally in a fashion similar to that of single size\nmonomer grains. Based on the results of the previous study, we obtain the\nrequisite conditions for chondrules to acquire monomer-accreting FGRs with\ngrain size coarsening observed in some chondrites. In the case of similar size\ndistribution as that of Inter Stellar Medium (ISM), the maximum grain size of\n$>$ $1$ $\\mu$m is widely ($\\alpha$ $<$ $10^{-3}$) required for monomer\naccretion, while if turbulent intensity in a nebula is extremely weak ($\\alpha$\n$<$ $10^{-5}$), a maximum grain size $\\sim$ $10$ $\\mu$m is required. The\nmonomer size distributions having larger mass fraction in the large grains\ncompared to ISM might be necessary for the effective grain size coarsening.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:48:36 GMT"}],"update_date":"2022-01-19"}
{"id":"2110.08565","submitter":"Domenico Tortorella","authors":"Domenico Tortorella, Alessio Micheli","title":"Dynamic Graph Echo State Networks","comments":"Accepted for oral presentation at ESANN 2021","journal-ref":"Proceedings of the 29th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2021), pp.\n  99-104","doi":"10.14428/esann/2021.ES2021-70","report-no":null,"categories":"cs.LG cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dynamic temporal graphs represent evolving relations between entities, e.g.\ninteractions between social network users or infection spreading. We propose an\nextension of graph echo state networks for the efficient processing of dynamic\ntemporal graphs, with a sufficient condition for their echo state property, and\nan experimental analysis of reservoir layout impact. Compared to temporal graph\nkernels that need to hold the entire history of vertex interactions, our model\nprovides a vector encoding for the dynamic graph that is updated at each\ntime-step without requiring training. Experiments show accuracy comparable to\napproximate temporal graph kernels on twelve dissemination process\nclassification tasks.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:51:50 GMT"},{"version":"v2","created":"Thu, 27 Oct 2022 19:39:01 GMT"}],"update_date":"2022-10-31"}
{"id":"2110.08566","submitter":"Zelin Yi","authors":"Guangxiang Su and Zelin Yi","title":"Enlargeable foliations and the monodromy groupoid","comments":"v3: minor changes","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $M$ be a spin manifold, the Dirac operator with coefficient in the\nuniversal flat Hilbert $C^\\ast \\pi_1(M)$-module determines a \"Rosenberg index\nelement\" which, according to B.Hanke and T.Schick, subsumes the enlargeablility\nobstruction of positive scalar curvature on $M$. In this note, we generalize\nthis result to the case of spin foliation. More precisely, given a foliation\n$(M,F)$ with $F$ spin, we shall define a foliation version of \"Rosenberg index\nelement\" and prove that it is nonzero at the presence of compactly\nenlargeability of $(M,F)$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 12:55:20 GMT"},{"version":"v2","created":"Mon, 17 Jan 2022 05:39:49 GMT"},{"version":"v3","created":"Tue, 14 Feb 2023 03:08:45 GMT"}],"update_date":"2023-02-15"}
{"id":"2110.08567","submitter":"Kazutoshi Sasahara","authors":"Shimpei Okuda, Michio Hosaka, and Kazutoshi Sasahara","title":"Detecting directional forces in the evolution of grammar: A case study\n  of the English perfect with intransitives across EEBO, COHA, and Google Books","comments":"16 pages, 3 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Languages have diverse characteristics that have emerged through evolution.\nIn modern English grammar, the perfect is formed with \\textit{have}+PP (past\nparticiple), but in earlier English the \\textit{be}+PP form also existed. It is\nwidely recognised that the auxiliary verb BE was replaced by HAVE throughout\nevolution, except for some special cases. However, whether this evolution was\ncaused by natural selection or random drift is still unclear. Here we examined\ndirectional forces in the evolution of the English perfect with intransitives\nby combining three large-scale data sources: EEBO (Early English Books Online),\nCOHA (Corpus of Historical American English), and Google Books. We found that\nmost intransitive verbs exhibited an apparent transition from \\textit{be}+PP to\n\\textit{have}+PP, most of which were classified as `selection' by a deep neural\nnetwork-based model. These results suggest that the English perfect could have\nevolved through natural selection rather than random drift, and provide\ninsights into the cultural evolution of grammar.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:07:16 GMT"},{"version":"v2","created":"Mon, 28 Nov 2022 07:08:57 GMT"},{"version":"v3","created":"Wed, 5 Apr 2023 12:53:40 GMT"}],"update_date":"2023-04-06"}
{"id":"2110.08568","submitter":"Fangqiu Yi","authors":"Fangqiu Yi and Hongyu Wen and Tingting Jiang","title":"ASFormer: Transformer for Action Segmentation","comments":"Accepted by BMVC 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Algorithms for the action segmentation task typically use temporal models to\npredict what action is occurring at each frame for a minute-long daily\nactivity. Recent studies have shown the potential of Transformer in modeling\nthe relations among elements in sequential data. However, there are several\nmajor concerns when directly applying the Transformer to the action\nsegmentation task, such as the lack of inductive biases with small training\nsets, the deficit in processing long input sequence, and the limitation of the\ndecoder architecture to utilize temporal relations among multiple action\nsegments to refine the initial predictions. To address these concerns, we\ndesign an efficient Transformer-based model for action segmentation task, named\nASFormer, with three distinctive characteristics: (i) We explicitly bring in\nthe local connectivity inductive priors because of the high locality of\nfeatures. It constrains the hypothesis space within a reliable scope, and is\nbeneficial for the action segmentation task to learn a proper target function\nwith small training sets. (ii) We apply a pre-defined hierarchical\nrepresentation pattern that efficiently handles long input sequences. (iii) We\ncarefully design the decoder to refine the initial predictions from the\nencoder. Extensive experiments on three public datasets demonstrate that\neffectiveness of our methods. Code is available at\n\\url{https://github.com/ChinaYi/ASFormer}.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:07:20 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08569","submitter":"Raymond Zhou","authors":"Raymond Zhou, Shahrukh Athar, Zhongling Wang, and Zhou Wang","title":"Deep Image Debanding","comments":"5 pages, 4 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Banding or false contour is an annoying visual artifact whose impact is even\nmore pronounced in ultra high definition, high dynamic range, and wide colour\ngamut visual content, which is becoming increasingly popular. Since users\nassociate a heightened expectation of quality with such content and banding\nleads to deteriorated visual quality-of-experience, the area of banding removal\nor debanding has taken paramount importance. Existing debanding approaches are\nmostly knowledge-driven. Despite the widespread success of deep learning in\nother areas of image processing and computer vision, data-driven debanding\napproaches remain surprisingly missing. In this work, we make one of the first\nattempts to develop a deep learning based banding artifact removal method for\nimages and name it deep debanding network (deepDeband). For its training, we\nconstruct a large-scale dataset of 51,490 pairs of corresponding pristine and\nbanded image patches. Performance evaluation shows that deepDeband is\nsuccessful at greatly reducing banding artifacts in images, outperforming\nexisting methods both quantitatively and visually.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:11:48 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08570","submitter":"Kwabena Doku-Amponsah","authors":"E. Ocran, R. Minkah and K. Doku-Amponsah","title":"A Reduced-Bias Weighted least square estimation of the Extreme Value\n  Index","comments":"26 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME math.ST stat.AP stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we propose a reduced-bias estimator of the EVI for Pareto-type\ntails (heavy-tailed) distributions. This is derived using the weighted least\nsquares method. It is shown that the estimator is unbiased, consistent and\nasymptotically normal under the second-order conditions on the underlying\ndistribution of the data. The finite sample properties of the proposed\nestimator are studied through a simulation study. The results show that it is\ncompetitive to the existing estimators of the extreme value index in terms of\nbias and Mean Square Error. In addition, it yields estimates of $\\gamma>0$ that\nare less sensitive to the number of top-order statistics, and hence, can be\nused for selecting an optimal tail fraction. The proposed estimator is further\nillustrated using practical datasets from pedochemical and insurance.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:24:13 GMT"},{"version":"v2","created":"Sun, 10 Apr 2022 10:55:46 GMT"}],"update_date":"2022-04-12"}
{"id":"2110.08571","submitter":"Yang Wu","authors":"Yang Wu, Shirui Feng, Guanbin Li, Liang Lin","title":"Explore before Moving: A Feasible Path Estimation and Memory Recalling\n  Framework for Embodied Navigation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  An embodied task such as embodied question answering (EmbodiedQA), requires\nan agent to explore the environment and collect clues to answer a given\nquestion that related with specific objects in the scene. The solution of such\ntask usually includes two stages, a navigator and a visual Q&A module. In this\npaper, we focus on the navigation and solve the problem of existing navigation\nalgorithms lacking experience and common sense, which essentially results in a\nfailure finding target when robot is spawn in unknown environments.\n  Inspired by the human ability to think twice before moving and conceive\nseveral feasible paths to seek a goal in unfamiliar scenes, we present a route\nplanning method named Path Estimation and Memory Recalling (PEMR) framework.\nPEMR includes a \"looking ahead\" process, \\textit{i.e.} a visual feature\nextractor module that estimates feasible paths for gathering 3D navigational\ninformation, which is mimicking the human sense of direction. PEMR contains\nanother process ``looking behind'' process that is a memory recall mechanism\naims at fully leveraging past experience collected by the feature extractor.\nLast but not the least, to encourage the navigator to learn more accurate prior\nexpert experience, we improve the original benchmark dataset and provide a\nfamily of evaluation metrics for diagnosing both navigation and question\nanswering modules. We show strong experimental results of PEMR on the\nEmbodiedQA navigation task.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:30:55 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08572","submitter":"Dachao Lin","authors":"Haishan Ye, Dachao Lin, Zhihua Zhang","title":"Greedy and Random Broyden's Methods with Explicit Superlinear\n  Convergence Rates in Nonlinear Equations","comments":"arXiv admin note: text overlap with arXiv:2109.01974","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we propose the greedy and random Broyden's method for solving\nnonlinear equations. Specifically, the greedy method greedily selects the\ndirection to maximize a certain measure of progress for approximating the\ncurrent Jacobian matrix, while the random method randomly chooses a direction.\nWe establish explicit (local) superlinear convergence rates of both methods if\nthe initial point and approximate Jacobian are close enough to a solution and\ncorresponding Jacobian. Our two novel variants of Broyden's method enjoy two\nimportant advantages that the approximate Jacobians of our algorithms will\nconverge to the exact ones and the convergence rates of our algorithms are\nasymptotically faster than the original Broyden's method. Our work is the first\ntime to achieve such two advantages theoretically. Our experiments also\nempirically validate the advantages of our algorithms.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:34:42 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08573","submitter":"Prabhupada Dixit","authors":"Prabhupada Dixit and Md. Nasim","title":"Insight from the elliptic flow of identified hadrons measured in\n  relativistic heavy-ion collisions","comments":"8 pages, 6 figures","journal-ref":null,"doi":"10.1142/S0218301322500598","report-no":null,"categories":"nucl-ex hep-ex hep-ph nucl-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we have discussed the transverse momentum dependence of\nelliptic flow measured in relativistic heavy-ion collisions. The transverse\nmomentum dependence of the number of constituent quarks ($n_{q}$) scaled\n$v_{2}$ is obtained for all the measured identified hadrons. The $n_{q}$ scaled\n$\\phi$ $v_{2}$ is found to be similar to $n_{q}$ scaled $\\Omega$ $v_{2}$. This\nindicates that both $\\phi$ and $\\Omega$ are produced through quark\nrecombination at RHIC energies. We also find $n_{q}$ scaled proton $v_{2}$\n($v_{2}$ of light quarks) is higher than $n_{q}$ scaled $\\phi$ and $\\Omega$\n$v_{2}$ ($v_{2}$ of strange quarks) at $p_{T}/n_{q}$ $<$ 1.0 GeV/c. This can be\nexplained by considering quark $v_{2}$ is proportional to its transverse\nkinetic energy considering mass of deconfined light and strange quarks equal to\n$\\sim $4 MeV and $\\sim$ 140 MeV, respectively.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:37:57 GMT"},{"version":"v2","created":"Wed, 8 Jun 2022 10:24:15 GMT"}],"update_date":"2022-08-17"}
{"id":"2110.08574","submitter":"Satoshi Ejima","authors":"Satoshi Ejima, Florian Lange and Holger Fehske","title":"Nonequilibrium dynamics in pumped Mott insulators","comments":"6 pages, 5 figures + 4 pages supplemental material","journal-ref":"Phys. Rev. Research 4, L012012 (2022)","doi":"10.1103/PhysRevResearch.4.L012012","report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use time-evolution techniques for (infinite) matrix-product-states to\ncalculate, directly in the thermodynamic limit, the time-dependent\nphotoemission spectra and dynamic structure factors of the half-filled Hubbard\nchain after pulse irradiation. These quantities exhibit clear signatures of the\nphotoinduced phase transition from insulator to metal that occurs because of\nthe formation of so-called $\\eta$ pairs. In addition, the spin dynamic\nstructure factor loses spectral weight in the whole momentum space, reflecting\nthe suppression of antiferromagnetic correlations due to the buildup of\n$\\eta$-pairing states. The numerical method demonstrated in this work can be\nreadily applied to other one-dimensional models driven out of equilibrium by\noptical pumping.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:46:44 GMT"},{"version":"v2","created":"Wed, 26 Jan 2022 20:07:26 GMT"}],"update_date":"2022-02-10"}
{"id":"2110.08575","submitter":"Shiladitya Banerjee","authors":"Diana Serbanescu, Nikola Ojkic, Shiladitya Banerjee","title":"Cellular resource allocation strategies for cell size and shape control\n  in bacteria","comments":"Review article, 13 pages, 5 figures,","journal-ref":"The FEBS Journal (2021)","doi":"10.1111/febs.16234","report-no":null,"categories":"q-bio.CB physics.bio-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Bacteria are highly adaptive microorganisms that thrive in a wide range of\ngrowth conditions via changes in cell morphologies and macromolecular\ncomposition. How bacterial morphologies are regulated in diverse environmental\nconditions is a longstanding question. Regulation of cell size and shape\nimplies control mechanisms that couple the growth and division of bacteria to\ntheir cellular environment and macromolecular composition. In the past decade,\nsimple quantitative laws have emerged that connect cell growth to proteomic\ncomposition and the nutrient availability. However, the relationships between\ncell size, shape and growth physiology remain challenging to disentangle and\nunifying models are lacking. In this review, we focus on regulatory models of\ncell size control that reveal the connections between bacterial cell morphology\nand growth physiology. In particular, we discuss how changes in nutrient\nconditions and translational perturbations regulate the cell size, growth rate\nand proteome composition. Integrating quantitative models with experimental\ndata, we identify the physiological principles of bacterial size regulation,\nand discuss the optimization strategies of cellular resource allocation for\nsize control.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 13:55:16 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.08576","submitter":"Feng Qi","authors":"Feng Qi, Mark Daniel Ward","title":"Closed-form formulas and properties of coefficients in Maclaurin's\n  series expansion of Wilf's function composited by inverse tangent, square\n  root, and exponential functions","comments":"26 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the paper, with the aid of the Fa\\`a di Bruno formula, be virtue of\nseveral identities for the Bell polynomials of the second kind, with the help\nof two combinatorial identities, by means of the (logarithmically) complete\nmonotonicity of generating functions of several integer sequences, and in the\nlight of Wronski's theorem, the authors establish Taylor's series expansions of\nseveral functions involving the inverse (hyperbolic) tangent function, find out\nMaclaurin's series expansion of a complex function composited by inverse\ntangent, square root, and exponential functions and posed by Herbert S. Wilf,\nand analyze some properties, including generating functions, limits,\npositivity, monotonicity, and logarithmic convexity, of the coefficients in\nMaclaurin's series expansion of Wilf's function. These coefficients in\nMaclaurin's series expansion of Wilf's function are closed-form expressions in\nterms of the Stirling numbers of the second kind. The authors also derive a\nclosed-form formula for a sequence of special values of Gauss' hypergeometric\nfunction, discover a closed-form formula for a sequence of special values of\nthe Bell polynomials of the second kind, present several infinite series\nrepresentations of the circular constant Pi and other sequences, recover an\nasymptotic rational approximation to the circular constant Pi, and connect\nseveral integer sequences by determinants.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:03:54 GMT"},{"version":"v2","created":"Sun, 1 May 2022 14:32:22 GMT"}],"update_date":"2022-05-03"}
{"id":"2110.08577","submitter":"Dinesh Singh","authors":"Dinesh Singh, Hardik Tankaria, Makoto Yamada","title":"Nys-Newton: Nystr\\\"om-Approximated Curvature for Stochastic Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Second-order optimization methods are among the most widely used optimization\napproaches for convex optimization problems, and have recently been used to\noptimize non-convex optimization problems such as deep learning models. The\nwidely used second-order optimization methods such as quasi-Newton methods\ngenerally provide curvature information by approximating the Hessian using the\nsecant equation. However, the secant equation becomes insipid in approximating\nthe Newton step owing to its use of the first-order derivatives. In this study,\nwe propose an approximate Newton sketch-based stochastic optimization algorithm\nfor large-scale empirical risk minimization. Specifically, we compute a partial\ncolumn Hessian of size ($d\\times m$) with $m\\ll d$ randomly selected variables,\nthen use the \\emph{Nystr\\\"om method} to better approximate the full Hessian\nmatrix. To further reduce the computational complexity per iteration, we\ndirectly compute the update step ($\\Delta\\boldsymbol{w}$) without computing and\nstoring the full Hessian or its inverse. We then integrate our approximated\nHessian with stochastic gradient descent and stochastic variance-reduced\ngradient methods. The results of numerical experiments on both convex and\nnon-convex functions show that the proposed approach was able to obtain a\nbetter approximation of Newton\\textquotesingle s method, exhibiting performance\ncompetitive with that of state-of-the-art first-order and stochastic\nquasi-Newton methods. Furthermore, we provide a theoretical convergence\nanalysis for convex functions.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:04:51 GMT"},{"version":"v2","created":"Sat, 29 Jan 2022 21:25:27 GMT"}],"update_date":"2022-02-01"}
{"id":"2110.08578","submitter":"Zhixin Sun","authors":"Zhixin Sun, Xian Zhong, Shuqin Chen, Lin Li, and Luo Zhong","title":"Visual-aware Attention Dual-stream Decoder for Video Captioning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Video captioning is a challenging task that captures different visual parts\nand describes them in sentences, for it requires visual and linguistic\ncoherence. The attention mechanism in the current video captioning method\nlearns to assign weight to each frame, promoting the decoder dynamically. This\nmay not explicitly model the correlation and the temporal coherence of the\nvisual features extracted in the sequence frames.To generate semantically\ncoherent sentences, we propose a new Visual-aware Attention (VA) model, which\nconcatenates dynamic changes of temporal sequence frames with the words at the\nprevious moment, as the input of attention mechanism to extract sequence\nfeatures.In addition, the prevalent approaches widely use the teacher-forcing\n(TF) learning during training, where the next token is generated conditioned on\nthe previous ground-truth tokens. The semantic information in the previously\ngenerated tokens is lost. Therefore, we design a self-forcing (SF) stream that\ntakes the semantic information in the probability distribution of the previous\ntoken as input to enhance the current token.The Dual-stream Decoder (DD)\narchitecture unifies the TF and SF streams, generating sentences to promote the\nannotated captioning for both streams.Meanwhile, with the Dual-stream Decoder\nutilized, the exposure bias problem is alleviated, caused by the discrepancy\nbetween the training and testing in the TF learning.The effectiveness of the\nproposed Visual-aware Attention Dual-stream Decoder (VADD) is demonstrated\nthrough the result of experimental studies on Microsoft video description\n(MSVD) corpus and MSR-Video to text (MSR-VTT) datasets.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:08:20 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08579","submitter":"Manuel Alberto M. Ferreira Prof. Dr.","authors":"Manuel Alberto M. Ferreira","title":"Stochastic Processes in Networks of Queues with Exponential Service\n  Times and only one Class of Customers","comments":"9 pages","journal-ref":null,"doi":"10.12988/ams.2014.47522","report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Two networks of queues models, presented initially by Jackson, in the open\ncase, and Gordon and Newell, in the closed case, stochastic processes are\npresented and studied in some of their details and problems. The service times\nare exponentially distributed and there is only one class of customers.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:14:28 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08580","submitter":"Anchit Gupta","authors":"Anchit Gupta, Faizan Farooq Khan, Rudrabha Mukhopadhyay, Vinay P.\n  Namboodiri, C. V. Jawahar","title":"Intelligent Video Editing: Incorporating Modern Talking Face Generation\n  Algorithms in a Video Editor","comments":"9 pages, 7 figures, accepted in ICVGIP 2021","journal-ref":null,"doi":"10.1145/3490035.3490284","report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper proposes a video editor based on OpenShot with several\nstate-of-the-art facial video editing algorithms as added functionalities. Our\neditor provides an easy-to-use interface to apply modern lip-syncing algorithms\ninteractively. Apart from lip-syncing, the editor also uses audio and facial\nre-enactment to generate expressive talking faces. The manual control improves\nthe overall experience of video editing without missing out on the benefits of\nmodern synthetic video generation algorithms. This control enables us to\nlip-sync complex dubbed movie scenes, interviews, television shows, and other\nvisual content. Furthermore, our editor provides features that automatically\ntranslate lectures from spoken content, lip-sync of the professor, and\nbackground content like slides. While doing so, we also tackle the critical\naspect of synchronizing background content with the translated speech. We\nqualitatively evaluate the usefulness of the proposed editor by conducting\nhuman evaluations. Our evaluations show a clear improvement in the efficiency\nof using human editors and an improved video generation quality. We attach demo\nvideos with the supplementary material clearly explaining the tool and also\nshowcasing multiple results.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:19:12 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08581","submitter":"Hui Chen","authors":"Hui Chen, Hadi Sarieddeen, Tarig Ballal, Henk Wymeersch, Mohamed-Slim\n  Alouini, Tareq Y. Al-Naffouri","title":"A Tutorial on Terahertz-Band Localization for 6G Communication Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Terahertz (THz) communications are celebrated as key enablers for converged\nlocalization and sensing in future sixth-generation (6G) wireless communication\nsystems and beyond. Instead of being a byproduct of the communication system,\nlocalization in 6G is indispensable for location-aware communications. Towards\nthis end, we aim to identify the prospects, challenges, and requirements of THz\nlocalization techniques. We first review the history and trends of localization\nmethods and discuss their objectives, constraints, and applications in\ncontemporary communication systems. We then detail the latest advances in THz\ncommunications and introduce the THz-specific channel and system models.\nAfterward, we formulate THz-band localization as a 3D position/orientation\nestimation problem, detailing geometry-based localization techniques and\ndescribing potential THz localization and sensing extensions. We further\nformulate the offline design and online optimization of THz localization\nsystems, provide numerical simulation results, and conclude by providing\nlessons learned and future research directions. Preliminary results illustrate\nthat under the same transmission power and array footprint, THz-based\nlocalization outperforms millimeter wave-based localization. In other words,\nthe same level of localization performance can be achieved at THz-band with\nless transmission power or a smaller footprint.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:20:09 GMT"},{"version":"v2","created":"Mon, 25 Oct 2021 22:18:33 GMT"},{"version":"v3","created":"Mon, 14 Mar 2022 23:41:45 GMT"},{"version":"v4","created":"Mon, 23 May 2022 16:54:00 GMT"},{"version":"v5","created":"Tue, 24 May 2022 14:24:43 GMT"},{"version":"v6","created":"Tue, 15 Nov 2022 08:36:17 GMT"}],"update_date":"2022-11-16"}
{"id":"2110.08582","submitter":"Leila Eftekhari","authors":"Leila Eftekhari, Soleiman Hosseinpour, Moein Khalighi, Salvador\n  Jimenez","title":"Bifurcation analysis of a fractional-order Pinsky-Rinzel model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Abstract The present work describes a new fractional-order system of a\ntwo-compartment CA3 hippocampal pyramidal cell, which is known as Pinsky-Rinzel\nmodel with Caputo fractional derivative. Firstly, The transient of the\nsolutions is investigated. Then based on the bifurcation diagrams, we study the\ngeneral behavior of the system. In this case, fractional derivative order and\ncurrents injection, are taken as bifurcation parameters. Chaotic regions are\nobtained for different values of the fractional derivative order and different\ninjection currents. Finally, a numerical approach is introduced to study the\nstability of the system under certain conditions. The obtained results can be\nconsidered as help to control relevant diseases caused by maximal injection\ncurrents abnormality.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:25:27 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08583","submitter":"Morgane Riviere","authors":"Morgane Riviere, Jade Copet, Gabriel Synnaeve","title":"ASR4REAL: An extended benchmark for speech models","comments":"Submitted to ICASSP 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.CL cs.LG cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Popular ASR benchmarks such as Librispeech and Switchboard are limited in the\ndiversity of settings and speakers they represent. We introduce a set of\nbenchmarks matching real-life conditions, aimed at spotting possible biases and\nweaknesses in models. We have found out that even though recent models do not\nseem to exhibit a gender bias, they usually show important performance\ndiscrepancies by accent, and even more important ones depending on the\nsocio-economic status of the speakers. Finally, all tested models show a strong\nperformance drop when tested on conversational speech, and in this precise\ncontext even a language model trained on a dataset as big as Common Crawl does\nnot seem to have significant positive effect which reiterates the importance of\ndeveloping conversational language models\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:34:25 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08584","submitter":"Richard Brath","authors":"Richard Brath","title":"Surveying Wonderland for many more literature visualization techniques","comments":"7 pages. 58 figures, each a different visualization of Alice's\n  Adventures in Wonderland","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  There are still many potential literature visualizations to be discovered. By\nfocusing on a single text, the author surveys many existing visualizations\nacross research domains, in the wild, and creates new visualizations. 58\ntechniques are indicated, suggesting a wider variety of visualizations beyond\nresearch disciplines.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:35:48 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08585","submitter":"Carlos A. S. Almeida","authors":"A. R. P. Moreira, F. C. E. Lima, and C. A. S. Almeida","title":"Configurational Entropy and braneworlds in f(T,B) gravity","comments":"20 pages,10 captioned figures. Updated version to match accepted one\n  in IJMPD. Title changed. Minor modifications","journal-ref":null,"doi":"10.1142/S0218271822500808","report-no":null,"categories":"hep-th gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The thick brane scenario built on the f(T,B) teleparallel gravity theory was\nconsidered for the study of phase transitions, internal structures, and new\nclasses of solutions in a model. In this theory, T denotes the torsion scalar,\nand B is a boundary term. An interesting result was observed when brane\nsplitting occurs, i. e., internal structures in the model arise as a\nconsequence of the appearance of new domain walls in the theory. In fact, this\npreliminary result influences the profile of the matter field (from kink to\nmulti-kink) so that for appropriate values of the parameters $k_{1,2}$ multiple\nphase transitions are identified. To perform this analysis, the Differential\nConfigurational Entropy (DCE) which has the ability to predict the existence of\nphase transitions through critical points was used. Furthermore, the DCE is\nable to select the most stable solutions since it gives us details about the\ninformational content of the field settings.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 14:51:17 GMT"},{"version":"v2","created":"Fri, 3 Jun 2022 18:06:46 GMT"}],"update_date":"2022-06-07"}
{"id":"2110.08586","submitter":"Gustavo Claudio Karl Couto","authors":"Gustavo Claudio Karl Couto and Eric Aislan Antonelo","title":"Generative Adversarial Imitation Learning for End-to-End Autonomous\n  Driving on Urban Environments","comments":null,"journal-ref":"2021 IEEE Symposium Series on Computational Intelligence (SSCI)","doi":"10.1109/SSCI50451.2021.9660156","report-no":null,"categories":"cs.RO cs.AI cs.LG cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Autonomous driving is a complex task, which has been tackled since the first\nself-driving car ALVINN in 1989, with a supervised learning approach, or\nbehavioral cloning (BC). In BC, a neural network is trained with state-action\npairs that constitute the training set made by an expert, i.e., a human driver.\nHowever, this type of imitation learning does not take into account the\ntemporal dependencies that might exist between actions taken in different\nmoments of a navigation trajectory. These type of tasks are better handled by\nreinforcement learning (RL) algorithms, which need to define a reward function.\nOn the other hand, more recent approaches to imitation learning, such as\nGenerative Adversarial Imitation Learning (GAIL), can train policies without\nexplicitly requiring to define a reward function, allowing an agent to learn by\ntrial and error directly on a training set of expert trajectories. In this\nwork, we propose two variations of GAIL for autonomous navigation of a vehicle\nin the realistic CARLA simulation environment for urban scenarios. Both of them\nuse the same network architecture, which process high dimensional image input\nfrom three frontal cameras, and other nine continuous inputs representing the\nvelocity, the next point from the sparse trajectory and a high-level driving\ncommand. We show that both of them are capable of imitating the expert\ntrajectory from start to end after training ends, but the GAIL loss function\nthat is augmented with BC outperforms the former in terms of convergence time\nand training stability.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:04:13 GMT"}],"update_date":"2023-02-08"}
{"id":"2110.08587","submitter":"Sneh Bala Sinha","authors":"T. N. Shorey and Sneh Bala Sinha","title":"Extension of Laguerre polynomials with negative arguments II","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For $n \\geq 3$ and $s \\leq 92$, it is proved in \\cite{ShSi} that, except for\nfinitely many pairs $(n, s), G_1(x) = G_1(x, n, s) $ is either irreducible or\nlinear factor times an irreducible polynomial. If $s \\leq 30$, we determine\nhere explicitely the set of pairs $(n, s)$ in the above assertion. This implies\na new proof of the result of Nair and Shorey \\cite{NaSh1} that $G_1(x)$ is\nirreducible for $s \\leq 22$.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:10:29 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08588","submitter":"Jeremy Carroll","authors":"Jeremy J. Carroll, Pankaj Anand, David Guo","title":"Preproduction Deploys: Cloud-Native Integration Testing","comments":"8 pages, 1 figure, submitted to IEEE CloudSummit 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The microservice architecture for cloud-based systems is extended to not only\nrequire each loosely coupled component to be independently deployable, but also\nto provide independent routing for each component. This supports canary\ndeployments, green/blue deployments and roll-back. Both ad hoc and system\nintegration test traffic can be directed to components before they are released\nto production traffic. Front-end code is included in this architecture by using\nserver-side rendering of JS bundles. Environments for integration testing are\ncreated with preproduction deploys side by side with production deploys using\nappropriate levels of isolation. After a successful integration test run,\npreproduction components are known to work with production precisely as it is.\nFor isolation, test traffic uses staging databases that are copied daily from\nthe production databases, omitting sensitive data. Safety and security concerns\nare dealt with in a targeted fashion, not monolithically. This architecture\nscales well with organization size; is more effective for integration testing;\nand is better aligned with agile business practices than traditional\napproaches.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:13:03 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08589","submitter":"Bethany Thompson","authors":"Bethany H. Thompson, Gaetano Di Caterina, Jeremy P. Voisey","title":"Pseudo-label refinement using superpixels for semi-supervised brain\n  tumour segmentation","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training neural networks using limited annotations is an important problem in\nthe medical domain. Deep Neural Networks (DNNs) typically require large,\nannotated datasets to achieve acceptable performance which, in the medical\ndomain, are especially difficult to obtain as they require significant time\nfrom expert radiologists. Semi-supervised learning aims to overcome this\nproblem by learning segmentations with very little annotated data, whilst\nexploiting large amounts of unlabelled data. However, the best-known technique,\nwhich utilises inferred pseudo-labels, is vulnerable to inaccurate\npseudo-labels degrading the performance. We propose a framework based on\nsuperpixels - meaningful clusters of adjacent pixels - to improve the accuracy\nof the pseudo labels and address this issue. Our framework combines superpixels\nwith semi-supervised learning, refining the pseudo-labels during training using\nthe features and edges of the superpixel maps. This method is evaluated on a\nmultimodal magnetic resonance imaging (MRI) dataset for the task of brain\ntumour region segmentation. Our method demonstrates improved performance over\nthe standard semi-supervised pseudo-labelling baseline when there is a reduced\nannotator burden and only 5 annotated patients are available. We report\nDSC=0.824 and DSC=0.707 for the test set whole tumour and tumour core regions\nrespectively.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:17:11 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08590","submitter":"Abduragim Shtanchaev","authors":"Abduragim Shtanchaev, Artur Bille, Olga Sutyrina, Sara Elelimy","title":"Automated Remote Sensing Forest Inventory Using Satellite Imagery","comments":"15 pages, 11 figures, 71th International Astronautical Congress (IAC)\n  - The CyberSpace Edition","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For many countries like Russia, Canada, or the USA, a robust and detailed\ntree species inventory is essential to manage their forests sustainably. Since\none can not apply unmanned aerial vehicle (UAV) imagery-based approaches to\nlarge-scale forest inventory applications, the utilization of machine learning\nalgorithms on satellite imagery is a rising topic of research. Although\nsatellite imagery quality is relatively low, additional spectral channels\nprovide a sufficient amount of information for tree crown classification tasks.\nAssuming that tree crowns are detected already, we use embeddings of tree\ncrowns generated by Autoencoders as a data set to train classical Machine\nLearning algorithms. We compare our Autoencoder (AE) based approach to\ntraditional convolutional neural networks (CNN) end-to-end classifiers.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:24:12 GMT"},{"version":"v2","created":"Sun, 7 Nov 2021 07:35:00 GMT"}],"update_date":"2021-11-09"}
{"id":"2110.08591","submitter":"Zekeriya Anil Guven","authors":"Zekeriya Anil Guven, Banu Diri, Tolgahan Cakaloglu","title":"n-stage Latent Dirichlet Allocation: A Novel Approach for LDA","comments":"Published in: 2019 4th International Conference on Computer Science\n  and Engineering (UBMK). This study is extension version of \"Comparison of\n  Topic Modeling Methods for Type Detection of Turkish News\"\n  http://dx.doi.org/10.1109/UBMK.2019.8907050 . Please citation this IEEE paper","journal-ref":null,"doi":"10.1109/UBMK.2019.8907050","report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nowadays, data analysis has become a problem as the amount of data is\nconstantly increasing. In order to overcome this problem in textual data, many\nmodels and methods are used in natural language processing. The topic modeling\nfield is one of these methods. Topic modeling allows determining the semantic\nstructure of a text document. Latent Dirichlet Allocation (LDA) is the most\ncommon method among topic modeling methods. In this article, the proposed\nn-stage LDA method, which can enable the LDA method to be used more\neffectively, is explained in detail. The positive effect of the method has been\ndemonstrated by the applied English and Turkish studies. Since the method\nfocuses on reducing the word count in the dictionary, it can be used\nlanguage-independently. You can access the open-source code of the method and\nthe example: https://github.com/anil1055/n-stage_LDA\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:26:53 GMT"},{"version":"v2","created":"Wed, 20 Oct 2021 08:39:24 GMT"}],"update_date":"2021-10-22"}
{"id":"2110.08592","submitter":"Elad Michael Schiller (PhD)","authors":"Romaric Duvignau and Michel Raynal and Elad Michael Schiller","title":"Self-stabilizing Byzantine- and Intrusion-tolerant Consensus","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One of the most celebrated problems of fault-tolerant distributed computing\nis the consensus problem. It was shown to abstract a myriad of problems in\nwhich processes have to agree on a single value. Consensus applications include\nfundamental services for the environments of the Cloud or Blockchain. In such\nchallenging environments, malicious behavior is often modeled as adversarial\nByzantine faults. At OPODIS 2010, Moste}faoui and Raynal, in short, MR,\npresented a Byzantine- and intrusion-tolerant solution to consensus in which\nthe decided value cannot be a value proposed only by Byzantine processes. In\naddition to this validity property, MR has optimal resilience since it can deal\nwith up to t < n/3 Byzantine processes, where n is the number of processes. We\nnote that MR provides this multivalued consensus object (which accepts\nproposals taken from a set with a finite number of values) assuming the\navailability of a single Binary consensus object (which accepts proposals taken\nfrom the set {0,1}).\n  This work, which focuses on multivalued consensus, aims at the design of an\neven more robust solution than MR. Our proposal expands MR's fault-model with\nself-stabilization, a vigorous notion of fault-tolerance. In addition to\ntolerating Byzantine and communication failures, self-stabilizing systems can\nautomatically recover after the occurrence of arbitrary transient-faults. These\nfaults represent any violation of the assumptions according to which the system\nwas designed to operate (provided that the algorithm code remains intact).\n  To the best of our knowledge, we propose the first self-stabilizing solution\nfor intrusion-tolerant multivalued consensus for asynchronous message-passing\nsystems prone to Byzantine failures.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:32:36 GMT"},{"version":"v2","created":"Sat, 10 Sep 2022 13:00:13 GMT"}],"update_date":"2022-09-13"}
{"id":"2110.08593","submitter":"Amretashis Sengupta","authors":"A. Sengupta","title":"First principles design of 2 dimensional Nickel dichalcogenide Janus\n  materials NiXY (X,Y=S,Se,Te)","comments":"9 pages, 5 Figures, 2 tables","journal-ref":"Computational Materials Science 206 (2022) 111278","doi":"10.1016/j.commatsci.2022.111278","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we propose novel two-dimensional (2D) Janus Ni dichalcogenide\nmaterials and explore their feasibility, stability and evaluate their\nelectronic and optical properties with ab-initio calculations. Three unique\nJanus materials, namely NiSSe, NiSTe and NiSeTe, based on the 2H hexagonal\npolytype of NiS2, NiSe2 and NiTe2 were proposed. Density functional theory\n(DFT) calculations, show that among the three proposed NiXY Janus 2D materials,\nNiSSe had the best energetic and dynamical stability. GGA PBE calculations\nshowed NiSSe to have a semi-metallic bandstructure with the Ni-Se interaction\nhaving a dominant role in the band profile near the Fermi energy. Electron\nlocalization function (ELF) and total potential plots show a distinguishable\nasymmetry in terms of valence electron localization and distribution between\nthe S and Se atoms in 2D NiSSe. The presence of large amount of electron gas\nlike feature in the ELF around the chalcogen atoms also indicates their\nimportance in the conduction properties. Optical properties calculated with\nrandom phase approximation (RPA) show the 2D NiSSe to have broad spectrum\noptical response with significant peaks lying in each of the infra-red, visible\nand the ultraviolet range of the spectra.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:33:21 GMT"},{"version":"v2","created":"Sun, 28 Nov 2021 08:01:15 GMT"}],"update_date":"2022-02-22"}
{"id":"2110.08594","submitter":"Masatoshi Yamada","authors":"Nobuyoshi Ohta and Masatoshi Yamada","title":"Higgs scalar potential coupled to gravity in the exponential\n  parametrization in arbitrary gauge","comments":"49 pages, 13 figures, Version published in PRD","journal-ref":"Phys. Rev. D 105 (2022) 2, 026013","doi":"10.1103/PhysRevD.105.026013","report-no":null,"categories":"hep-th gr-qc hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the parametrization and gauge dependences in the Higgs field coupled\nto gravity in the context of asymptotic safety. We use the exponential\nparametrization to derive the fixed points for the cosmological constant,\nPlanck mass, Higgs mass and its coupling, keeping arbitrary gauge parameters\n$\\alpha$ and $\\beta$, and compare the results with the linear split. We find\nthat the beta functions for the Higgs potential are expressed in terms of\nredefined Planck mass such that the apparent gauge dependence is absent. Only\nthe trace mode of the gravity fluctuations couples to the Higgs potential and\nit tends to decouple in the large $\\beta$ limit, but the anomalous dimension\nbecomes large, invalidating the local potential approximation. This gives the\nlimitation of the exponential parametrization. There are also singularities for\nsome values of the gauge parameters but well away from these, we find rather\nstable fixed points and critical exponents. We thus find that there are regions\nfor the gauge parameters to give stable fixed points and critical exponents\nagainst the change of gauge parameters. The Higgs coupling is confirmed to be\nirrelevant for the reasonable choice of gauge parameters.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:35:09 GMT"},{"version":"v2","created":"Thu, 13 Jan 2022 05:33:35 GMT"}],"update_date":"2022-01-14"}
{"id":"2110.08595","submitter":"Fady Aziz","authors":"Pascal Weller, Fady Aziz, Sherif Abdulatif, Urs Schneider, Marco F.\n  Huber","title":"A MIMO Radar-based Few-Shot Learning Approach for Human-ID","comments":"5 pages, 6 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Radar for deep learning-based human identification has become a research area\nof increasing interest. It has been shown that micro-Doppler ($\\mu$-D) can\nreflect the walking behavior through capturing the periodic limbs'\nmicro-motions. One of the main aspects is maximizing the number of included\nclasses while considering the real-time and training dataset size constraints.\nIn this paper, a multiple-input-multiple-output (MIMO) radar is used to\nformulate micro-motion spectrograms of the elevation angular velocity\n($\\mu$-$\\omega$). The effectiveness of concatenating this newly-formulated\nspectrogram with the commonly used $\\mu$-D is investigated. To accommodate for\nnon-constrained real walking motion, an adaptive cycle segmentation framework\nis utilized and a metric learning network is trained on half gait cycles\n($\\approx$ 0.5 s). Studies on the effects of various numbers of classes\n(5--20), different dataset sizes, and varying observation time windows 1--2 s\nare conducted. A non-constrained walking dataset of 22 subjects is collected\nwith different aspect angles with respect to the radar. The proposed few-shot\nlearning (FSL) approach achieves a classification error of 11.3 % with only 2\nmin of training data per subject.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:37:57 GMT"},{"version":"v2","created":"Mon, 13 Jun 2022 14:37:13 GMT"}],"update_date":"2022-06-14"}
{"id":"2110.08596","submitter":"Felix Buot Ph.D.","authors":"F. A. Buot, G. Maglasang, A. R. Elnar, and C. M. Galon","title":"On Hofstadter butterfly spectrum: Chern-Simons theory, subband gap\n  mapping, IQHE and FQHE labelling","comments":"10 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The magnetic field affects the Bloch band structure in a couple of ways.\nFirst it breaks the Bloch band into magnetic subbands or the Landau levels are\nbroadened into magnetic Bloch bands. The resulting group of subbands in the\ncentral portion of the energy scale is associated with the integer quantum Hall\neffect (IQHE). Then at high fields it changes the integrated density of states\nof the remaining lowest and topmost subband, respectively, which can be\nassociated with fractional quantum Hall effect (FQHE).\n  Here, we employ the Maxwell Chern-Simons gauge theory to formulate the\nsubband-gap mapping algorithm and to construct the butterfly profile of the\nHofstadter spectrum. The two regions in the spectrum responsible for the IQHE\nare identified. At very high magnetic fields the highest and lowest subband are\naffected by magnetic-field induced restructuring of the integrated density of\nstates in each subband, respectively. The resulting transformation of each of\nthe two subband is responsible for the FQHE. Thus, in the central regions of\nthe energy scale, the principal group of subbands defined by the gap mapping is\nresponsible for the IQHE. The fine structure of the topmost and lowest subband,\nwhich convey an iterative nature of the magnetic spectrum is a result of a\nhierarchical scaling and restructuring by the magnetic fields on the integrated\ndensity of states in each respective subband and is responsible for the FQHE.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:47:18 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.08597","submitter":"Neda Heidari","authors":"N. Heidari, I. Boisse, J. Orell-Mique, G. Hebrard, L. Acuna, N. C.\n  Hara, J. Lillo-Box, J. D. Eastman, L. Arnold, N. Astudillo-Defru, V.\n  Adibekyan, A. Bieryla, X. Bonfils, F. Bouchy, T. Barclay, C.E. Brasseur, S.\n  Borgniet, V. Bourrier, L. Buchhave, A. Behmard, C. Beard, N. M .Batalha,\n  B.Courcol, P. Cortes-Zuleta, K. Collins, A. Carmona, I. J. M. Crossfield, A.\n  Chontos, X. Delfosse, S. Dalal, M.Deleuil, O. D. S. Demangeon, R. F. Diaz, X.\n  Dumusque, T. Daylan, D. Dragomir, E. Delgado Mena, C. Dressing, F. Dai, P. A.\n  Dalba, D. Ehrenreich, T. Forveille, B. Fulton, T. Fetherolf, G. Gaisne, S.\n  Giacalone, N. Riazi, S. Hoyer, M. J. Hobson, A. W. Howard, D. Huber, M. L.\n  Hill, L. A. Hirsch, H. Isaacson, J. Jenkins, S. R. Kane, F. Kiefer, R. Luque,\n  D. W. Latham, J. Lubin, T. Lopez, O. Mousis, C. Moutou, G. Montagnier, L.\n  Mignon, A. Mayo, T. Mocnik, J. M. A. Murphy, E. Palle, F. Pepe, E. A.\n  Petigura, J. Rey, G. Ricker, P. Robertson, A. Roy, R. A. Rubenzahl, L. J.\n  Rosenthal, A. Santerne, N. C. Santos, S. G. Sousa, K. G. Stassun, M.\n  Stalport, N. Scarsdale, P. A. Strom, S. Seager, D. Segransan, P. Tenenbaum,\n  R. Tronsgaard, S. Udry, R. Vanderspek, F. Vakili, J. Winn, L. M. Weiss","title":"HD207897 b: A dense sub-Neptune transiting a nearby and bright K-type\n  star","comments":"18 pages, 12 figures, 6 tables; accepted for publication in the A&A\n  journal; comments welcome","journal-ref":"A&A 658, A176 (2022)","doi":"10.1051/0004-6361/202141429","report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present the discovery and characterization of a transiting sub-Neptune\norbiting with a 16.20 day period around a nearby (28 pc) and bright(V=8.37) K0V\nstar HD207897 (TOI-1611). This discovery is based on photometric measurements\nfrom the Transiting Exoplanet Survey Satellite(TESS) mission and radial\nvelocity (RV) observations from the SOPHIE, Automated Planet Finder (APF) and\nHIRES high precision spectrographs. We used EXOFASTv2 for simultaneously\nmodeling the parameters of the planet and its host star, combining photometric\nand RV data to determine the planetary system parameters. We show that the\nplanet has a radius of 2.50+/-0.08 RE and a mass of either 14.4+/-1.6 ME or\n15.9+/-1.6 ME with nearly equal probability; the two solutions correspond to\ntwo possibilities for the stellar activity period. Hence, the density is either\n5.1+/-0.7 g cm^-3 or 5.5^{+0.8}_{-0.7} g cm^-3, making it one of the relatively\nrare dense sub-Neptunes. The existence of such a dense planet at only 0.12 AU\nfrom its host star is unusual in the currently observed sub-Neptune (2<RE<4)\npopulation. The most likely scenario is that this planet has migrated to its\ncurrent position.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:53:26 GMT"}],"update_date":"2022-03-14"}
{"id":"2110.08598","submitter":"C.-H. Huck Yang","authors":"Hu Hu, Sabato Marco Siniscalchi, Chao-Han Huck Yang, Chin-Hui Lee","title":"A Variational Bayesian Approach to Learning Latent Variables for\n  Acoustic Knowledge Transfer","comments":"Accepted to ICASSP 2022. Code is available at\n  https://github.com/MihawkHu/ASC_Knowledge_Transfer","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.LG cs.NE cs.SD","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a variational Bayesian (VB) approach to learning distributions of\nlatent variables in deep neural network (DNN) models for cross-domain knowledge\ntransfer, to address acoustic mismatches between training and testing\nconditions. Instead of carrying out point estimation in conventional maximum a\nposteriori estimation with a risk of having a curse of dimensionality in\nestimating a huge number of model parameters, we focus our attention on\nestimating a manageable number of latent variables of DNNs via a VB inference\nframework. To accomplish model transfer, knowledge learnt from a source domain\nis encoded in prior distributions of latent variables and optimally combined,\nin a Bayesian sense, with a small set of adaptation data from a target domain\nto approximate the corresponding posterior distributions. Experimental results\non device adaptation in acoustic scene classification show that our proposed VB\napproach can obtain good improvements on target devices, and consistently\noutperforms 13 state-of-the-art knowledge transfer algorithms.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:54:01 GMT"},{"version":"v2","created":"Sun, 20 Feb 2022 18:32:04 GMT"}],"update_date":"2022-02-22"}
{"id":"2110.09382","submitter":"Pim Verschuuren","authors":"Pim Jordi Verschuuren","title":"Frequentist-Bayes Hybrid Covariance Estimationfor Unfolding Problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we present a frequentist-Bayesian hybrid method for estimating\ncovariances of unfolded distributions using pseudo-experiments. The method is\ncompared with other covariance estimation methods using the unbiased Rao-Cramer\nbound (RCB) and frequentist pseudo-experiments. We show that the unbiased RCB\nmethod diverges from the other two methods when regularization is introduced.\nThe new hybrid method agrees well with the frequentist pseudo-experiment method\nfor various amounts of regularization. However, the hybrid method has the added\nadvantage of not requiring a clear likelihood definition and can be used in\ncombination with any unfolding algorithm that uses a response matrix to model\nthe detector response.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:34:15 GMT"}],"update_date":"2021-10-19"}
{"id":"2110.09516","submitter":"Linda Chamakh","authors":"Linda Chamakh and Zolt\\'an Szab\\'o","title":"Kernel Minimum Divergence Portfolios","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG q-fin.PM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Portfolio optimization is a key challenge in finance with the aim of creating\nportfolios matching the investors' preference. The target distribution approach\nrelying on the Kullback-Leibler or the $f$-divergence represents one of the\nmost effective forms of achieving this goal. In this paper, we propose to use\nkernel and optimal transport (KOT) based divergences to tackle the task, which\nrelax the assumptions and the optimization constraints of the previous\napproaches. In case of the kernel-based maximum mean discrepancy (MMD) we (i)\nprove the analytic computability of the underlying mean embedding for various\ntarget distribution-kernel pairs, (ii) show that such analytic knowledge can\nlead to faster convergence of MMD estimators, and (iii) extend the results to\nthe unbounded exponential kernel with minimax lower bounds. Numerical\nexperiments demonstrate the improved performance of our KOT estimators both on\nsynthetic and real-world examples.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:29:27 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.09517","submitter":"Weikui Ye","authors":"Zhi Chen, Weikui Ye and Zhaoyang Yin","title":"Global Regularity and instability for the incompressible non-viscous\n  Oldroyd-B model","comments":"Oldroyd-B model; exponential decay; global solutions; instability.\n  arXiv admin note: substantial text overlap with arXiv:2110.08475","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we consider the 2-dimensional non-viscous Oldroyd-B model. In\nthe case of the ratio equal 1~($\\alpha=0$), it is a difficult case since the\nvelocity field $u(t,x)$ is no longer decay. Fortunately, by {observing the\nexponential decay} of the stress tensor $\\tau(t,x)$, we succeeded in proving\nthe global existence for this system with some large initial data. Moreover, we\ngive an unsteady result: when the ratio is close to 1~($a\\rightarrow 0$), the\nsystem is not steady for large time. This implies an interesting physical\nphenomenon that the term $a\\mathbb{D}u$ is a bridge between the transformation\nof kinetic energy $u$ and elastic potential energy $\\tau$, but this process is\ntransient for large time, which leads the instability.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:39:47 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.09892","submitter":"Oleksandr O Zhmudskyy","authors":"K. S. Karplyuk, O. O. Zhmudskyy","title":"The spin group of fermions","comments":"4 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph hep-th","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  It was shown that in the small Wigner group there is a one-parameter subgroup\nof the Lorentz transformations, which leave unchanged not only the momentum of\nthe fermion with spin h/2, but also its spin characteristics. This is the group\nof symmetry transformations of the moving fermion. These transformations\nconsist of rotations around the projection axis of the spin and boosts\ncoordinated with them. In other words, there are infinitely many frames of\nreference in which the fermion has the same momentum and the same spin\nprojection onto the selected axis, although these frames move relative to each\nother and have been rotated relative to each other.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:54:34 GMT"}],"update_date":"2021-10-20"}
{"id":"2110.09893","submitter":"Yiding Cao","authors":"Yiding Cao, Yingjun Dong, Minjun Kim, Neil G. MacLaren, Sriniwas\n  Pandey, Shelley D. Dionne, Francis J. Yammarino, and Hiroki Sayama","title":"Visualizing Collective Idea Generation and Innovation Processes in\n  Social Networks","comments":null,"journal-ref":"IEEE Transactions on Computational Social Systems, 2022,\n  https://ieeexplore.ieee.org/document/9819965","doi":"10.1109/TCSS.2022.3184628","report-no":null,"categories":"cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collective idea generation and innovation processes are complex and dynamic,\ninvolving a large amount of qualitative narrative information that is difficult\nto monitor, analyze, and visualize using traditional methods. In this study, we\ndeveloped three new visualization methods for collective idea generation and\ninnovation processes and applied them to data from online social network\nexperiments. The first visualization is the Idea Cloud, which helps monitor\ncollective idea posting activity and intuitively tracks idea clustering and\ntransition. The second visualization is the Idea Geography, which helps\nunderstand how the idea space and its utility landscape are structured and how\ncollaboration was performed in that space. The third visualization is the Idea\nNetwork, which connects idea dynamics with the social structure of the people\nwho generated them, displaying how social influence among neighbors may have\naffected collaborative activities and where innovative ideas arose and spread\nin the social network.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 15:34:56 GMT"},{"version":"v2","created":"Sat, 18 Jun 2022 04:40:53 GMT"},{"version":"v3","created":"Sun, 17 Jul 2022 02:51:36 GMT"}],"update_date":"2022-07-19"}
{"id":"2110.10150","submitter":"Yusen Zhang","authors":"Yusen Zhang, Ansong Ni, Ziming Mao, Chen Henry Wu, Chenguang Zhu,\n  Budhaditya Deb, Ahmed H. Awadallah, Dragomir Radev, Rui Zhang","title":"Summ^N: A Multi-Stage Summarization Framework for Long Input Dialogues\n  and Documents","comments":"ACL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text summarization helps readers capture salient information from documents,\nnews, interviews, and meetings. However, most state-of-the-art pretrained\nlanguage models (LM) are unable to efficiently process long text for many\nsummarization tasks. In this paper, we propose Summ$^N$, a simple, flexible,\nand effective multi-stage framework for input texts that are longer than the\nmaximum context length of typical pretrained LMs. Summ$^N$ first splits the\ndata samples and generates a coarse summary in multiple stages and then\nproduces the final fine-grained summary based on it. Our framework can process\ninput text of arbitrary length by adjusting the number of stages while keeping\nthe LM input size fixed. Moreover, it can deal with both single-source\ndocuments and dialogues, and it can be used on top of different backbone\nabstractive summarization models. To the best of our knowledge, Summ$^N$ is the\nfirst multi-stage split-then-summarize framework for long input summarization.\nOur experiments demonstrate that Summ$^N$ outperforms previous state-of-the-art\nmethods by improving ROUGE scores on three long meeting summarization datasets\nAMI, ICSI, and QMSum, two long TV series datasets from SummScreen, and a long\ndocument summarization dataset GovReport. Our data and code are available at\nhttps://github.com/psunlpgroup/Summ-N.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 06:19:54 GMT"},{"version":"v2","created":"Wed, 13 Apr 2022 19:05:02 GMT"}],"update_date":"2022-04-15"}
{"id":"2110.10262","submitter":"Chelsea Bartram","authors":"C. Bartram, T. Braine, R. Cervantes, N. Crisosto, N. Du, G. Leum, P.\n  Mohapatra, T. Nitta, L. J Rosenberg, G. Rybka, J. Yang, John Clarke, I.\n  Siddiqi, A. Agrawal, A. V. Dixit, M. H. Awida, A. S. Chou, M. Hollister, S.\n  Knirck, A. Sonnenschein, W. Wester, J. R. Gleason, A. T. Hipp, S. Jois, P.\n  Sikivie, N. S. Sullivan, D. B. Tanner, S. Hoof, E. Lentz, R. Khatiwada, G.\n  Carosi, C. Cisneros, N. Robertson, N. Woollett, L. D. Duffy, C. Boutan, M.\n  Jones, B. H. LaRoque, N. S. Oblath, M. S. Taubman, E. J. Daw, M. G. Perry, J.\n  H. Buckley, C. Gaikwad, J. Hoffman, K. Murch, M. Goryachev, B. T. McAllister,\n  A. Quiskamp, C. Thomson, M. E. Tobar","title":"Dark Matter Axion Search Using a Josephson Traveling Wave Parametric\n  Amplifier","comments":null,"journal-ref":"Rev. Sci. Instrum., 94, 044703, 2023","doi":"10.1063/5.0122907","report-no":null,"categories":"hep-ex astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a new exclusion bound of axion-like particle dark matter with\naxion-photon couplings above $\\mathrm{10^{-13}}$ $\\mathrm{GeV^{-1}}$ over the\nfrequency range 4796.7--4799.5 MHz, corresponding to a narrow range of axion\nmasses centered around 19.84 $\\mu$eV. This measurement represents the first\nimplementation of a Josephson Traveling Wave Parametric Amplifier (JTWPA) in a\ndark matter search. The JTWPA was operated in the insert of the Axion Dark\nMatter eXperiment (ADMX) as part of an independent receiver chain that was\nattached to a 0.588-liter cavity. The ability of the JTWPA to deliver high gain\nover a wide (3 GHz) bandwidth has engendered interest from those aiming to\nperform broadband axion searches, a longstanding goal in this field.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 17:21:34 GMT"}],"update_date":"2023-06-08"}
{"id":"2110.11070","submitter":"Arpan Biswas","authors":"Arpan Biswas, Claudio Fuentes, Christopher Hoyle","title":"A Nested Weighted Tchebycheff Multi-Objective Bayesian Optimization\n  Approach for Flexibility of Unknown Utopia Estimation in Expensive Black-box\n  Design Problems","comments":"35 pages, 8 figures in main text and 2 figures in supplementary","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a nested weighted Tchebycheff Multi-objective Bayesian\noptimization framework where we build a regression model selection procedure\nfrom an ensemble of models, towards better estimation of the uncertain\nparameters of the weighted-Tchebycheff expensive black-box multi-objective\nfunction. In existing work, a weighted Tchebycheff MOBO approach has been\ndemonstrated which attempts to estimate the unknown utopia in formulating\nacquisition function, through calibration using a priori selected regression\nmodel. However, the existing MOBO model lacks flexibility in selecting the\nappropriate regression models given the guided sampled data and therefore, can\nunder-fit or over-fit as the iterations of the MOBO progress, reducing the\noverall MOBO performance. As it is too complex to a priori guarantee a best\nmodel in general, this motivates us to consider a portfolio of different\nfamilies of predictive models fitted with current training data, guided by the\nWTB MOBO; the best model is selected following a user-defined prediction root\nmean-square-error-based approach. The proposed approach is implemented in\noptimizing a multi-modal benchmark problem and a thin tube design under\nconstant loading of temperature-pressure, with minimizing the risk of\ncreep-fatigue failure and design cost. Finally, the nested weighted Tchebycheff\nMOBO model performance is compared with different MOBO frameworks with respect\nto accuracy in parameter estimation, Pareto-optimal solutions and function\nevaluation cost. This method is generalized enough to consider different\nfamilies of predictive models in the portfolio for best model selection, where\nthe overall design architecture allows for solving any high-dimensional\n(multiple functions) complex black-box problems and can be extended to any\nother global criterion multi-objective optimization methods where prior\nknowledge of utopia is required.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 00:44:06 GMT"}],"update_date":"2021-10-22"}
{"id":"2110.11077","submitter":"Melissa Mendes","authors":"Melissa Mendes, Farrukh J. Fattoyev, Andrew Cumming, Charles Gale","title":"Probing dense matter physics with transiently-accreting neutron stars:\n  the case of source MXB 1659-29","comments":"Talk given at the XVI Marcel Grossmann Meeting (2021), to be\n  published on their proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th astro-ph.HE nucl-ex","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Recent observational data on transiently-accreting neutron stars has\nunequivocally shown fast-cooling sources, such as in the case of neutron star\nMXB 1659-29. Previous calculations have estimated its total neutrino luminosity\nand heat capacity, as well as suggested that direct Urca reactions take place\nin $1 \\%$ of the volume of the core. In this paper, we reproduce the inferred\nluminosity of this source with detailed models of equations of state (EOS) and\nnuclear pairing gaps. We show that three superfluidity gap models are\ninconsistent with data for all EOS and another three are disfavoured because of\nfine tuning arguments. We also calculate the total heat capacity for all\nconstructed stars and show that independent observations of mass and luminosity\ncould set constraints on the core superfluidity of a source as well as the\ndensity slope of the symmetry energy, L. This is an important step towards\ndefining a universal equation of state for neutron stars and therefore, towards\na better understanding of the phase diagram of asymmetric matter at high\ndensities.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 19:56:21 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.11407","submitter":"Sohini Roychowdhury","authors":"Sohini Roychowdhury, James Y. Sato","title":"Video-Data Pipelines for Machine Learning Applications","comments":"10 pages, 6 Figures, 5 Tables, conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data pipelines are an essential component for end-to-end solutions that take\nmachine learning algorithms to production. Engineering data pipelines for\nvideo-sequences poses several challenges including isolation of key-frames from\nvideo sequences that are high quality and represent significant variations in\nthe scene. Manual isolation of such quality key-frames can take hours of\nsifting through hours worth of video data. In this work, we present a data\npipeline framework that can automate this process of manual frame sifting in\nvideo sequences by controlling the fraction of frames that can be removed based\non image quality and content type. Additionally, the frames that are retained\ncan be automatically tagged per sequence, thereby simplifying the process of\nautomated data retrieval for future ML model deployments. We analyze the\nperformance of the proposed video-data pipeline for versioned deployment and\nmonitoring for object detection algorithms that are trained on outdoor\nautonomous driving video sequences. The proposed video-data pipeline can retain\nanywhere between 0.1-20% of the all input frames that are representative of\nhigh image quality and high variations in content. This frame selection,\nautomated scene tagging followed by model verification can be completed in\nunder 30 seconds for 22 video-sequences under analysis in this work. Thus, the\nproposed framework can be scaled to additional video-sequence data sets for\nautomating ML versioned deployments.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:28:56 GMT"}],"update_date":"2021-10-25"}
{"id":"2110.12870","submitter":"J\\=anis Baj\\=ars","authors":"J\\=anis Baj\\=ars and Filips Kozirevs","title":"Data-driven intrinsic localized mode detection and classification in\n  one-dimensional crystal lattice model","comments":null,"journal-ref":"Physics Letters A 436(6):128071 (2022)","doi":"10.1016/j.physleta.2022.128071","report-no":null,"categories":"cond-mat.mtrl-sci cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work we propose Support Vector Machine classification algorithms to\nclassify onedimensional crystal lattice waves from locally sampled data.\nDifferent learning datasets of particle displacements, momenta and energy\ndensity values are considered. Efficiency of the classification algorithms is\nfurther improved by two dimensionality reduction techniques: Principal\nComponent Analysis and Locally Linear Embedding. Robustness of classifiers is\ninvestigated and demonstrated. Developed algorithms are successfully applied to\ndetect localized intrinsic modes in three numerical simulations considering a\ncase of two localized stationary breather solutions, a single stationary\nbreather solution in noisy background and two mobile breather collision.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 16:15:06 GMT"},{"version":"v2","created":"Tue, 5 Apr 2022 09:08:44 GMT"}],"update_date":"2022-04-06"}
{"id":"2110.12872","submitter":"B\\'echir Amri Dr","authors":"B\\'echir Amri","title":"On the structure of the ring of integer-valued entire functions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV math.CA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The present paper studies structure of the ring of integer-valued entire\nfunctions.\n  We characterize certain classes of prime and maximal ideals and investigate\nsome of their properties.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:24:08 GMT"}],"update_date":"2021-10-26"}
{"id":"2110.13001","submitter":"Yujie Di","authors":"Yujie Di, Yingjie Shao, Lian-Kuan Chen","title":"Real-Time Wave Mitigation for Water-Air OWC Systems Via Beam Tracking","comments":null,"journal-ref":null,"doi":"10.1109/LPT.2021.3135419","report-no":null,"categories":"eess.SP physics.app-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a water-air optical wireless communication (OWC) channel, dynamic ocean\nwaves may significantly deflect the light beam from its original direction,\nthus deteriorating the communication performance. In this letter, a beam\ntracking system to mitigate wave-induced communication degradation is\nexperimentally demonstrated. By employing the beam tracking on the PAM6 system,\na maximum of 486% improvement (from 140 Mb/s to 820 Mb/s) in throughput is\nrealized at a 1.2-m air distance for an average wave slope changing rate of\n0.34 rad/s. For PAM4 signals, the packet loss rate reduces significantly from\n75% to 11%, and a maximum throughput of 1.25 Gb/s is achieved.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 10:42:57 GMT"}],"update_date":"2022-01-12"}
{"id":"2110.13610","submitter":"Yongming Liu","authors":"Zhiming Zhang and Yongming Liu","title":"Robust physics discovery via supervised and unsupervised pattern\n  recognition using the Euler characteristic","comments":null,"journal-ref":null,"doi":"10.1016/j.cma.2022.115110","report-no":null,"categories":"cs.CE cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning approaches have been widely used for discovering the\nunderlying physics of dynamical systems from measured data. Existing\napproaches, however, still lack robustness, especially when the measured data\ncontain a large level of noise. The lack of robustness is mainly attributed to\nthe insufficient representativeness of used features. As a result, the\nintrinsic mechanism governing the observed system cannot be accurately\nidentified. In this study, we use an efficient topological descriptor for\ncomplex data, i.e., the Euler characteristics (ECs), as features to\ncharacterize the spatiotemporal data collected from dynamical systems and\ndiscover the underlying physics. Unsupervised manifold learning and supervised\nclassification results show that EC can be used to efficiently distinguish\nsystems with different while similar governing models. We also demonstrate that\nthe machine learning approaches using EC can improve the confidence level of\nsparse regression methods of physics discovery.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:37:42 GMT"}],"update_date":"2022-06-08"}
{"id":"2110.15117","submitter":"Ivan Kennedy Professor","authors":"Ivan R. Kennedy, Migdat Hodzic, Angus N. Crossan, Niranjan Acharige\n  and John Runcie","title":"A New Theory for Estimating Maximum Power from Wind Turbines: A\n  Fundamental Newtonian Approach","comments":"21 pages, 7 figures, 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.class-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A novel method for calculating power output from wind turbines using\nNewtonian mechanics is proposed. This contrasts with current methods based on\ninterception rates by airfoils of kinetic energy to estimate power output,\ngoverned by the Betz limit of propeller theory. Radial action generates torques\nfrom impulses from air molecules at differing radii on rotor surfaces, both\nwindward and leeward. Dimensionally, torque is a rate of action. Integration of\nthe windward torque is achieved numerically using inputs of rotor dimensions,\nthe angle of incidence of elastic wind impulse on the blade surface, chord and\nblade lengths and the tip speed ratio with wind speed. The rate of leeward or\nback torque in the plane of rotation is estimated from radial impulses from the\nblades rotation on material particles, with magnitude varying with the square\nof the blade radius and its angular velocity. The net torque from these rates\nof action and reaction is converted to power by its product with the angular\nvelocity of the turbine rotors, considered as an ideal cycle for wind turbines.\nIts design should assist optimization of the aerodynamic elements of turbine\noperation. A matter of concern must be predictions for a significant rate of\nheat production by wind turbines, represented partly by the magnitude of the\nleeward reaction torque but also by a greater release of heat downwind caused\nby a turbulent cascade in the wake of air flow following its impacts with the\nblades. Given the widespread occurrence of wind farms as sources of renewable\nenergy and a need to minimize environmental impacts this new method should\npromote improved theory and practice regarding wind energy.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 05:23:17 GMT"}],"update_date":"2021-10-29"}
{"id":"2110.15387","submitter":"Mihai Nadin","authors":"Mihai Nadin, Asma Naz","title":"Anticipation-driven Adaptive Architecture for Assisted Living","comments":"12 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Anticipatory expression underlies human performance. Medical conditions and,\nespecially, aging result in diminished anticipatory action. In order to\nmitigate the loss, means for engaging still available resources (capabilities)\ncan be provided. In particular, anticipation-driven adaptive environments could\nbe beneficial in medical care, as well as in assisted living for those seeking\nsuch assistance. These adaptive environments are conceived to be individualized\nand individualizable, in order to stimulate independent action instead of\ncreating dependencies.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 20:55:33 GMT"}],"update_date":"2021-11-01"}
{"id":"2110.15733","submitter":"Hongwu Peng","authors":"Bingbing Li, Hongwu Peng, Rajat Sainju, Junhuan Yang, Lei Yang,\n  Yueying Liang, Weiwen Jiang, Binghui Wang, Hang Liu, and Caiwen Ding","title":"Detecting Gender Bias in Transformer-based Models: A Case Study on BERT","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we propose a novel gender bias detection method by utilizing\nattention map for transformer-based models. We 1) give an intuitive gender bias\njudgement method by comparing the different relation degree between the genders\nand the occupation according to the attention scores, 2) design a gender bias\ndetector by modifying the attention module, 3) insert the gender bias detector\ninto different positions of the model to present the internal gender bias flow,\nand 4) draw the consistent gender bias conclusion by scanning the entire\nWikipedia, a BERT pretraining dataset. We observe that 1) the attention\nmatrices, Wq and Wk introduce much more gender bias than other modules\n(including the embedding layer) and 2) the bias degree changes periodically\ninside of the model (attention matrix Q, K, V, and the remaining part of the\nattention layer (including the fully-connected layer, the residual connection,\nand the layer normalization module) enhance the gender bias while the averaged\nattentions reduces the bias).\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 21:25:58 GMT"}],"update_date":"2021-11-01"}
{"id":"2111.09189","submitter":"Yuanfei Wang","authors":"Yuanfei Wang, Fangwei Zhong, Jing Xu, Yizhou Wang","title":"ToM2C: Target-oriented Multi-agent Communication and Cooperation with\n  Theory of Mind","comments":"ICLR 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Being able to predict the mental states of others is a key factor to\neffective social interaction. It is also crucial for distributed multi-agent\nsystems, where agents are required to communicate and cooperate. In this paper,\nwe introduce such an important social-cognitive skill, i.e. Theory of Mind\n(ToM), to build socially intelligent agents who are able to communicate and\ncooperate effectively to accomplish challenging tasks. With ToM, each agent is\ncapable of inferring the mental states and intentions of others according to\nits (local) observation. Based on the inferred states, the agents decide \"when\"\nand with \"whom\" to share their intentions. With the information observed,\ninferred, and received, the agents decide their sub-goals and reach a consensus\namong the team. In the end, the low-level executors independently take\nprimitive actions to accomplish the sub-goals. We demonstrate the idea in two\ntypical target-oriented multi-agent tasks: cooperative navigation and\nmulti-sensor target coverage. The experiments show that the proposed model not\nonly outperforms the state-of-the-art methods on reward and communication\nefficiency, but also shows good generalization across different scales of the\nenvironment.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:29:55 GMT"},{"version":"v2","created":"Mon, 25 Apr 2022 09:13:53 GMT"}],"update_date":"2022-04-26"}
{"id":"2111.09424","submitter":"Nupur Choudhury","authors":"Nupur Choudhury, Chinmoy Kalita, Kandarpa Kumar Sarma","title":"Design of a Scalable 4G Portable Network Using Low Cost SDR And\n  Raspberry Pi","comments":null,"journal-ref":"WSEAS TRANSACTIONS on COMMUNICATIONS,2021","doi":"10.37394/23204.2021.20.15","report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Of late, Software Defined Radio (SDR) approach has become an effective means\nto design high data rate wireless systems for a range of applications. There\nare methods with which low cost SDR based 4th generation (4G) or long term\nevolution (LTE) systems can be designed. Using low cost Raspberry Pi systems,\nthe SDR aided 4G systems can be designed for high data rate communication. The\nwork is related to the design of a 4G wireless system using low cost SDR\nsolutions and integrated to a programmable controller based on a Raspberry Pi.\nExperimental results show that the system is effective in a range of\nconditions.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:21:57 GMT"}],"update_date":"2021-11-24"}
{"id":"2112.00625","submitter":"Theo Schaad","authors":"Theo P. Schaad","title":"A Challenging 7-Fold Tiling Puzzle","comments":"22 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A quasiperiodic 7-fold rhombic tiling is constructed with an iterative\nsubstitution scheme. The inflation factor is 5.04892..., the square of the\nlonger diagonal of a regular heptagon. There are many substitutions possible\nthat fill larger similar tiles with three base shapes but finding the matching\nrules (how the larger tiles fit together to make even larger tiles) turns into\na challenging puzzle. At the end, a new solution is found with seven\nsubstitution rules. The relationship to a higher-order Fibonacci series is\nexplored. The tiling is presented with a celestial theme reminiscent of a\nstarry night.\n","versions":[{"version":"v1","created":"Fri, 15 Oct 2021 18:46:24 GMT"}],"update_date":"2021-12-02"}
{"id":"2112.03170","submitter":"Yue Yu","authors":"Zhijing Zhang, Yue Yu, Qinghua Ma, Haixiang Yao","title":"A revised comparison between FF five-factor model and three-factor\n  model,based on China's A-share market","comments":"17 pages, under review","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.GN econ.GN q-fin.EC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In allusion to some contradicting results in existing research, this paper\nselects China's latest stock data from 2005 to 2020 for empirical analysis. By\nchoosing this periods' data, we avoid the periods of China's significant stock\nmarket reforms to reduce the impact of the government's policy on the factor\neffect. In this paper, the redundant factors (HML, CMA) are orthogonalized, and\nthe regression analysis of 5*5 portfolio of Size-B/M and Size-Inv is carried\nout with these two orthogonalized factors. It found that the HML and the CMA\nare still significant in many portfolios, indicating that they have a strong\nexplanatory ability, which is also consistent with the results of GRS test. All\nthese show that the five-factor model has a better ability to explain the\nexcess return rate. In the concrete analysis, this paper uses the methods of\nthe five-factor 25-group portfolio returns calculation, the five-factor\nregression analysis, the orthogonal treatment, the five-factor 25-group\nregression and the GRS test to more comprehensively explain the excellent\nexplanatory ability of the five-factor model to the excess return. Then, we\nanalyze the possible reasons for the strong explanatory ability of the HML, CMA\nand RMW from the aspects of price to book ratio, turnover rate and correlation\ncoefficient. We also give a detailed explanation of the results, and analyze\nthe changes of China's stock market policy and investors' investment style\nrecent years. Finally, this paper attempts to put forward some useful\nsuggestions on the development of asset pricing model and China's stock market.\n","versions":[{"version":"v1","created":"Sat, 16 Oct 2021 04:46:46 GMT"}],"update_date":"2021-12-07"}
